<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>da9d7a4bc89d49eaad91e3ae5bfc6bb9</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<section id="1-introduction" class="cell markdown" id="cb-h0Z1gJFn5">
<h1>1. Introduction</h1>
<p>This workbook builds and evaluates an automatic classifier that
assigns three labels to research papers: Discipline, Subfield, and
Methodology. It culminates in a working inference tool that accepts PDFs
and returns predicted labels with confidences.</p>
<p>How to use this notebook. Run cells top-to-bottom. Sections are
self-contained and save their outputs (metrics tables and figures) so
later sections can load and compare results.</p>
<p>Evaluation focus. Macro-F1 is reported as the primary score because
it reflects performance across all classes rather than being dominated
by any single label. I also show per-class recall to make performance by
category transparent.</p>
<p>What you will find here.</p>
<ol>
<li><p>Data Loading &amp; Preprocessing: Load data, apply light text
cleaning, preview token lengths used later.</p></li>
<li><p>Baseline Models: Train TF-IDF baselines; write metrics CSVs for
comparison.</p></li>
<li><p>Transformer Models: Single-label runs for SciBERT, RoBERTa,
DistilBERT (“Model-1”), plus extended variants (C/D/E) with compact
visualisations.</p></li>
<li><p>Model Comparisons: TF-IDF vs SciBERT, Model 1 comparisons, all
models Macro-F1, and a unified per class recall heatmap.</p></li>
<li><p>Multi-Label Classification (SciBERT): One model predicting the
three label types jointly.</p></li>
<li><p>Complete Classification Pipeline: Upload PDFs &gt; extract
abstract &gt; return labels with confidences.</p></li>
<li><p>Conclusion &amp; Discussion</p></li>
</ol>
<p>Inference assets for Section 7: mlb.pkl, classes.npy, and the model
checkpoint (e.g., multi_label_scibert.pt). The notebook will prompt if
any are missing.</p>
<p>Environment. Runs on GPU; ran out of it so some with CPU. Random
seeds are set where practical.</p>
<p>Outputs. All figures/tables displayed are also saved to disk for easy
inclusion in the written report.</p>
</section>
<section id="imports" class="cell markdown" id="5xlyw8pYnrYt">
<h3>Imports</h3>
</section>
<div class="cell code" id="rep8H59irlyy">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># install dependencies</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">-</span>q transformers datasets scikit<span class="op">-</span>learn pdfplumber</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># general</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> io</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> string</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pickle</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dataclasses <span class="im">import</span> dataclass</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Dict, Any, List</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># data and visualisation</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> csv</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> display</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="co"># nlp tools</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> stopwords</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> spacy</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pdfplumber</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="co"># sklearn for ML</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> (</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>    train_test_split,</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>    StratifiedKFold,</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>    cross_val_score,</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>    cross_val_predict,</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfVectorizer</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder, MultiLabelBinarizer</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, classification_report, f1_score</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="co"># torch and transformers</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, WeightedRandomSampler</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.optim <span class="im">import</span> AdamW</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> (</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>    AutoTokenizer,</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>    AutoModelForSequenceClassification,</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>    get_linear_schedule_with_warmup,</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>    AutoModel</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a><span class="co"># huggingface</span></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> Dataset</span></code></pre></div>
</div>
<section id="2-data-loading--preprocessing" class="cell markdown"
id="qACOfKFUfZnC">
<h1>2. Data Loading &amp; Preprocessing</h1>
<p>Before training any models, the text is normalised into a consistent,
model-friendly form. This section loads Ver5dataset_three_final.csv,
removes rows without text_excerpt, and produces two canonical views of
the text that the rest of the workbook will use.</p>
<p>The cleaning pipeline lowercases text, strips punctuation, runs spaCy
lemmatisation, and optionally filters out stopwords (NLTK). From this,
two columns are created:</p>
<p>processed_no_stopwords: suited to bag-of-words baselines such as
TF-IDF.</p>
<p>processed_with_stopwords: keeps function words for transformer models
that benefit from full sentence context (SciBERT/RoBERTa/DistilBERT) and
for the final PDF-to-labels tool.</p>
<p>A short preview (head=5) of both processed columns is shown to verify
the transformation, followed by printed counts for the three targets
(discipline, subfield, methodology) to provide a quick sense of category
coverage for the evaluations that follow.</p>
<p>Conventions used later: TF-IDF cells read processed_no_stopwords; all
transformer experiments and the final inference pipeline read
processed_with_stopwords.</p>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:73}"
id="zPKszLjWIAVp" data-outputId="b4b6a51c-ceea-42a4-9366-5144a6b3fcf1">
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load data</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> google.colab <span class="im">import</span> files</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Upload dataset</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>uploaded <span class="op">=</span> files.upload()</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the uploaded CSV file</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">&quot;Ver5dataset_three_final.csv&quot;</span>)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Drop rows with null in &#39;text_excerpt&#39;</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df[df[<span class="st">&#39;text_excerpt&#39;</span>].notnull()].copy()</span></code></pre></div>
<div class="output display_data">

     <input type="file" id="files-fd17fd8c-6aae-43b6-a993-17a3e26bccf0" name="files[]" multiple disabled
        style="border:none" />
     <output id="result-fd17fd8c-6aae-43b6-a993-17a3e26bccf0">
      Upload widget is only available when the cell has been executed in the
      current browser session. Please rerun this cell to enable.
      </output>
      <script>// Copyright 2017 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

/**
 * @fileoverview Helpers for google.colab Python module.
 */
(function(scope) {
function span(text, styleAttributes = {}) {
  const element = document.createElement('span');
  element.textContent = text;
  for (const key of Object.keys(styleAttributes)) {
    element.style[key] = styleAttributes[key];
  }
  return element;
}

// Max number of bytes which will be uploaded at a time.
const MAX_PAYLOAD_SIZE = 100 * 1024;

function _uploadFiles(inputId, outputId) {
  const steps = uploadFilesStep(inputId, outputId);
  const outputElement = document.getElementById(outputId);
  // Cache steps on the outputElement to make it available for the next call
  // to uploadFilesContinue from Python.
  outputElement.steps = steps;

  return _uploadFilesContinue(outputId);
}

// This is roughly an async generator (not supported in the browser yet),
// where there are multiple asynchronous steps and the Python side is going
// to poll for completion of each step.
// This uses a Promise to block the python side on completion of each step,
// then passes the result of the previous step as the input to the next step.
function _uploadFilesContinue(outputId) {
  const outputElement = document.getElementById(outputId);
  const steps = outputElement.steps;

  const next = steps.next(outputElement.lastPromiseValue);
  return Promise.resolve(next.value.promise).then((value) => {
    // Cache the last promise value to make it available to the next
    // step of the generator.
    outputElement.lastPromiseValue = value;
    return next.value.response;
  });
}

/**
 * Generator function which is called between each async step of the upload
 * process.
 * @param {string} inputId Element ID of the input file picker element.
 * @param {string} outputId Element ID of the output display.
 * @return {!Iterable<!Object>} Iterable of next steps.
 */
function* uploadFilesStep(inputId, outputId) {
  const inputElement = document.getElementById(inputId);
  inputElement.disabled = false;

  const outputElement = document.getElementById(outputId);
  outputElement.innerHTML = '';

  const pickedPromise = new Promise((resolve) => {
    inputElement.addEventListener('change', (e) => {
      resolve(e.target.files);
    });
  });

  const cancel = document.createElement('button');
  inputElement.parentElement.appendChild(cancel);
  cancel.textContent = 'Cancel upload';
  const cancelPromise = new Promise((resolve) => {
    cancel.onclick = () => {
      resolve(null);
    };
  });

  // Wait for the user to pick the files.
  const files = yield {
    promise: Promise.race([pickedPromise, cancelPromise]),
    response: {
      action: 'starting',
    }
  };

  cancel.remove();

  // Disable the input element since further picks are not allowed.
  inputElement.disabled = true;

  if (!files) {
    return {
      response: {
        action: 'complete',
      }
    };
  }

  for (const file of files) {
    const li = document.createElement('li');
    li.append(span(file.name, {fontWeight: 'bold'}));
    li.append(span(
        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +
        `last modified: ${
            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :
                                    'n/a'} - `));
    const percent = span('0% done');
    li.appendChild(percent);

    outputElement.appendChild(li);

    const fileDataPromise = new Promise((resolve) => {
      const reader = new FileReader();
      reader.onload = (e) => {
        resolve(e.target.result);
      };
      reader.readAsArrayBuffer(file);
    });
    // Wait for the data to be ready.
    let fileData = yield {
      promise: fileDataPromise,
      response: {
        action: 'continue',
      }
    };

    // Use a chunked sending to avoid message size limits. See b/62115660.
    let position = 0;
    do {
      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);
      const chunk = new Uint8Array(fileData, position, length);
      position += length;

      const base64 = btoa(String.fromCharCode.apply(null, chunk));
      yield {
        response: {
          action: 'append',
          file: file.name,
          data: base64,
        },
      };

      let percentDone = fileData.byteLength === 0 ?
          100 :
          Math.round((position / fileData.byteLength) * 100);
      percent.textContent = `${percentDone}% done`;

    } while (position < fileData.byteLength);
  }

  // All done.
  yield {
    response: {
      action: 'complete',
    }
  };
}

scope.google = scope.google || {};
scope.google.colab = scope.google.colab || {};
scope.google.colab._files = {
  _uploadFiles,
  _uploadFilesContinue,
};
})(self);
</script> 
</div>
<div class="output stream stdout">
<pre><code>Saving Ver5dataset_three_final.csv to Ver5dataset_three_final.csv
</code></pre>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:382}"
id="brarHjngInH5" data-outputId="34ec44a3-75c7-451a-b5fd-84fdaefcc3bb">
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Text Processing</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Download NLTK stopwords</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">&quot;stopwords&quot;</span>)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>stop_words <span class="op">=</span> <span class="bu">set</span>(stopwords.words(<span class="st">&quot;english&quot;</span>))</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Load spaCy model</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>nlp <span class="op">=</span> spacy.load(<span class="st">&quot;en_core_web_sm&quot;</span>)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Preprocessing function</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> preprocess_text(text, remove_stopwords<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> text.lower().translate(<span class="bu">str</span>.maketrans(<span class="st">&#39;&#39;</span>, <span class="st">&#39;&#39;</span>, string.punctuation))</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    doc <span class="op">=</span> nlp(text)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    tokens <span class="op">=</span> []</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> token <span class="kw">in</span> doc:</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> token.is_alpha:</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> remove_stopwords <span class="kw">and</span> token.text <span class="kw">in</span> stop_words:</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>                <span class="cf">continue</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>            tokens.append(token.lemma_)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">&quot; &quot;</span>.join(tokens)</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply preprocessing</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&#39;processed_no_stopwords&#39;</span>] <span class="op">=</span> df[<span class="st">&#39;text_excerpt&#39;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: preprocess_text(<span class="bu">str</span>(x), remove_stopwords<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&#39;processed_with_stopwords&#39;</span>] <span class="op">=</span> df[<span class="st">&#39;text_excerpt&#39;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: preprocess_text(<span class="bu">str</span>(x), remove_stopwords<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Preview of processed text (head=5):&quot;</span>)</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>display(df[[<span class="st">&quot;processed_no_stopwords&quot;</span>, <span class="st">&quot;processed_with_stopwords&quot;</span>]].head(<span class="dv">5</span>))</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Show class counts</span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Class Distribution:&quot;</span>)</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Methodology:&quot;</span>, df[<span class="st">&#39;methodology&#39;</span>].value_counts().to_dict())</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Discipline:&quot;</span>, df[<span class="st">&#39;discipline&#39;</span>].value_counts().to_dict())</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Subfield:&quot;</span>, df[<span class="st">&#39;subfield&#39;</span>].value_counts().to_dict())</span></code></pre></div>
<div class="output stream stderr">
<pre><code>[nltk_data] Downloading package stopwords to /root/nltk_data...
[nltk_data]   Unzipping corpora/stopwords.zip.
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>
Preview of processed text (head=5):
</code></pre>
</div>
<div class="output display_data">

  <div id="df-7d81f562-31e8-4fe9-a91f-a580c747a07a" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>processed_no_stopwords</th>
      <th>processed_with_stopwords</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>report magnitude flash detect approximately mi...</td>
      <td>we report on a magnitude flash detect for appr...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>discuss feasibility gamma ray burst grb tev ga...</td>
      <td>we discuss feasibility of gamma ray burst grb ...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>dimension infiniterange kawasaki spin exchange...</td>
      <td>in all dimension infiniterange kawasaki spin e...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>technique develop explore complete space inter...</td>
      <td>technique be develop for explore the complete ...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>set general structure analysis frustrationfree...</td>
      <td>we set up a general structure for the analysis...</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-7d81f562-31e8-4fe9-a91f-a580c747a07a')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-7d81f562-31e8-4fe9-a91f-a580c747a07a button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-7d81f562-31e8-4fe9-a91f-a580c747a07a');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    <div id="df-f47686a8-4368-4de5-a0ab-2f3f4fb04962">
      <button class="colab-df-quickchart" onclick="quickchart('df-f47686a8-4368-4de5-a0ab-2f3f4fb04962')"
                title="Suggest charts"
                style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
      </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

      <script>
        async function quickchart(key) {
          const quickchartButtonEl =
            document.querySelector('#' + key + ' button');
          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
          quickchartButtonEl.classList.add('colab-df-spinner');
          try {
            const charts = await google.colab.kernel.invokeFunction(
                'suggestCharts', [key], {});
          } catch (error) {
            console.error('Error during call to suggestCharts:', error);
          }
          quickchartButtonEl.classList.remove('colab-df-spinner');
          quickchartButtonEl.classList.add('colab-df-quickchart-complete');
        }
        (() => {
          let quickchartButtonEl =
            document.querySelector('#df-f47686a8-4368-4de5-a0ab-2f3f4fb04962 button');
          quickchartButtonEl.style.display =
            google.colab.kernel.accessAllowed ? 'block' : 'none';
        })();
      </script>
    </div>

    </div>
  </div>

</div>
<div class="output stream stdout">
<pre><code>
Class Distribution:
Methodology: {&#39;Design Science / System Design&#39;: 3601, &#39;Theoretical / Conceptual&#39;: 1477, &#39;Mixed Methods&#39;: 450, &#39;Qualitative&#39;: 54}
Discipline: {&#39;Economics&#39;: 1263, &#39;Computer Science&#39;: 1259, &#39;Mathematics&#39;: 1101, &#39;Physics&#39;: 580, &#39;Statistics&#39;: 546, &#39;Quantitative Biology&#39;: 456, &#39;Astrophysics&#39;: 209, &#39;Electrical Engineering and Systems Science&#39;: 168}
Subfield: {&#39;General Economics&#39;: 1714, &#39;Machine Learning&#39;: 1424, &#39;Algebraic Geometry&#39;: 1005, &#39;Neural and Cognitive Modeling&#39;: 486, &#39;Quantum Physics&#39;: 385, &#39;Computer Science and Game Theory&#39;: 273, &#39;Galaxy Astrophysics&#39;: 189, &#39;Image and Video Processing&#39;: 106}
</code></pre>
</div>
</div>
<section id="3-baseline-models-tf-idf" class="cell markdown"
id="4sYU25-vfic6">
<h1>3. Baseline Models (TF-IDF)</h1>
</section>
<section id="31-tf-idf-basic" class="cell markdown" id="V9gSHY5mEjOW">
<h2>3.1 TF-IDF Basic</h2>
<p>Section 3.1 trains baseline linear classifiers with a shared TF-IDF
representation. The text is vectorised from processed_with_stopwords
using TfidfVectorizer(max_features=3000), then split into train/test
with a fixed seed (random_state=42) and stratification on the
methodology label to keep the label mix comparable across splits.</p>
<p>Three models are fitted independently for: methodology, discipline,
and subfield and an individual classification_report. In addition, the
methodology run writes a single-row metrics file,
tfidf_basic_methodology_metrics.csv, containing:</p>
<ul>
<li>run, val_acc, macro_f1</li>
<li>per-class recalls for: Design Science / System Design, Mixed
Methods, Qualitative, Theoretical / Conceptual</li>
</ul>
<p>The results are:</p>
<ul>
<li>Methodology: overall accuracy is about 0.76; strong recall for
Design Science/System Design and Mixed Methods, lower for
Theoretical/Conceptual, and very limited performance on Qualitative.
Macro-F1 is is about 0.39.</li>
<li>Discipline: accuracy is about 0.48, with noticeable variation across
classes (some high-recall categories and some lower-recall ones);
macro-F1 is about 0.40.</li>
<li>Subfield: accuracy is about 0.52; performance varies by category;
macro-F1 is about 0.33.</li>
</ul>
</section>
<div class="cell code" id="mdYAZLjodl-8">
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Shared TF-IDF Vectorisation</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>vectorizer <span class="op">=</span> TfidfVectorizer(max_features<span class="op">=</span><span class="dv">3000</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> vectorizer.fit_transform(df[<span class="st">&#39;processed_with_stopwords&#39;</span>])</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Shared Train/Test Split</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>X_train, X_test, idx_train, idx_test <span class="op">=</span> train_test_split(</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    X, df.index, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>, stratify<span class="op">=</span>df[<span class="st">&#39;methodology&#39;</span>]</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="cell code" id="H4ScRp2mXInB">
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> save_methodology_csv(run_name, y_true, y_pred, out_path):</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># build metrics</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    rep <span class="op">=</span> classification_report(y_true, y_pred, output_dict<span class="op">=</span><span class="va">True</span>, zero_division<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    val_acc  <span class="op">=</span> accuracy_score(y_true, y_pred)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    macro_f1 <span class="op">=</span> f1_score(y_true, y_pred, average<span class="op">=</span><span class="st">&quot;macro&quot;</span>)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># pull recalls by class label</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    recall_design <span class="op">=</span> rep.get(<span class="st">&quot;Design Science / System Design&quot;</span>, {}).get(<span class="st">&quot;recall&quot;</span>, <span class="fl">0.0</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    recall_mixed  <span class="op">=</span> rep.get(<span class="st">&quot;Mixed Methods&quot;</span>, {}).get(<span class="st">&quot;recall&quot;</span>, <span class="fl">0.0</span>)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    recall_qual   <span class="op">=</span> rep.get(<span class="st">&quot;Qualitative&quot;</span>, {}).get(<span class="st">&quot;recall&quot;</span>, <span class="fl">0.0</span>)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    recall_tc     <span class="op">=</span> rep.get(<span class="st">&quot;Theoretical / Conceptual&quot;</span>, {}).get(<span class="st">&quot;recall&quot;</span>, <span class="fl">0.0</span>)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># write CSV</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> <span class="bu">open</span>(out_path, mode<span class="op">=</span><span class="st">&quot;w&quot;</span>, newline<span class="op">=</span><span class="st">&quot;&quot;</span>) <span class="im">as</span> f:</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>        w <span class="op">=</span> csv.writer(f)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>        w.writerow([</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;run&quot;</span>, <span class="st">&quot;val_acc&quot;</span>, <span class="st">&quot;macro_f1&quot;</span>,</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;recall_Design_Science_/_System_Design&quot;</span>,</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;recall_Mixed_Methods&quot;</span>,</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;recall_Qualitative&quot;</span>,</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;recall_Theoretical_/_Conceptual&quot;</span></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>        w.writerow([</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>            run_name, <span class="bu">round</span>(val_acc, <span class="dv">6</span>), <span class="bu">round</span>(macro_f1, <span class="dv">6</span>),</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>            <span class="bu">round</span>(recall_design, <span class="dv">6</span>), <span class="bu">round</span>(recall_mixed, <span class="dv">6</span>),</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>            <span class="bu">round</span>(recall_qual, <span class="dv">6</span>), <span class="bu">round</span>(recall_tc, <span class="dv">6</span>)</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Methodology metrics saved to </span><span class="sc">{</span>out_path<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="ofaCA2TJJLuq" data-outputId="aa8b7df1-73e6-4f50-c2dc-630c44d9dbf9">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Methodology</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>y_m <span class="op">=</span> df.loc[idx_train, <span class="st">&#39;methodology&#39;</span>]</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>y_test_m <span class="op">=</span> df.loc[idx_test, <span class="st">&#39;methodology&#39;</span>]</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>model_m <span class="op">=</span> LogisticRegression(max_iter<span class="op">=</span><span class="dv">1000</span>).fit(X_train, y_m)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>y_pred_m <span class="op">=</span> model_m.predict(X_test)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">[Methodology - TFIDF Basic]&quot;</span>)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Accuracy:&quot;</span>, accuracy_score(y_test_m, y_pred_m))</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test_m, y_pred_m, zero_division<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="co"># save CSV</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>save_methodology_csv(</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    run_name<span class="op">=</span><span class="st">&quot;TFIDF_basic&quot;</span>,</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>    y_true<span class="op">=</span>y_test_m,</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>    y_pred<span class="op">=</span>y_pred_m,</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    out_path<span class="op">=</span><span class="st">&quot;tfidf_basic_methodology_metrics.csv&quot;</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Discipline</span></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>y_d <span class="op">=</span> df.loc[idx_train, <span class="st">&#39;discipline&#39;</span>]</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>y_test_d <span class="op">=</span> df.loc[idx_test, <span class="st">&#39;discipline&#39;</span>]</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>model_d <span class="op">=</span> LogisticRegression(max_iter<span class="op">=</span><span class="dv">1000</span>).fit(X_train, y_d)</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>y_pred_d <span class="op">=</span> model_d.predict(X_test)</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">[Discipline - TFIDF Basic]&quot;</span>)</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Accuracy:&quot;</span>, accuracy_score(y_test_d, y_pred_d))</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test_d, y_pred_d))</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Subfield</span></span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>y_s <span class="op">=</span> df.loc[idx_train, <span class="st">&#39;subfield&#39;</span>]</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>y_test_s <span class="op">=</span> df.loc[idx_test, <span class="st">&#39;subfield&#39;</span>]</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>model_s <span class="op">=</span> LogisticRegression(max_iter<span class="op">=</span><span class="dv">1000</span>).fit(X_train, y_s)</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>y_pred_s <span class="op">=</span> model_s.predict(X_test)</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">[Subfield - TFIDF Basic]&quot;</span>)</span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Accuracy:&quot;</span>, accuracy_score(y_test_s, y_pred_s))</span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test_s, y_pred_s))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>
[Methodology - TFIDF Basic]
Accuracy: 0.756490599820949
                                precision    recall  f1-score   support

Design Science / System Design       0.77      0.93      0.84       721
                 Mixed Methods       0.80      0.04      0.08        90
                   Qualitative       0.00      0.00      0.00        11
      Theoretical / Conceptual       0.72      0.57      0.63       295

                      accuracy                           0.76      1117
                     macro avg       0.57      0.39      0.39      1117
                  weighted avg       0.75      0.76      0.72      1117

Methodology metrics saved to tfidf_basic_methodology_metrics.csv

[Discipline - TFIDF Basic]
Accuracy: 0.4816472694717995
                                            precision    recall  f1-score   support

                              Astrophysics       0.86      0.61      0.71        41
                          Computer Science       0.27      0.34      0.30       238
                                 Economics       0.67      0.83      0.74       267
Electrical Engineering and Systems Science       0.00      0.00      0.00        28
                               Mathematics       0.45      0.60      0.51       209
                                   Physics       0.34      0.08      0.14       119
                      Quantitative Biology       0.55      0.39      0.46        99
                                Statistics       0.44      0.31      0.36       116

                                  accuracy                           0.48      1117
                                 macro avg       0.45      0.40      0.40      1117
                              weighted avg       0.46      0.48      0.46      1117

</code></pre>
</div>
<div class="output stream stderr">
<pre><code>/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f&quot;{metric.capitalize()} is&quot;, len(result))
/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f&quot;{metric.capitalize()} is&quot;, len(result))
/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f&quot;{metric.capitalize()} is&quot;, len(result))
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>
[Subfield - TFIDF Basic]
Accuracy: 0.5201432408236347
                                  precision    recall  f1-score   support

              Algebraic Geometry       0.51      0.77      0.61       193
Computer Science and Game Theory       0.00      0.00      0.00        42
             Galaxy Astrophysics       0.75      0.50      0.60        36
               General Economics       0.63      0.65      0.64       370
      Image and Video Processing       0.00      0.00      0.00        18
                Machine Learning       0.40      0.55      0.46       275
   Neural and Cognitive Modeling       0.56      0.21      0.30       107
                 Quantum Physics       0.14      0.01      0.02        76

                        accuracy                           0.52      1117
                       macro avg       0.37      0.34      0.33      1117
                    weighted avg       0.48      0.52      0.48      1117

</code></pre>
</div>
<div class="output stream stderr">
<pre><code>/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f&quot;{metric.capitalize()} is&quot;, len(result))
/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f&quot;{metric.capitalize()} is&quot;, len(result))
/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f&quot;{metric.capitalize()} is&quot;, len(result))
</code></pre>
</div>
</div>
<section id="32-tf-idf-kfold" class="cell markdown" id="e0a9bteiflLt">
<h2>3.2 TF-IDF Kfold</h2>
<p>Section 3.2 repeats the TF-IDF baselines with 5 fold stratified cross
validation to check that the single split in 3.1 is representative. The
same TF-IDF features are used. For each task:</p>
<ul>
<li>cross_val_score (scoring="accuracy") reports the mean CV
accuracy.</li>
<li>cross_val_predict yields out of fold predictions so a full
classification_report can be printed on all items.</li>
<li>The methodology run is also saved to
tfidf_kfold_methodology_metrics.csv with the same fields as in 3.1 (run,
val_acc, macro_f1, and per-class recalls).</li>
</ul>
<p>The results are:</p>
<ul>
<li>Methodology: accuracy is about 0.76, macro-F1 is about 0.38. Pattern
mirrors 3.1, strongest recall for Design Science / System Design and
Mixed Methods; weaker for Theoretical / Conceptual and Qualitative.</li>
<li>Discipline: accuracy is about 0.47, macro-F1 is about 0.39.</li>
<li>Subfield: accuracy is about 0.52, macro-F1 is about 0.33.</li>
</ul>
<p>Overall, K-Fold results are consistent with the single-split
baseline, providing a stable reference for the transformer comparisons
later in Section 5.</p>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="7qdujF1deRBA" data-outputId="9cac2b26-28a4-4f93-d53d-4e46d117435d">
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>cv <span class="op">=</span> StratifiedKFold(n_splits<span class="op">=</span><span class="dv">5</span>, shuffle<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co"># methodology</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">[Methodology - TFIDF K-Fold]&quot;</span>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>y_m <span class="op">=</span> df[<span class="st">&#39;methodology&#39;</span>]</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>model_m <span class="op">=</span> LogisticRegression(max_iter<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>scores_m <span class="op">=</span> cross_val_score(model_m, X, y_m, cv<span class="op">=</span>cv, scoring<span class="op">=</span><span class="st">&#39;accuracy&#39;</span>)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Cross-validated accuracy (mean):&quot;</span>, np.mean(scores_m))</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>y_pred_m <span class="op">=</span> cross_val_predict(model_m, X, y_m, cv<span class="op">=</span>cv)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_m, y_pred_m, zero_division<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="co"># save CSV</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>save_methodology_csv(</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>    run_name<span class="op">=</span><span class="st">&quot;TFIDF_kfold&quot;</span>,</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>    y_true<span class="op">=</span>y_m,</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>    y_pred<span class="op">=</span>y_pred_m,</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>    out_path<span class="op">=</span><span class="st">&quot;tfidf_kfold_methodology_metrics.csv&quot;</span></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a><span class="co"># discipline</span></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">[Discipline - TFIDF K-Fold]&quot;</span>)</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>y_d <span class="op">=</span> df[<span class="st">&#39;discipline&#39;</span>]</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>model_d <span class="op">=</span> LogisticRegression(max_iter<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>scores_d <span class="op">=</span> cross_val_score(model_d, X, y_d, cv<span class="op">=</span>cv, scoring<span class="op">=</span><span class="st">&#39;accuracy&#39;</span>)</span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Cross-validated accuracy (mean):&quot;</span>, np.mean(scores_d))</span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>y_pred_d <span class="op">=</span> cross_val_predict(model_d, X, y_d, cv<span class="op">=</span>cv)</span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_d, y_pred_d))</span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a><span class="co"># subfield</span></span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">[Subfield - TFIDF K-Fold]&quot;</span>)</span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a>y_s <span class="op">=</span> df[<span class="st">&#39;subfield&#39;</span>]</span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a>model_s <span class="op">=</span> LogisticRegression(max_iter<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a>scores_s <span class="op">=</span> cross_val_score(model_s, X, y_s, cv<span class="op">=</span>cv, scoring<span class="op">=</span><span class="st">&#39;accuracy&#39;</span>)</span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Cross-validated accuracy (mean):&quot;</span>, np.mean(scores_s))</span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a>y_pred_s <span class="op">=</span> cross_val_predict(model_s, X, y_s, cv<span class="op">=</span>cv)</span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_s, y_pred_s))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>
[Methodology - TFIDF K-Fold]
Cross-validated accuracy (mean): 0.7586887881325748
                                precision    recall  f1-score   support

Design Science / System Design       0.77      0.93      0.84      3601
                 Mixed Methods       0.80      0.02      0.03       450
                   Qualitative       0.00      0.00      0.00        54
      Theoretical / Conceptual       0.71      0.59      0.65      1477

                      accuracy                           0.76      5582
                     macro avg       0.57      0.39      0.38      5582
                  weighted avg       0.75      0.76      0.72      5582

Methodology metrics saved to tfidf_kfold_methodology_metrics.csv

[Discipline - TFIDF K-Fold]
Cross-validated accuracy (mean): 0.4704376482064413
                                            precision    recall  f1-score   support

                              Astrophysics       0.79      0.55      0.65       209
                          Computer Science       0.30      0.35      0.32      1259
                                 Economics       0.64      0.86      0.73      1263
Electrical Engineering and Systems Science       0.20      0.01      0.01       168
                               Mathematics       0.44      0.56      0.49      1101
                                   Physics       0.19      0.04      0.07       580
                      Quantitative Biology       0.55      0.42      0.48       456
                                Statistics       0.41      0.29      0.34       546

                                  accuracy                           0.47      5582
                                 macro avg       0.44      0.38      0.39      5582
                              weighted avg       0.44      0.47      0.44      5582


[Subfield - TFIDF K-Fold]
Cross-validated accuracy (mean): 0.5231065674505764
                                  precision    recall  f1-score   support

              Algebraic Geometry       0.52      0.79      0.63      1005
Computer Science and Game Theory       0.00      0.00      0.00       273
             Galaxy Astrophysics       0.73      0.49      0.59       189
               General Economics       0.61      0.73      0.66      1714
      Image and Video Processing       0.00      0.00      0.00       106
                Machine Learning       0.42      0.48      0.45      1424
   Neural and Cognitive Modeling       0.44      0.16      0.24       486
                 Quantum Physics       0.18      0.02      0.04       385

                        accuracy                           0.52      5582
                       macro avg       0.36      0.34      0.33      5582
                    weighted avg       0.46      0.52      0.48      5582

</code></pre>
</div>
<div class="output stream stderr">
<pre><code>/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f&quot;{metric.capitalize()} is&quot;, len(result))
/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f&quot;{metric.capitalize()} is&quot;, len(result))
/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f&quot;{metric.capitalize()} is&quot;, len(result))
</code></pre>
</div>
</div>
<section id="33-baseline-model-comparisons" class="cell markdown"
id="8TJC-4WlEv_t">
<h2>3.3 Baseline Model Comparisons</h2>
<p>In section 3.3 I did a comparisons of the baseline between the TF-IDF
models, and this is the observations:</p>
<ul>
<li><p>Validation accuracy: essentially identical, 0.756 (Basic) vs
0.759 (K-Fold).</p></li>
<li><p>Macro-F1: similar, with the K-Fold mean slightly lower, 0.390
(Basic) vs 0.381 (K-Fold).</p></li>
<li><p>Per-class recall:</p>
<ul>
<li>Design Science / System Design: consistently high (at about 0.93
both).</li>
<li>Theoretical / Conceptual: comparable (at about 0.57 vs 0.59).</li>
<li>Mixed Methods: very low in both (at about 0.04 basic; 0.02
K-Fold).</li>
<li>Qualitative: 0.00 in both baselines.</li>
</ul></li>
</ul>
<p>The single-split and cross-validated baselines agree closely, so
either can serve as the TF-IDF reference in later sections. The patterns
also indicate which categories are well captured by bag-of-words
features (e.g., DS/SD) and which will likely benefit from more
expressive models, motivating the transformer experiments that
follow.</p>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:235}"
id="aNyhRVSw7kR5" data-outputId="2bdfb3c2-811b-49da-d667-9c33e65df6d1">
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Upload one or more CSVs</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> google.colab <span class="im">import</span> files</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>uploaded <span class="op">=</span> files.upload()</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Read and stack them</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>dfs <span class="op">=</span> [pd.read_csv(io.BytesIO(data)) <span class="cf">for</span> _, data <span class="kw">in</span> uploaded.items()]</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>table <span class="op">=</span> pd.concat(dfs, ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Display + save</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>display(table)</span></code></pre></div>
<div class="output display_data">

     <input type="file" id="files-974b777f-3395-46ec-a9d4-8dd0af78b608" name="files[]" multiple disabled
        style="border:none" />
     <output id="result-974b777f-3395-46ec-a9d4-8dd0af78b608">
      Upload widget is only available when the cell has been executed in the
      current browser session. Please rerun this cell to enable.
      </output>
      <script>// Copyright 2017 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

/**
 * @fileoverview Helpers for google.colab Python module.
 */
(function(scope) {
function span(text, styleAttributes = {}) {
  const element = document.createElement('span');
  element.textContent = text;
  for (const key of Object.keys(styleAttributes)) {
    element.style[key] = styleAttributes[key];
  }
  return element;
}

// Max number of bytes which will be uploaded at a time.
const MAX_PAYLOAD_SIZE = 100 * 1024;

function _uploadFiles(inputId, outputId) {
  const steps = uploadFilesStep(inputId, outputId);
  const outputElement = document.getElementById(outputId);
  // Cache steps on the outputElement to make it available for the next call
  // to uploadFilesContinue from Python.
  outputElement.steps = steps;

  return _uploadFilesContinue(outputId);
}

// This is roughly an async generator (not supported in the browser yet),
// where there are multiple asynchronous steps and the Python side is going
// to poll for completion of each step.
// This uses a Promise to block the python side on completion of each step,
// then passes the result of the previous step as the input to the next step.
function _uploadFilesContinue(outputId) {
  const outputElement = document.getElementById(outputId);
  const steps = outputElement.steps;

  const next = steps.next(outputElement.lastPromiseValue);
  return Promise.resolve(next.value.promise).then((value) => {
    // Cache the last promise value to make it available to the next
    // step of the generator.
    outputElement.lastPromiseValue = value;
    return next.value.response;
  });
}

/**
 * Generator function which is called between each async step of the upload
 * process.
 * @param {string} inputId Element ID of the input file picker element.
 * @param {string} outputId Element ID of the output display.
 * @return {!Iterable<!Object>} Iterable of next steps.
 */
function* uploadFilesStep(inputId, outputId) {
  const inputElement = document.getElementById(inputId);
  inputElement.disabled = false;

  const outputElement = document.getElementById(outputId);
  outputElement.innerHTML = '';

  const pickedPromise = new Promise((resolve) => {
    inputElement.addEventListener('change', (e) => {
      resolve(e.target.files);
    });
  });

  const cancel = document.createElement('button');
  inputElement.parentElement.appendChild(cancel);
  cancel.textContent = 'Cancel upload';
  const cancelPromise = new Promise((resolve) => {
    cancel.onclick = () => {
      resolve(null);
    };
  });

  // Wait for the user to pick the files.
  const files = yield {
    promise: Promise.race([pickedPromise, cancelPromise]),
    response: {
      action: 'starting',
    }
  };

  cancel.remove();

  // Disable the input element since further picks are not allowed.
  inputElement.disabled = true;

  if (!files) {
    return {
      response: {
        action: 'complete',
      }
    };
  }

  for (const file of files) {
    const li = document.createElement('li');
    li.append(span(file.name, {fontWeight: 'bold'}));
    li.append(span(
        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +
        `last modified: ${
            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :
                                    'n/a'} - `));
    const percent = span('0% done');
    li.appendChild(percent);

    outputElement.appendChild(li);

    const fileDataPromise = new Promise((resolve) => {
      const reader = new FileReader();
      reader.onload = (e) => {
        resolve(e.target.result);
      };
      reader.readAsArrayBuffer(file);
    });
    // Wait for the data to be ready.
    let fileData = yield {
      promise: fileDataPromise,
      response: {
        action: 'continue',
      }
    };

    // Use a chunked sending to avoid message size limits. See b/62115660.
    let position = 0;
    do {
      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);
      const chunk = new Uint8Array(fileData, position, length);
      position += length;

      const base64 = btoa(String.fromCharCode.apply(null, chunk));
      yield {
        response: {
          action: 'append',
          file: file.name,
          data: base64,
        },
      };

      let percentDone = fileData.byteLength === 0 ?
          100 :
          Math.round((position / fileData.byteLength) * 100);
      percent.textContent = `${percentDone}% done`;

    } while (position < fileData.byteLength);
  }

  // All done.
  yield {
    response: {
      action: 'complete',
    }
  };
}

scope.google = scope.google || {};
scope.google.colab = scope.google.colab || {};
scope.google.colab._files = {
  _uploadFiles,
  _uploadFilesContinue,
};
})(self);
</script> 
</div>
<div class="output stream stdout">
<pre><code>Saving tfidf_basic_methodology_metrics.csv to tfidf_basic_methodology_metrics (1).csv
Saving tfidf_kfold_methodology_metrics.csv to tfidf_kfold_methodology_metrics (1).csv
</code></pre>
</div>
<div class="output display_data">

  <div id="df-38437072-8a07-4517-bd6f-e097ec76815e" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>run</th>
      <th>val_acc</th>
      <th>macro_f1</th>
      <th>recall_Design_Science_/_System_Design</th>
      <th>recall_Mixed_Methods</th>
      <th>recall_Qualitative</th>
      <th>recall_Theoretical_/_Conceptual</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>TFIDF_basic</td>
      <td>0.756491</td>
      <td>0.390160</td>
      <td>0.934813</td>
      <td>0.044444</td>
      <td>0.0</td>
      <td>0.566102</td>
    </tr>
    <tr>
      <th>1</th>
      <td>TFIDF_kfold</td>
      <td>0.758689</td>
      <td>0.381373</td>
      <td>0.931408</td>
      <td>0.017778</td>
      <td>0.0</td>
      <td>0.591063</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-38437072-8a07-4517-bd6f-e097ec76815e')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-38437072-8a07-4517-bd6f-e097ec76815e button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-38437072-8a07-4517-bd6f-e097ec76815e');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    <div id="df-6fbcd9ba-4102-446a-8a9f-5f1cd2885c86">
      <button class="colab-df-quickchart" onclick="quickchart('df-6fbcd9ba-4102-446a-8a9f-5f1cd2885c86')"
                title="Suggest charts"
                style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
      </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

      <script>
        async function quickchart(key) {
          const quickchartButtonEl =
            document.querySelector('#' + key + ' button');
          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
          quickchartButtonEl.classList.add('colab-df-spinner');
          try {
            const charts = await google.colab.kernel.invokeFunction(
                'suggestCharts', [key], {});
          } catch (error) {
            console.error('Error during call to suggestCharts:', error);
          }
          quickchartButtonEl.classList.remove('colab-df-spinner');
          quickchartButtonEl.classList.add('colab-df-quickchart-complete');
        }
        (() => {
          let quickchartButtonEl =
            document.querySelector('#df-6fbcd9ba-4102-446a-8a9f-5f1cd2885c86 button');
          quickchartButtonEl.style.display =
            google.colab.kernel.accessAllowed ? 'block' : 'none';
        })();
      </script>
    </div>

  <div id="id_4a1edaf4-5e6a-410d-b7df-74016578f1c2">
    <style>
      .colab-df-generate {
        background-color: #E8F0FE;
        border: none;
        border-radius: 50%;
        cursor: pointer;
        display: none;
        fill: #1967D2;
        height: 32px;
        padding: 0 0 0 0;
        width: 32px;
      }

      .colab-df-generate:hover {
        background-color: #E2EBFA;
        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
        fill: #174EA6;
      }

      [theme=dark] .colab-df-generate {
        background-color: #3B4455;
        fill: #D2E3FC;
      }

      [theme=dark] .colab-df-generate:hover {
        background-color: #434B5C;
        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
        fill: #FFFFFF;
      }
    </style>
    <button class="colab-df-generate" onclick="generateWithVariable('table')"
            title="Generate code using this dataframe."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z"/>
  </svg>
    </button>
    <script>
      (() => {
      const buttonEl =
        document.querySelector('#id_4a1edaf4-5e6a-410d-b7df-74016578f1c2 button.colab-df-generate');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      buttonEl.onclick = () => {
        google.colab.notebook.generateWithVariable('table');
      }
      })();
    </script>
  </div>

    </div>
  </div>

</div>
</div>
<section id="4-transformer-based-models" class="cell markdown"
id="WTyzNI8tfsCO">
<h1>4. Transformer-Based Models</h1>
</section>
<section id="41-scibert-model-1" class="cell markdown"
id="PqkSvQpKPuXT">
<h2>4.1 SciBERT Model 1</h2>
<p>I set up SciBERT as a baseline transformer for methodology
classification using only standard choices, an 80/20 split (seed=42),
512-token context to avoid truncation confounds, AdamW (2e-5) with small
batches and gradient clipping, and a short 3-epoch run. Checkpoints were
picked by validation accuracy for stability, while macro-F1 and
per-class recall were logged for analysis and reuse in later plots.</p>
<p>On this minimal recipe the model reached val acc at about 0.82 and
macro-F1 at about 0.59. Recall was very strong for Design Science /
System Design ( at about 0.95) and Theoretical / Conceptual (at about
0.72), and lower for Mixed Methods (at about 0.35) and Qualitative (at
about 0.17). That pattern suggests SciBERT already captures
terminology-rich methodological cues, while categories whose signals are
more diffuse across the abstract remain harder.</p>
<p>What this leads to next. Building directly on this baseline, I
explore three focused SciBERT variants:</p>
<ul>
<li><p>C1 (baseline @ 256 tokens): halve the sequence length to check if
a shorter window maintains performance while improving
efficiency.</p></li>
<li><p>C2 (loss weights): test simple class weighting to see if minority
recalls rise monitoring for instability or overfitting
side-effects.</p></li>
<li><p>C3 (combo): combine the shorter context with light
warm-up/reshuffling and weights to probe whether gains compound or trade
off.</p></li>
</ul>
<p>These controlled changes keep the core model fixed and vary one or
two factors at a time, so any shifts in macro-F1 or per-class recall can
be attributed to the specific adjustment rather than a wholesale
reconfiguration.</p>
</section>
<section id="setup-and-labelling" class="cell markdown"
id="mOl_8usNhRyg">
<h3>Setup and Labelling</h3>
<p>I fix the random seed across NumPy and PyTorch to make runs
comparable, without this, small sampling differences in a modest dataset
can shift validation metrics enough to obscure design effects. I then
isolate the methodology task as a single-label classification problem
and map textual classes to integers via a LabelEncoder. It also allows
me to compare like-for-like with the TF-IDF baselines.</p>
<p>This is done because Methodology is the most semantically subtle of
the three label families (discipline, subfield, methodology). If a model
captures this well, it is usually strong elsewhere. Encoding once here
also standardises label order, which is essential when logging per-class
metrics to CSV for later plots.</p>
</section>
<div class="cell code" id="TPUFancng2Jf">
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> set_seed(seed<span class="op">=</span><span class="dv">42</span>):</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>    random.seed(seed)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>    np.random.seed(seed)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>    torch.manual_seed(seed)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    torch.cuda.manual_seed_all(seed)</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>set_seed(<span class="dv">42</span>)</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Reset index to get a unique identifier for each row</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>df_m <span class="op">=</span> df[df[<span class="st">&#39;methodology&#39;</span>].notnull()].copy().reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Add an &#39;orig_idx&#39; column to keep track of the original row index</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>df_m[<span class="st">&#39;orig_idx&#39;</span>] <span class="op">=</span> df_m.index</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>le <span class="op">=</span> LabelEncoder()</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>df_m[<span class="st">&#39;label&#39;</span>] <span class="op">=</span> le.fit_transform(df_m[<span class="st">&#39;methodology&#39;</span>])</span></code></pre></div>
</div>
<section id="tokenisation-and-data-loaders" class="cell markdown"
id="VXxDHUnbhiH7">
<h3>Tokenisation and Data Loaders</h3>
<p>I wrap the subset in a Hugging Face Dataset and make an 80/20 split
with a fixed seed so later transformer variants are measured on the same
validation fold. Tokenisation uses allenai/scibert_scivocab_uncased at
512 tokens with max-length padding. That length covers the vast majority
of abstracts in my corpus and lets the model attend across longer,
multi-clause sentences typical in academic prose.</p>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:269,&quot;referenced_widgets&quot;:[&quot;d587d9fbe3b34e2194957f7f7c473a03&quot;,&quot;f6974d03d3bc45b7868cb1b5d642caea&quot;,&quot;2f5ec4b6438647bda6b1ff558af103ab&quot;,&quot;e404e4f16e264fb8913bf6fb40ad143f&quot;,&quot;2edff39888d346278afb077659e589f1&quot;,&quot;85f97abbe9584dee8d7cac9db5506d51&quot;,&quot;1a4576f9f43d44609c7c0ab536424f6d&quot;,&quot;2bba61d34e3b4cac8152f852b5016b6c&quot;,&quot;989f7a41f8c44cd29e35bb46d9730f36&quot;,&quot;a3d6008d4b0643a5a7f87d22b6acd40c&quot;,&quot;3ee0ba28ab0f41979e9f6a7ec33a9f33&quot;,&quot;cb9aa607e3a84c7787935d5f2572f01b&quot;,&quot;de3e5d91d15d418aa218fc23a42acc88&quot;,&quot;df95721c359a46c8a885e094e11c76be&quot;,&quot;5126693edd1b4fc592023f11cf02f031&quot;,&quot;2899ca3d0aba4bc38ede9b40dcf85ef5&quot;,&quot;5fb4253829bc4f83a7415e0cf32e18e7&quot;,&quot;5346ffd350f34375adb9ceff260ffc68&quot;,&quot;45d2482bc37c43f3b861d317baa7379f&quot;,&quot;d08b0386c1934b3faac1faa4e5f36fe0&quot;,&quot;902826b3cf7d4fb18ab397a3b1d7ec79&quot;,&quot;eda255527f764b69affca550c6a2f992&quot;,&quot;d2302dd9f0bf45b4b79d657573fe64a7&quot;,&quot;2b7b8412afe741e5a7321ed56c7fcff4&quot;,&quot;7b55bb49d9a24d3d8b6b6372837714e5&quot;,&quot;934a0ddba32747f4887b46d2385b5740&quot;,&quot;9be39d84188344db8150f63e03257a10&quot;,&quot;e05101c0c42f4de88278712eb8ec126f&quot;,&quot;bd51a1308ad3436d80ff9c4427bdb977&quot;,&quot;86c5526df7be48179d8a7ad64d891744&quot;,&quot;fb3ef12d6a194d79873a7c72a96b207e&quot;,&quot;f9d48a55b7a0477aa47bce2ec5527e40&quot;,&quot;50ffbb7c79d945c3989897a6acc05dc6&quot;,&quot;1735b7002f7e4c288dbcf875ce72ca33&quot;,&quot;ecae94b43f3b4c5bbd5b7187d0766b63&quot;,&quot;c6a390a2689e401abb10063a47c52f80&quot;,&quot;e21b86c137bd4a239cf42698ad265645&quot;,&quot;dfd6d7db269f42ecb24580ea98ce3153&quot;,&quot;70205f6fc62f4327aeef538fd0ebdcda&quot;,&quot;e2c6b90bb0224dcd9e06b540702c697d&quot;,&quot;085f71cfebe7496e868f23d72d03df6e&quot;,&quot;e1cc978aa21a4869a643b77d9b51ce12&quot;,&quot;de8f5d69fe6a4b8eb06d4d15cc9eca0f&quot;,&quot;f809b6080bd34405bda6de1c3eb6b50b&quot;]}"
id="LupqMgochg_U" data-outputId="80bc718f-4d62-4194-d5dd-a54e414f1608">
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Hugging Face Dataset and split</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> Dataset.from_pandas(df_m[[<span class="st">&#39;processed_with_stopwords&#39;</span>, <span class="st">&#39;label&#39;</span>, <span class="st">&#39;orig_idx&#39;</span>]])</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> dataset.train_test_split(test_size<span class="op">=</span><span class="fl">0.2</span>, seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> dataset[<span class="st">&quot;train&quot;</span>], dataset[<span class="st">&quot;test&quot;</span>]</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Tokenisation</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>model_name <span class="op">=</span> <span class="st">&quot;allenai/scibert_scivocab_uncased&quot;</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_name)</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tokenize(example):</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tokenizer(</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>        example[<span class="st">&#39;processed_with_stopwords&#39;</span>],</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>        truncation<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>        padding<span class="op">=</span><span class="st">&quot;max_length&quot;</span>,</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>        max_length<span class="op">=</span><span class="dv">512</span></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>train_ds <span class="op">=</span> train_ds.<span class="bu">map</span>(tokenize, batched<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>val_ds   <span class="op">=</span> val_ds.<span class="bu">map</span>(tokenize,   batched<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Set format for PyTorch</span></span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>cols <span class="op">=</span> [<span class="st">&quot;input_ids&quot;</span>, <span class="st">&quot;attention_mask&quot;</span>, <span class="st">&quot;label&quot;</span>, <span class="st">&quot;orig_idx&quot;</span>]</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>train_ds.set_format(<span class="bu">type</span><span class="op">=</span><span class="st">&quot;torch&quot;</span>, columns<span class="op">=</span>cols)</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>val_ds.set_format(<span class="bu">type</span><span class="op">=</span><span class="st">&quot;torch&quot;</span>,   columns<span class="op">=</span>cols)</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a><span class="co"># DataLoaders</span></span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(train_ds, batch_size<span class="op">=</span><span class="dv">4</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>val_loader   <span class="op">=</span> DataLoader(val_ds,   batch_size<span class="op">=</span><span class="dv">4</span>, shuffle<span class="op">=</span><span class="va">False</span>)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: 
The secret `HF_TOKEN` does not exist in your Colab secrets.
To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.
You will be able to reuse this secret in all of your notebooks.
Please note that authentication is recommended but still optional to access public models or datasets.
  warnings.warn(
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb23"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;d587d9fbe3b34e2194957f7f7c473a03&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb24"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;cb9aa607e3a84c7787935d5f2572f01b&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb25"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;d2302dd9f0bf45b4b79d657573fe64a7&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb26"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;1735b7002f7e4c288dbcf875ce72ca33&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
</div>
<section id="training-and-validation-loop" class="cell markdown"
id="Uo0CMEwJhmr-">
<h3>Training and Validation Loop</h3>
<p>I fine-tune AutoModelForSequenceClassification with AdamW (lr=2e-5)
and batch size 4. The batch size is a memory-constrained choice common
with 512-token sequences; AdamW with a low learning rate is the standard
recipe for stable BERT-family optimisation. I clip gradients at 1.0 to
prevent rare but harmful spikes when the classifier head is still
“cold”.</p>
<p>I keep training short (3 epochs) and track the best checkpoint by
validation accuracy each epoch. With relatively few labelled examples,
long schedules tend to overfit the idiosyncrasies of the split,
selecting the best epoch acts as a light form of early stopping.</p>
<p>The selection metric needs to be low-variance and monotone with
“general goodness” to avoid bouncing between epochs. Accuracy is more
stable than macro-F1 on small classes (e.g., Qualitative), so I use it
for checkpoint selection; macro-F1 and per-class recall are still
computed and logged for analysis and decision-making.</p>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:188,&quot;referenced_widgets&quot;:[&quot;9a37192d701f426188191479f5038ccf&quot;,&quot;cf7f949db372469a961887cb13349d84&quot;,&quot;59a1bdfdfb7e4a5d95a64908865922ae&quot;,&quot;3f5645f7cac94d0aad44386bde3529c2&quot;,&quot;b2ca99efc4b445c38412c665c2913ffe&quot;,&quot;250ea2c8cf004c009b5bf58b9dc05a9f&quot;,&quot;654534faf0e14335b53ceda125ca3426&quot;,&quot;c267cdeedeb14cde8387fde878f7a3e5&quot;,&quot;f4bb62b32fc742c690ffbd621baa835b&quot;,&quot;5f88ca69859e4f538f825c2a669bcd3c&quot;,&quot;7ef4ce6ad97a4c589dfa5c260559d3a7&quot;,&quot;8d7e4a772a3b4b2f8894106f4700ba66&quot;,&quot;a34540c3dcd24fedb91c6181b3ecc529&quot;,&quot;4e9c399a360d4910bebc4266619acbde&quot;,&quot;a52c5244d75e46a3bb222d847d3eddb8&quot;,&quot;6ed3bd84bdc34f64944c299e1c29a969&quot;,&quot;6e13314321f5410290554b7b8cffe091&quot;,&quot;8454b78d515e44d8b052f90d08faba3c&quot;,&quot;1140bf532f5a4c2bbbc0c277c1dbd7ff&quot;,&quot;0c159a9fa8aa42fcb649e54c6bf2f6e4&quot;,&quot;fe9ccf9fe11c408fa8fa42672c438841&quot;,&quot;50961bf8d78d4391957efae9eba3dfcd&quot;]}"
id="jPtfSziqhm3f" data-outputId="6e24d339-58fa-4a23-a516-18359cb99ef4">
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Model / Optimiser</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">&quot;cuda&quot;</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">&quot;cpu&quot;</span>)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="co"># device = torch.device(&quot;cpu&quot;)</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>    model_name, num_labels<span class="op">=</span><span class="bu">len</span>(le.classes_)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>).to(device)</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> AdamW(model.parameters(), lr<span class="op">=</span><span class="fl">2e-5</span>)</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Training + Validation</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>best_val_acc <span class="op">=</span> <span class="op">-</span><span class="fl">1.0</span></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>best_state <span class="op">=</span> <span class="va">None</span></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, epochs <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>    train_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch <span class="kw">in</span> train_loader:</span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>        batch <span class="op">=</span> {k: v.to(device) <span class="cf">for</span> k, v <span class="kw">in</span> batch.items()}</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> model(</span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a>            input_ids<span class="op">=</span>batch[<span class="st">&quot;input_ids&quot;</span>],</span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>            attention_mask<span class="op">=</span>batch[<span class="st">&quot;attention_mask&quot;</span>],</span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>            labels<span class="op">=</span>batch[<span class="st">&quot;label&quot;</span>]</span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> outputs.loss</span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a>        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a>        train_loss <span class="op">+=</span> loss.item()</span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a>    avg_train_loss <span class="op">=</span> train_loss <span class="op">/</span> <span class="bu">len</span>(train_loader)</span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a>    val_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a>    val_preds, val_labels <span class="op">=</span> [], []</span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb27-39"><a href="#cb27-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> batch <span class="kw">in</span> val_loader:</span>
<span id="cb27-40"><a href="#cb27-40" aria-hidden="true" tabindex="-1"></a>            batch <span class="op">=</span> {k: v.to(device) <span class="cf">for</span> k, v <span class="kw">in</span> batch.items()}</span>
<span id="cb27-41"><a href="#cb27-41" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> model( input_ids<span class="op">=</span>batch[<span class="st">&quot;input_ids&quot;</span>], attention_mask<span class="op">=</span>batch[<span class="st">&quot;attention_mask&quot;</span>],</span>
<span id="cb27-42"><a href="#cb27-42" aria-hidden="true" tabindex="-1"></a>                            labels<span class="op">=</span>batch[<span class="st">&quot;label&quot;</span>])</span>
<span id="cb27-43"><a href="#cb27-43" aria-hidden="true" tabindex="-1"></a>            val_loss <span class="op">+=</span> outputs.loss.item()</span>
<span id="cb27-44"><a href="#cb27-44" aria-hidden="true" tabindex="-1"></a>            preds <span class="op">=</span> torch.argmax(outputs.logits, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb27-45"><a href="#cb27-45" aria-hidden="true" tabindex="-1"></a>            val_preds.extend(preds.cpu().numpy())</span>
<span id="cb27-46"><a href="#cb27-46" aria-hidden="true" tabindex="-1"></a>            val_labels.extend(batch[<span class="st">&quot;label&quot;</span>].cpu().numpy())</span>
<span id="cb27-47"><a href="#cb27-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-48"><a href="#cb27-48" aria-hidden="true" tabindex="-1"></a>    avg_val_loss <span class="op">=</span> val_loss <span class="op">/</span> <span class="bu">len</span>(val_loader)</span>
<span id="cb27-49"><a href="#cb27-49" aria-hidden="true" tabindex="-1"></a>    val_acc <span class="op">=</span> accuracy_score(val_labels, val_preds)</span>
<span id="cb27-50"><a href="#cb27-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-51"><a href="#cb27-51" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> val_acc <span class="op">&gt;</span> best_val_acc:</span>
<span id="cb27-52"><a href="#cb27-52" aria-hidden="true" tabindex="-1"></a>        best_val_acc <span class="op">=</span> val_acc</span>
<span id="cb27-53"><a href="#cb27-53" aria-hidden="true" tabindex="-1"></a>        best_state <span class="op">=</span> {k: v.detach().cpu().clone() <span class="cf">for</span> k, v <span class="kw">in</span> model.state_dict().items()}</span>
<span id="cb27-54"><a href="#cb27-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-55"><a href="#cb27-55" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Epoch </span><span class="sc">{</span>epoch<span class="sc">:02d}</span><span class="ss"> | train_loss: </span><span class="sc">{</span>avg_train_loss<span class="sc">:.4f}</span><span class="ss"> | &quot;</span></span>
<span id="cb27-56"><a href="#cb27-56" aria-hidden="true" tabindex="-1"></a>          <span class="ss">f&quot;val_loss: </span><span class="sc">{</span>avg_val_loss<span class="sc">:.4f}</span><span class="ss"> | val_acc: </span><span class="sc">{</span>val_acc<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb28"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;9a37192d701f426188191479f5038ccf&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb29"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;8d7e4a772a3b4b2f8894106f4700ba66&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: [&#39;classifier.bias&#39;, &#39;classifier.weight&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Epoch 01 | train_loss: 0.7739 | val_loss: 0.6848 | val_acc: 0.7905
Epoch 02 | train_loss: 0.6327 | val_loss: 0.8851 | val_acc: 0.7995
Epoch 03 | train_loss: 0.5445 | val_loss: 0.7035 | val_acc: 0.8201
</code></pre>
</div>
</div>
<section id="evaluation-and-summary" class="cell markdown"
id="jwpwLhZahtnZ">
<h3>Evaluation and Summary</h3>
<p>Validation accuracy at about 0.820; macro-F1 at about 0.59. Per-class
recall shows strong performance on Design Science/System Design (at
about 0.95) and Theoretical/Conceptual (at about 0.72), moderate on
Mixed Methods (at about 0.35), and lower on Qualitative (at about 0.17).
These results substantially outperform the TF-IDF baselines and
establish SciBERT as a strong candidate architecture for subsequent
extensions and the multi-label pipeline.</p>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="TbOzcGeHhtzS" data-outputId="7c612d19-595d-44a3-9aa9-0741952bd000">
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load best model state</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> best_state <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>    model.load_state_dict(best_state)</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluation</span></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>preds, labels <span class="op">=</span> [], []</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch <span class="kw">in</span> val_loader:</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>        batch <span class="op">=</span> {k: v.to(device) <span class="cf">for</span> k, v <span class="kw">in</span> batch.items()}</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> model(</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a>            input_ids<span class="op">=</span>batch[<span class="st">&quot;input_ids&quot;</span>],</span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>            attention_mask<span class="op">=</span>batch[<span class="st">&quot;attention_mask&quot;</span>]</span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>        ).logits</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>        predictions <span class="op">=</span> torch.argmax(logits, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a>        preds.extend(predictions.cpu().numpy())</span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>        labels.extend(batch[<span class="st">&quot;label&quot;</span>].cpu().numpy())</span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Validation accuracy:&quot;</span>, accuracy_score(labels, preds))</span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(labels, preds, target_names<span class="op">=</span>le.classes_))</span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Summary Table</span></span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a>val_acc <span class="op">=</span> accuracy_score(labels, preds)</span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a>report <span class="op">=</span> classification_report(labels, preds, target_names<span class="op">=</span>le.classes_, output_dict<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a>row <span class="op">=</span> {</span>
<span id="cb32-27"><a href="#cb32-27" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;run&quot;</span>: <span class="st">&quot;scibert_base_methodology_1run_len512&quot;</span>,</span>
<span id="cb32-28"><a href="#cb32-28" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;max_len&quot;</span>: <span class="dv">512</span>,</span>
<span id="cb32-29"><a href="#cb32-29" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;lr&quot;</span>: <span class="fl">2e-5</span>,</span>
<span id="cb32-30"><a href="#cb32-30" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;train_loss&quot;</span>: avg_train_loss,</span>
<span id="cb32-31"><a href="#cb32-31" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;val_loss&quot;</span>: avg_val_loss,</span>
<span id="cb32-32"><a href="#cb32-32" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;val_acc&quot;</span>: val_acc,</span>
<span id="cb32-33"><a href="#cb32-33" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;macro_f1&quot;</span>: report[<span class="st">&quot;macro avg&quot;</span>][<span class="st">&quot;f1-score&quot;</span>]</span>
<span id="cb32-34"><a href="#cb32-34" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb32-35"><a href="#cb32-35" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> label <span class="kw">in</span> le.classes_:</span>
<span id="cb32-36"><a href="#cb32-36" aria-hidden="true" tabindex="-1"></a>    row[<span class="ss">f&quot;recall_</span><span class="sc">{</span>label<span class="sc">.</span>replace(<span class="st">&#39; &#39;</span>, <span class="st">&#39;_&#39;</span>)<span class="sc">}</span><span class="ss">&quot;</span>] <span class="op">=</span> report[label][<span class="st">&quot;recall&quot;</span>]</span>
<span id="cb32-37"><a href="#cb32-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-38"><a href="#cb32-38" aria-hidden="true" tabindex="-1"></a>df_summary <span class="op">=</span> pd.DataFrame([row])</span>
<span id="cb32-39"><a href="#cb32-39" aria-hidden="true" tabindex="-1"></a>csv_name <span class="op">=</span> <span class="ss">f&quot;scibert_methodology_1run_summary_len</span><span class="sc">{</span><span class="dv">512</span><span class="sc">}</span><span class="ss">.csv&quot;</span></span>
<span id="cb32-40"><a href="#cb32-40" aria-hidden="true" tabindex="-1"></a>df_summary.to_csv(csv_name, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb32-41"><a href="#cb32-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;</span><span class="ch">\n</span><span class="ss">Saved CSV summary to: </span><span class="sc">{</span>csv_name<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>
Validation accuracy: 0.8200537153088631
                                precision    recall  f1-score   support

Design Science / System Design       0.84      0.95      0.89       685
                 Mixed Methods       0.63      0.35      0.45        94
                   Qualitative       0.75      0.17      0.27        18
      Theoretical / Conceptual       0.80      0.72      0.76       320

                      accuracy                           0.82      1117
                     macro avg       0.76      0.55      0.59      1117
                  weighted avg       0.81      0.82      0.81      1117


Saved CSV summary to: scibert_methodology_1run_summary_len512.csv
</code></pre>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:17}"
id="dsPAcLu9T0TV" data-outputId="f3457df0-b411-4b08-a24e-72f7b2198b01">
<div class="sourceCode" id="cb34"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Save trained model state</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>torch.save(best_state, <span class="st">&quot;scibert_methodology_best_state.pt&quot;</span>)</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> google.colab <span class="im">import</span> files</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>files.download(<span class="st">&quot;scibert_methodology_best_state.pt&quot;</span>)</span></code></pre></div>
<div class="output display_data">
<pre><code>&lt;IPython.core.display.Javascript object&gt;</code></pre>
</div>
<div class="output display_data">
<pre><code>&lt;IPython.core.display.Javascript object&gt;</code></pre>
</div>
</div>
<section id="411-tools-for-investigative-study" class="cell markdown"
id="GBunI758MLbI">
<h3>4.1.1 Tools for Investigative Study</h3>
<p>This portion is done in Jupyter Notebook, because processing using
Colab's CPU for the LIME tool keeps breaking (it could not perform in
the allocated CPU), so I used Jupyter Notebook to run locally and used
my own CPU which worked.</p>
<p>Please refer to tools_for_colab.ipynb, in the notebook, you'll find
the contents covering:</p>
<ul>
<li>loading the saved SciBERT Model 1 for the LIME tool</li>
<li>token length distribution, this discovered that majority of samples
fall well below the 256-token threshold, with only 9.48% exceeding 256
tokens and 0.02% exceeding the 512 tokens. Hence, a maximum sequence
length of 256 tokens would be a suitable and efficient truncation
threshold for downstream model training and LIME explanations.</li>
<li>applying LIME tool for interpretability, which treats the model as a
black box and perturbs the input text to learn the most influential
tokens for prediction.</li>
<li>extracted the top 10 most important keywords (NUM_FEATURES) from
each sample and tracked both:
<ul>
<li>How often each keyword appeared across samples per methodology
label.</li>
<li>The cumulative importance weight (magnitude of influence) for each
keyword.</li>
</ul></li>
<li>harvested a large number of research papers from the arXiv API</li>
<li>lightweight rule-based classifier to predict the methodology of
papers based solely on keyword presence in the abstract text</li>
</ul>
</section>
<section id="42-scibert-extended-models-c1-c2-c3" class="cell markdown"
id="i6sc_RHUQVzQ">
<h2>4.2 SciBERT Extended Models (C1, C2, C3)</h2>
<p>After establishing that SciBERT works well on the methodology task at
512 tokens, I re-ran it at 256 tokens (supported by my token-length
study) and systematically varied how the model “sees” minority classes.
The question was simple: can I gain recall on the hard classes (Mixed
Methods, Qualitative) without collapsing overall performance? To probe
that, I changed only the data/optimisation bias, not the
architecture.</p>
<p>Setup:</p>
<ul>
<li><p>C1: baseline @256 Plain fine-tuning (cross-entropy with label
smoothing 0.05), no sampler, no class weights, no warm-up. This is the
control run: how good is SciBERT when I don’t force any class
rebalancing?</p></li>
<li><p>C2: class weights only Same setup, but the loss is weighted
inversely to class frequency. This directly punishes mistakes on rare
classes more heavily. The intent is to push the optimiser to “care”
about Qualitative and Mixed Methods even when they are scarce in each
batch.</p></li>
<li><p>C3: sampler + class weights + warm-up A WeightedRandomSampler
that over-samples minority labels (tempering with an α exponent and a
cap to avoid degenerate batches), and the same class-weighted loss. I
also add a 10% linear warm-up to avoid large early steps when the head
is randomly initialised. This combination tries to fix both what the
model sees (batch composition) and how it learns from it (loss
geometry).</p></li>
</ul>
<p>Observation:</p>
<ul>
<li><p>C1 maintains strong recall on the majority class Design
Science/System Design (at about 0.91) and reasonable
Theoretical/Conceptual (at about 0.70), but it collapses on Qualitative
(at 0). This indicates the backbone learns the dominant signal well but
under-trains minority labels.</p></li>
<li><p>C2 pushes attention toward the minorities: Qualitative rises (at
about 0.50) and Mixed Methods stays comparable, yet the price is a large
drop on the majority class (DS/SD at about 0.34) and overall
reliability.</p></li>
<li><p>C3 lands between them: Mixed Methods improves further (at about
0.57) and Qualitative becomes usable (at about 0.44) while majority
performance remains acceptable (DS/SD at about 0.77). Macro-F1 is the
best of the three at 256 tokens, showing a more even treatment of all
labels without a severe collapse elsewhere.</p></li>
</ul>
<p>These runs confirm two things. First, 256 tokens is a safe operating
point for SciBERT on abstracts. Second, biasing the learner (via weights
and sampling) can recover minority recall but can’t remove the gap
without denting majority stability. That suggests the limit is
representational rather than purely optimisation-related. I therefore
keep the controls fixed (256 tokens, same split, early stopping) and
advance to compare pretraining regimes, RoBERTa for potentially stronger
general-text representations and DistilBERT to map the efficiency
frontier, before deciding which family to carry into the multi-label
pipeline.</p>
</section>
<section id="set-up-and-utilities" class="cell markdown"
id="F8bRZkboXP8_">
<h3>Set Up and Utilities</h3>
<p>I lock the random seed across NumPy and PyTorch so that every variant
runs on the same stochastic footing. The RunConfig dataclass pins down
everything that must stay constant across runs (model name, sequence
length 256, batch size, optimiser, patience) and exposes only the levers
I want to study: a class-weighted loss, a weighted sampler, and a brief
linear warm-up. Keeping these options explicit prevents “silent” changes
between experiments and lets me attribute differences in recall to the
biasing strategy rather than to hidden defaults. I also keep label
smoothing at 0.05 to discourage over-confident logits on rare classes
without changing the task into a different objective.</p>
</section>
<div class="cell code" id="KYxFr9oOQZ-M">
<div class="sourceCode" id="cb37"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> set_seed(seed<span class="op">=</span><span class="dv">42</span>):</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>    random.seed(seed)<span class="op">;</span> np.random.seed(seed)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>    torch.manual_seed(seed)<span class="op">;</span> torch.cuda.manual_seed_all(seed)</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>set_seed(<span class="dv">42</span>)</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a><span class="at">@dataclass</span></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> RunConfig:</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>    name: <span class="bu">str</span></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>    model_name: <span class="bu">str</span> <span class="op">=</span> <span class="st">&quot;allenai/scibert_scivocab_uncased&quot;</span></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>    max_len: <span class="bu">int</span> <span class="op">=</span> <span class="dv">256</span></span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>    batch_size: <span class="bu">int</span> <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>    lr: <span class="bu">float</span> <span class="op">=</span> <span class="fl">2e-5</span></span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>    weight_decay: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>    epochs: <span class="bu">int</span> <span class="op">=</span> <span class="dv">6</span></span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a>    patience: <span class="bu">int</span> <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>    label_smoothing: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.05</span></span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a>    use_sampler: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span></span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a>    sampler_alpha: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a>    sampler_cap: <span class="bu">float</span> <span class="op">=</span> <span class="fl">8.0</span></span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a>    use_loss_weights: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span></span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a>    warmup_frac: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a>    device: <span class="bu">str</span> <span class="op">=</span> <span class="st">&quot;cuda&quot;</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">&quot;cpu&quot;</span></span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true" tabindex="-1"></a>    num_workers: <span class="bu">int</span> <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb37-25"><a href="#cb37-25" aria-hidden="true" tabindex="-1"></a>    pin_memory: <span class="bu">bool</span> <span class="op">=</span> <span class="va">True</span></span></code></pre></div>
</div>
<section id="tokenisation" class="cell markdown" id="mzzuJvcsXXFh">
<h3>Tokenisation</h3>
<p>I tokenised and build DataLoaders for the fixed 80/20 split. The
loader exposes two rebalancing mechanisms, applied per run as
follows:</p>
<ul>
<li>Class-weighted CrossEntropy, used in C2 and C3 to up-weight rare
classes in the loss.</li>
<li>WeightedRandomSampler, used in C3 only to over-sample minority
labels in batches.</li>
</ul>
<p>Label smoothing (0.05) is on in all C-runs to discourage
over-confident logits on scarce classes. Linear warm-up (10%) is used
only in C3 to stabilise early updates.</p>
</section>
<div class="cell code" id="kmRsfGcDXdP-">
<div class="sourceCode" id="cb38"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _tok_fn(tokenizer, max_len):</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _inner(ex):</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> tokenizer(ex[<span class="st">&quot;processed_with_stopwords&quot;</span>], truncation<span class="op">=</span><span class="va">True</span>, padding<span class="op">=</span><span class="st">&quot;max_length&quot;</span>, max_length<span class="op">=</span>max_len)</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> _inner</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_loaders(train_ds, val_ds, cfg: RunConfig, tokenizer, num_classes: <span class="bu">int</span>):</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>    train_tok <span class="op">=</span> train_ds.<span class="bu">map</span>(_tok_fn(tokenizer, cfg.max_len), batched<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>    val_tok   <span class="op">=</span> val_ds.<span class="bu">map</span>(_tok_fn(tokenizer, cfg.max_len),   batched<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>    cols <span class="op">=</span> [<span class="st">&quot;input_ids&quot;</span>,<span class="st">&quot;attention_mask&quot;</span>,<span class="st">&quot;label&quot;</span>]</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>    train_tok.set_format(<span class="bu">type</span><span class="op">=</span><span class="st">&quot;torch&quot;</span>, columns<span class="op">=</span>cols)</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>    val_tok.set_format(<span class="bu">type</span><span class="op">=</span><span class="st">&quot;torch&quot;</span>,   columns<span class="op">=</span>cols)</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> cfg.use_sampler:</span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>        train_labels <span class="op">=</span> np.array(train_tok[<span class="st">&quot;label&quot;</span>])</span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a>        class_counts <span class="op">=</span> np.bincount(train_labels, minlength<span class="op">=</span>num_classes)</span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>        class_counts[class_counts <span class="op">==</span> <span class="dv">0</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>        w_class <span class="op">=</span> <span class="fl">1.0</span> <span class="op">/</span> np.power(class_counts.astype(np.float64), cfg.sampler_alpha)</span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a>        w_class <span class="op">=</span> w_class <span class="op">/</span> w_class.mean()</span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a>        w_class <span class="op">=</span> np.minimum(w_class, cfg.sampler_cap)</span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a>        sample_weights <span class="op">=</span> w_class[train_labels]</span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a>        sampler <span class="op">=</span> WeightedRandomSampler(sample_weights, num_samples<span class="op">=</span><span class="bu">len</span>(sample_weights), replacement<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a>        train_loader <span class="op">=</span> DataLoader(train_tok, batch_size<span class="op">=</span>cfg.batch_size, sampler<span class="op">=</span>sampler,</span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a>                                  num_workers<span class="op">=</span>cfg.num_workers, pin_memory<span class="op">=</span>cfg.pin_memory)</span>
<span id="cb38-24"><a href="#cb38-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb38-25"><a href="#cb38-25" aria-hidden="true" tabindex="-1"></a>        train_loader <span class="op">=</span> DataLoader(train_tok, batch_size<span class="op">=</span>cfg.batch_size, shuffle<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb38-26"><a href="#cb38-26" aria-hidden="true" tabindex="-1"></a>                                  num_workers<span class="op">=</span>cfg.num_workers, pin_memory<span class="op">=</span>cfg.pin_memory)</span>
<span id="cb38-27"><a href="#cb38-27" aria-hidden="true" tabindex="-1"></a>    val_loader <span class="op">=</span> DataLoader(val_tok, batch_size<span class="op">=</span>cfg.batch_size, shuffle<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb38-28"><a href="#cb38-28" aria-hidden="true" tabindex="-1"></a>                            num_workers<span class="op">=</span>cfg.num_workers, pin_memory<span class="op">=</span>cfg.pin_memory)</span>
<span id="cb38-29"><a href="#cb38-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> train_loader, val_loader</span>
<span id="cb38-30"><a href="#cb38-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-31"><a href="#cb38-31" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_loss(cfg: RunConfig, train_loader, num_classes: <span class="bu">int</span>):</span>
<span id="cb38-32"><a href="#cb38-32" aria-hidden="true" tabindex="-1"></a>    weight <span class="op">=</span> <span class="va">None</span></span>
<span id="cb38-33"><a href="#cb38-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> cfg.use_loss_weights:</span>
<span id="cb38-34"><a href="#cb38-34" aria-hidden="true" tabindex="-1"></a>        labels <span class="op">=</span> np.array(train_loader.dataset[<span class="st">&quot;label&quot;</span>])</span>
<span id="cb38-35"><a href="#cb38-35" aria-hidden="true" tabindex="-1"></a>        counts <span class="op">=</span> np.bincount(labels, minlength<span class="op">=</span>num_classes)</span>
<span id="cb38-36"><a href="#cb38-36" aria-hidden="true" tabindex="-1"></a>        counts[counts <span class="op">==</span> <span class="dv">0</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb38-37"><a href="#cb38-37" aria-hidden="true" tabindex="-1"></a>        raw_w  <span class="op">=</span> (<span class="bu">len</span>(labels) <span class="op">/</span> (num_classes <span class="op">*</span> counts.astype(np.float64)))</span>
<span id="cb38-38"><a href="#cb38-38" aria-hidden="true" tabindex="-1"></a>        norm_w <span class="op">=</span> raw_w <span class="op">/</span> raw_w.mean()</span>
<span id="cb38-39"><a href="#cb38-39" aria-hidden="true" tabindex="-1"></a>        weight <span class="op">=</span> torch.tensor(norm_w, dtype<span class="op">=</span>torch.<span class="bu">float</span>, device<span class="op">=</span>cfg.device)</span>
<span id="cb38-40"><a href="#cb38-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb38-41"><a href="#cb38-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> nn.CrossEntropyLoss(weight<span class="op">=</span>weight, label_smoothing<span class="op">=</span>cfg.label_smoothing)</span>
<span id="cb38-42"><a href="#cb38-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">TypeError</span>:</span>
<span id="cb38-43"><a href="#cb38-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> nn.CrossEntropyLoss(weight<span class="op">=</span>weight)</span></code></pre></div>
</div>
<section id="c1-c2-c3-models-runner" class="cell markdown"
id="9xrr0ORKXsDT">
<h3>C1, C2, C3 models runner</h3>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:755,&quot;referenced_widgets&quot;:[&quot;3198d7d72fa74c76b777f48f215606ef&quot;,&quot;6106d0e3f71f439fbe28a3cc15bd93b2&quot;,&quot;6c63f9d7b20b40d68e97e635ae06f82b&quot;,&quot;148293fbbc87449bb52de22ca931970d&quot;,&quot;059835970acb4875919216ba78bd3a0d&quot;,&quot;f0593390b68246ed9375d251148a846b&quot;,&quot;b790172270da4498ad09166df34ef2b6&quot;,&quot;793d841b5815473c8c63d49735a71e22&quot;,&quot;0acb6f2faf134660838afd88f47bbaa0&quot;,&quot;519699f34fe24c6c968aac1e880b4116&quot;,&quot;524511b816354ab2b848875f141201da&quot;,&quot;93c03620288d426f83e551a04a2d7948&quot;,&quot;89707de142a9424e825e8ca446b9c60d&quot;,&quot;85340aaad6e4468cbb519362a7bd7a9c&quot;,&quot;12df6b4ce2844cdf81a8b66627377dd4&quot;,&quot;457fa6a59b1d4340be3450c0e9086ef2&quot;,&quot;09b92d58e27d47aaa33084750fa408d0&quot;,&quot;f6fa35f6383843adb0afd0c59c761cf2&quot;,&quot;3f0eb701ce914a1b980c1360ba51853d&quot;,&quot;d0e29342e54147ada78f220123c1835a&quot;,&quot;d5ecba850d1a47079bbd0af834f70c69&quot;,&quot;ec79f75f05b54d22bf71c6b6cbfa78db&quot;,&quot;84404c2caa7d420482ea709f60c3123d&quot;,&quot;346ec31e67da46ce8adee192213ce055&quot;,&quot;82ab3db555d54d98a46e3ef216a98090&quot;,&quot;6e52fc758f29494e8c793d7874ec068d&quot;,&quot;da640324711d4f55938a8d85909941a1&quot;,&quot;5a0db2c19b2544b4bf2b460e9072cf77&quot;,&quot;15a8f43f611d45ea87984c1c012be24a&quot;,&quot;9a6e70247be24c51a5e4b4ead9c0953d&quot;,&quot;641525f19e01411cbc848ef3fa0fa371&quot;,&quot;43ff07b00f194ce1ab7e97772c60850e&quot;,&quot;6933afe0eabc4f1bb8840c676744373d&quot;,&quot;26eb02d0dd8b4246a91d9e248535c718&quot;,&quot;cfc432710c454898bdbd7539f1265148&quot;,&quot;c051c1a9934c4fc0ba9e6240116e271b&quot;,&quot;f9ebedea49c64bd4b8ae5d24354b1844&quot;,&quot;0bca1290be3d476cb0e25d523b9d00d2&quot;,&quot;2010a2128f9d4ea6926f9f460b24df87&quot;,&quot;6a2fbeff0b9c425aa992330a731a4951&quot;,&quot;4b7b64b00c0e4d3ea46c5109e328d770&quot;,&quot;77def2da6b2b495e80da0a839dccf83c&quot;,&quot;1135d5b25460451e8782b0e9c7aec4bb&quot;,&quot;bfecdf7734724b5098bcb42bed9d0232&quot;,&quot;274bfcc233494decb96226f3fe7fa110&quot;,&quot;f049232a628d4727a389d52a0a0a9179&quot;,&quot;6b5e837b43f4416eaac3d7bf18d8de2c&quot;,&quot;e83b0af37c2046cc8ad9dabc6d99240c&quot;,&quot;7397aa8252da4d579609009739d2c778&quot;,&quot;b22857424748453696cccaab324d0efc&quot;,&quot;c6199ac30c3743ce9fe4d49ac8a26cc9&quot;,&quot;297f5fdb089b4b7992011d48b6ffc98d&quot;,&quot;a1994b7b691e4448b28dcffd46b7b8f4&quot;,&quot;e9a8999f8f174ecf9a06e5eba3cec9f2&quot;,&quot;6f5b591789ed48d7ad0715c427ceca56&quot;,&quot;b80a5dc24b884fd4b07bd0940ace56fc&quot;,&quot;3986e5aab9b544309b02ff760ee86f8f&quot;,&quot;e6ba9f4373b44329ae0a2f8ff008f7a7&quot;,&quot;260b805c901c4ab7ae05fc5ccc632af2&quot;,&quot;d6106749b3d34e09a97f8d879cb1c726&quot;,&quot;5ea3466666554beb91a87b513fd31f21&quot;,&quot;ce81f4336e994f449eedb92657dcd265&quot;,&quot;458219b494fd4dcfbaa1c0565077597e&quot;,&quot;7495323d6cbe43358245e4ceec7e3ddc&quot;,&quot;1e5550dbfb074ef9ade6e042c642c5eb&quot;,&quot;9608c0dc741a4f67a626d4da8ccef513&quot;]}"
id="JYNZsOI6XsOU" data-outputId="d12ac3a8-b025-4438-d79c-61f4a2857d50">
<div class="sourceCode" id="cb39"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> run_3_configs_for_label(df: pd.DataFrame, label_col: <span class="bu">str</span>) <span class="op">-&gt;</span> pd.DataFrame:</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> <span class="st">&quot;processed_with_stopwords&quot;</span> <span class="kw">in</span> df.columns <span class="kw">and</span> label_col <span class="kw">in</span> df.columns</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>    df_task <span class="op">=</span> df[df[label_col].notnull()].copy().reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>    le <span class="op">=</span> LabelEncoder()</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>    df_task[<span class="st">&quot;label&quot;</span>] <span class="op">=</span> le.fit_transform(df_task[label_col])</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>    num_classes <span class="op">=</span> <span class="bu">len</span>(le.classes_)</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>    full_ds <span class="op">=</span> Dataset.from_pandas(df_task[[<span class="st">&quot;processed_with_stopwords&quot;</span>,<span class="st">&quot;label&quot;</span>]])</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>    splits  <span class="op">=</span> full_ds.train_test_split(test_size<span class="op">=</span><span class="fl">0.2</span>, seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>    train_ds, val_ds <span class="op">=</span> splits[<span class="st">&quot;train&quot;</span>], splits[<span class="st">&quot;test&quot;</span>]</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>    runs: List[RunConfig] <span class="op">=</span> [</span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>        RunConfig(name<span class="op">=</span><span class="st">&quot;C1_baseline_len256&quot;</span>,    use_sampler<span class="op">=</span><span class="va">False</span>, use_loss_weights<span class="op">=</span><span class="va">False</span>, lr<span class="op">=</span><span class="fl">2e-5</span>, warmup_frac<span class="op">=</span><span class="fl">0.0</span>),</span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>        RunConfig(name<span class="op">=</span><span class="st">&quot;C2_lossweights_len256&quot;</span>, use_sampler<span class="op">=</span><span class="va">False</span>, use_loss_weights<span class="op">=</span><span class="va">True</span>,  lr<span class="op">=</span><span class="fl">2e-5</span>, warmup_frac<span class="op">=</span><span class="fl">0.0</span>),</span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>        RunConfig(name<span class="op">=</span><span class="st">&quot;C3_combo_len256&quot;</span>,       use_sampler<span class="op">=</span><span class="va">True</span>,  use_loss_weights<span class="op">=</span><span class="va">True</span>,  lr<span class="op">=</span><span class="fl">1.5e-5</span>, warmup_frac<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> run_once(cfg: RunConfig) <span class="op">-&gt;</span> Dict[<span class="bu">str</span>, Any]:</span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a>        set_seed(<span class="dv">42</span>)</span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a>        tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(cfg.model_name)</span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a>        train_loader, val_loader <span class="op">=</span> build_loaders(train_ds, val_ds, cfg, tokenizer, num_classes)</span>
<span id="cb39-22"><a href="#cb39-22" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(cfg.model_name, num_labels<span class="op">=</span>num_classes).to(cfg.device)</span>
<span id="cb39-23"><a href="#cb39-23" aria-hidden="true" tabindex="-1"></a>        optimizer <span class="op">=</span> torch.optim.AdamW(model.parameters(), lr<span class="op">=</span>cfg.lr, weight_decay<span class="op">=</span>cfg.weight_decay)</span>
<span id="cb39-24"><a href="#cb39-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-25"><a href="#cb39-25" aria-hidden="true" tabindex="-1"></a>        total_steps <span class="op">=</span> <span class="bu">len</span>(train_loader) <span class="op">*</span> cfg.epochs</span>
<span id="cb39-26"><a href="#cb39-26" aria-hidden="true" tabindex="-1"></a>        scheduler <span class="op">=</span> get_linear_schedule_with_warmup(</span>
<span id="cb39-27"><a href="#cb39-27" aria-hidden="true" tabindex="-1"></a>            optimizer,</span>
<span id="cb39-28"><a href="#cb39-28" aria-hidden="true" tabindex="-1"></a>            num_warmup_steps<span class="op">=</span><span class="bu">int</span>(cfg.warmup_frac <span class="op">*</span> total_steps),</span>
<span id="cb39-29"><a href="#cb39-29" aria-hidden="true" tabindex="-1"></a>            num_training_steps<span class="op">=</span>total_steps</span>
<span id="cb39-30"><a href="#cb39-30" aria-hidden="true" tabindex="-1"></a>        ) <span class="cf">if</span> cfg.warmup_frac <span class="kw">and</span> total_steps <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="va">None</span></span>
<span id="cb39-31"><a href="#cb39-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-32"><a href="#cb39-32" aria-hidden="true" tabindex="-1"></a>        loss_fct <span class="op">=</span> build_loss(cfg, train_loader, num_classes)</span>
<span id="cb39-33"><a href="#cb39-33" aria-hidden="true" tabindex="-1"></a>        best_val_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">&quot;inf&quot;</span>)<span class="op">;</span> best_state <span class="op">=</span> <span class="va">None</span><span class="op">;</span> patience_ctr <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb39-34"><a href="#cb39-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-35"><a href="#cb39-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, cfg.epochs <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb39-36"><a href="#cb39-36" aria-hidden="true" tabindex="-1"></a>            model.train()<span class="op">;</span> tr_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb39-37"><a href="#cb39-37" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> batch <span class="kw">in</span> train_loader:</span>
<span id="cb39-38"><a href="#cb39-38" aria-hidden="true" tabindex="-1"></a>                optimizer.zero_grad()</span>
<span id="cb39-39"><a href="#cb39-39" aria-hidden="true" tabindex="-1"></a>                batch <span class="op">=</span> {k: v.to(cfg.device) <span class="cf">for</span> k, v <span class="kw">in</span> batch.items()}</span>
<span id="cb39-40"><a href="#cb39-40" aria-hidden="true" tabindex="-1"></a>                out <span class="op">=</span> model(input_ids<span class="op">=</span>batch[<span class="st">&quot;input_ids&quot;</span>], attention_mask<span class="op">=</span>batch[<span class="st">&quot;attention_mask&quot;</span>])</span>
<span id="cb39-41"><a href="#cb39-41" aria-hidden="true" tabindex="-1"></a>                loss <span class="op">=</span> loss_fct(out.logits, batch[<span class="st">&quot;label&quot;</span>])</span>
<span id="cb39-42"><a href="#cb39-42" aria-hidden="true" tabindex="-1"></a>                loss.backward()</span>
<span id="cb39-43"><a href="#cb39-43" aria-hidden="true" tabindex="-1"></a>                torch.nn.utils.clip_grad_norm_(model.parameters(), <span class="fl">1.0</span>)</span>
<span id="cb39-44"><a href="#cb39-44" aria-hidden="true" tabindex="-1"></a>                optimizer.step()</span>
<span id="cb39-45"><a href="#cb39-45" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> scheduler <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>: scheduler.step()</span>
<span id="cb39-46"><a href="#cb39-46" aria-hidden="true" tabindex="-1"></a>                tr_loss <span class="op">+=</span> loss.item()</span>
<span id="cb39-47"><a href="#cb39-47" aria-hidden="true" tabindex="-1"></a>            avg_tr <span class="op">=</span> tr_loss <span class="op">/</span> <span class="bu">max</span>(<span class="dv">1</span>, <span class="bu">len</span>(train_loader))</span>
<span id="cb39-48"><a href="#cb39-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-49"><a href="#cb39-49" aria-hidden="true" tabindex="-1"></a>            model.<span class="bu">eval</span>()<span class="op">;</span> va_loss <span class="op">=</span> <span class="fl">0.0</span><span class="op">;</span> preds, labels <span class="op">=</span> [], []</span>
<span id="cb39-50"><a href="#cb39-50" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> torch.no_grad():</span>
<span id="cb39-51"><a href="#cb39-51" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> batch <span class="kw">in</span> val_loader:</span>
<span id="cb39-52"><a href="#cb39-52" aria-hidden="true" tabindex="-1"></a>                    batch <span class="op">=</span> {k: v.to(cfg.device) <span class="cf">for</span> k, v <span class="kw">in</span> batch.items()}</span>
<span id="cb39-53"><a href="#cb39-53" aria-hidden="true" tabindex="-1"></a>                    out <span class="op">=</span> model(input_ids<span class="op">=</span>batch[<span class="st">&quot;input_ids&quot;</span>], attention_mask<span class="op">=</span>batch[<span class="st">&quot;attention_mask&quot;</span>])</span>
<span id="cb39-54"><a href="#cb39-54" aria-hidden="true" tabindex="-1"></a>                    loss <span class="op">=</span> loss_fct(out.logits, batch[<span class="st">&quot;label&quot;</span>])</span>
<span id="cb39-55"><a href="#cb39-55" aria-hidden="true" tabindex="-1"></a>                    va_loss <span class="op">+=</span> loss.item()</span>
<span id="cb39-56"><a href="#cb39-56" aria-hidden="true" tabindex="-1"></a>                    preds.extend(torch.argmax(out.logits, dim<span class="op">=-</span><span class="dv">1</span>).cpu().numpy())</span>
<span id="cb39-57"><a href="#cb39-57" aria-hidden="true" tabindex="-1"></a>                    labels.extend(batch[<span class="st">&quot;label&quot;</span>].cpu().numpy())</span>
<span id="cb39-58"><a href="#cb39-58" aria-hidden="true" tabindex="-1"></a>            avg_va <span class="op">=</span> va_loss <span class="op">/</span> <span class="bu">max</span>(<span class="dv">1</span>, <span class="bu">len</span>(val_loader))</span>
<span id="cb39-59"><a href="#cb39-59" aria-hidden="true" tabindex="-1"></a>            val_acc <span class="op">=</span> accuracy_score(labels, preds)</span>
<span id="cb39-60"><a href="#cb39-60" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot;[</span><span class="sc">{</span>label_col<span class="sc">}</span><span class="ss"> | </span><span class="sc">{</span>cfg<span class="sc">.</span>name<span class="sc">}</span><span class="ss">] Epoch </span><span class="sc">{</span>epoch<span class="sc">:02d}</span><span class="ss"> | train_loss: </span><span class="sc">{</span>avg_tr<span class="sc">:.4f}</span><span class="ss"> | val_loss: </span><span class="sc">{</span>avg_va<span class="sc">:.4f}</span><span class="ss"> | val_acc: </span><span class="sc">{</span>val_acc<span class="sc">:.4f}</span><span class="ss"> | patience </span><span class="sc">{</span>patience_ctr<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>cfg<span class="sc">.</span>patience<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb39-61"><a href="#cb39-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-62"><a href="#cb39-62" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> avg_va <span class="op">&lt;</span> best_val_loss:</span>
<span id="cb39-63"><a href="#cb39-63" aria-hidden="true" tabindex="-1"></a>                best_val_loss <span class="op">=</span> avg_va</span>
<span id="cb39-64"><a href="#cb39-64" aria-hidden="true" tabindex="-1"></a>                best_state <span class="op">=</span> {k: v.detach().cpu().clone() <span class="cf">for</span> k, v <span class="kw">in</span> model.state_dict().items()}</span>
<span id="cb39-65"><a href="#cb39-65" aria-hidden="true" tabindex="-1"></a>                patience_ctr <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb39-66"><a href="#cb39-66" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb39-67"><a href="#cb39-67" aria-hidden="true" tabindex="-1"></a>                patience_ctr <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb39-68"><a href="#cb39-68" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> patience_ctr <span class="op">&gt;=</span> cfg.patience:</span>
<span id="cb39-69"><a href="#cb39-69" aria-hidden="true" tabindex="-1"></a>                    <span class="bu">print</span>(<span class="ss">f&quot;[</span><span class="sc">{</span>label_col<span class="sc">}</span><span class="ss"> | </span><span class="sc">{</span>cfg<span class="sc">.</span>name<span class="sc">}</span><span class="ss">] Early stopping.&quot;</span>)</span>
<span id="cb39-70"><a href="#cb39-70" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">break</span></span>
<span id="cb39-71"><a href="#cb39-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-72"><a href="#cb39-72" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> best_state <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb39-73"><a href="#cb39-73" aria-hidden="true" tabindex="-1"></a>            model.load_state_dict(best_state)</span>
<span id="cb39-74"><a href="#cb39-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-75"><a href="#cb39-75" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">eval</span>()<span class="op">;</span> preds, labels <span class="op">=</span> [], []</span>
<span id="cb39-76"><a href="#cb39-76" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb39-77"><a href="#cb39-77" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> batch <span class="kw">in</span> val_loader:</span>
<span id="cb39-78"><a href="#cb39-78" aria-hidden="true" tabindex="-1"></a>                batch <span class="op">=</span> {k: v.to(cfg.device) <span class="cf">for</span> k, v <span class="kw">in</span> batch.items()}</span>
<span id="cb39-79"><a href="#cb39-79" aria-hidden="true" tabindex="-1"></a>                logits <span class="op">=</span> model(input_ids<span class="op">=</span>batch[<span class="st">&quot;input_ids&quot;</span>], attention_mask<span class="op">=</span>batch[<span class="st">&quot;attention_mask&quot;</span>]).logits</span>
<span id="cb39-80"><a href="#cb39-80" aria-hidden="true" tabindex="-1"></a>                preds.extend(torch.argmax(logits, dim<span class="op">=-</span><span class="dv">1</span>).cpu().numpy())</span>
<span id="cb39-81"><a href="#cb39-81" aria-hidden="true" tabindex="-1"></a>                labels.extend(batch[<span class="st">&quot;label&quot;</span>].cpu().numpy())</span>
<span id="cb39-82"><a href="#cb39-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-83"><a href="#cb39-83" aria-hidden="true" tabindex="-1"></a>        rep <span class="op">=</span> classification_report(labels, preds, target_names<span class="op">=</span><span class="bu">list</span>(le.classes_), output_dict<span class="op">=</span><span class="va">True</span>, zero_division<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb39-84"><a href="#cb39-84" aria-hidden="true" tabindex="-1"></a>        macro_f1 <span class="op">=</span> rep[<span class="st">&quot;macro avg&quot;</span>][<span class="st">&quot;f1-score&quot;</span>]</span>
<span id="cb39-85"><a href="#cb39-85" aria-hidden="true" tabindex="-1"></a>        per_class <span class="op">=</span> {<span class="ss">f&quot;recall_</span><span class="sc">{</span>cls<span class="sc">.</span>replace(<span class="st">&#39;/&#39;</span>, <span class="st">&#39;-&#39;</span>)<span class="sc">.</span>replace(<span class="st">&#39; &#39;</span>, <span class="st">&#39;_&#39;</span>)<span class="sc">}</span><span class="ss">&quot;</span>: rep[cls][<span class="st">&quot;recall&quot;</span>] <span class="cf">for</span> cls <span class="kw">in</span> le.classes_}</span>
<span id="cb39-86"><a href="#cb39-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-87"><a href="#cb39-87" aria-hidden="true" tabindex="-1"></a>        row <span class="op">=</span> {</span>
<span id="cb39-88"><a href="#cb39-88" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;run&quot;</span>: cfg.name,</span>
<span id="cb39-89"><a href="#cb39-89" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;max_len&quot;</span>: cfg.max_len,</span>
<span id="cb39-90"><a href="#cb39-90" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;lr&quot;</span>: cfg.lr,</span>
<span id="cb39-91"><a href="#cb39-91" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;warmup&quot;</span>: cfg.warmup_frac,</span>
<span id="cb39-92"><a href="#cb39-92" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;sampler&quot;</span>: cfg.use_sampler,</span>
<span id="cb39-93"><a href="#cb39-93" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;alpha&quot;</span>: cfg.sampler_alpha <span class="cf">if</span> cfg.use_sampler <span class="cf">else</span> <span class="fl">0.0</span>,</span>
<span id="cb39-94"><a href="#cb39-94" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;loss_weights&quot;</span>: cfg.use_loss_weights,</span>
<span id="cb39-95"><a href="#cb39-95" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;val_acc&quot;</span>: rep[<span class="st">&quot;accuracy&quot;</span>],</span>
<span id="cb39-96"><a href="#cb39-96" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;macro_f1&quot;</span>: macro_f1,</span>
<span id="cb39-97"><a href="#cb39-97" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;val_loss&quot;</span>: <span class="bu">round</span>(best_val_loss, <span class="dv">4</span>),</span>
<span id="cb39-98"><a href="#cb39-98" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb39-99"><a href="#cb39-99" aria-hidden="true" tabindex="-1"></a>        row.update(per_class)</span>
<span id="cb39-100"><a href="#cb39-100" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> row</span>
<span id="cb39-101"><a href="#cb39-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-102"><a href="#cb39-102" aria-hidden="true" tabindex="-1"></a>    rows <span class="op">=</span> [run_once(cfg) <span class="cf">for</span> cfg <span class="kw">in</span> runs]</span>
<span id="cb39-103"><a href="#cb39-103" aria-hidden="true" tabindex="-1"></a>    summary <span class="op">=</span> pd.DataFrame(rows).sort_values(by<span class="op">=</span>[<span class="st">&quot;macro_f1&quot;</span>,<span class="st">&quot;val_acc&quot;</span>], ascending<span class="op">=</span><span class="va">False</span>).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb39-104"><a href="#cb39-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-105"><a href="#cb39-105" aria-hidden="true" tabindex="-1"></a>    front <span class="op">=</span> [<span class="st">&quot;run&quot;</span>,<span class="st">&quot;max_len&quot;</span>,<span class="st">&quot;lr&quot;</span>,<span class="st">&quot;warmup&quot;</span>,<span class="st">&quot;sampler&quot;</span>,<span class="st">&quot;alpha&quot;</span>,<span class="st">&quot;loss_weights&quot;</span>,<span class="st">&quot;val_acc&quot;</span>,<span class="st">&quot;macro_f1&quot;</span>,<span class="st">&quot;val_loss&quot;</span>]</span>
<span id="cb39-106"><a href="#cb39-106" aria-hidden="true" tabindex="-1"></a>    recalls <span class="op">=</span> [c <span class="cf">for</span> c <span class="kw">in</span> summary.columns <span class="cf">if</span> c.startswith(<span class="st">&quot;recall_&quot;</span>)]</span>
<span id="cb39-107"><a href="#cb39-107" aria-hidden="true" tabindex="-1"></a>    summary <span class="op">=</span> summary[front <span class="op">+</span> recalls]</span>
<span id="cb39-108"><a href="#cb39-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-109"><a href="#cb39-109" aria-hidden="true" tabindex="-1"></a>    display(summary)</span>
<span id="cb39-110"><a href="#cb39-110" aria-hidden="true" tabindex="-1"></a>    out_csv <span class="op">=</span> <span class="ss">f&quot;sciBERT_</span><span class="sc">{</span>label_col<span class="sc">}</span><span class="ss">_3run_summary_len256.csv&quot;</span></span>
<span id="cb39-111"><a href="#cb39-111" aria-hidden="true" tabindex="-1"></a>    summary.to_csv(out_csv, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb39-112"><a href="#cb39-112" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Saved summary to: </span><span class="sc">{</span>out_csv<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb39-113"><a href="#cb39-113" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> summary</span>
<span id="cb39-114"><a href="#cb39-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-115"><a href="#cb39-115" aria-hidden="true" tabindex="-1"></a>summary_methodology <span class="op">=</span> run_3_configs_for_label(df, <span class="st">&quot;methodology&quot;</span>)</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb40"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;3198d7d72fa74c76b777f48f215606ef&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb41"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;93c03620288d426f83e551a04a2d7948&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: [&#39;classifier.bias&#39;, &#39;classifier.weight&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>[methodology | C1_baseline_len256] Epoch 01 | train_loss: 0.8500 | val_loss: 0.8427 | val_acc: 0.7672 | patience 0/2
[methodology | C1_baseline_len256] Epoch 02 | train_loss: 0.7877 | val_loss: 0.9658 | val_acc: 0.7816 | patience 0/2
[methodology | C1_baseline_len256] Epoch 03 | train_loss: 0.7272 | val_loss: 0.7590 | val_acc: 0.7959 | patience 1/2
[methodology | C1_baseline_len256] Epoch 04 | train_loss: 0.6747 | val_loss: 0.7916 | val_acc: 0.7959 | patience 0/2
[methodology | C1_baseline_len256] Epoch 05 | train_loss: 0.6213 | val_loss: 0.8990 | val_acc: 0.7842 | patience 1/2
[methodology | C1_baseline_len256] Early stopping.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb44"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;84404c2caa7d420482ea709f60c3123d&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb45"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;26eb02d0dd8b4246a91d9e248535c718&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: [&#39;classifier.bias&#39;, &#39;classifier.weight&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>[methodology | C2_lossweights_len256] Epoch 01 | train_loss: 2.0755 | val_loss: 1.8565 | val_acc: 0.4557 | patience 0/2
[methodology | C2_lossweights_len256] Epoch 02 | train_loss: 1.8999 | val_loss: 2.0195 | val_acc: 0.2068 | patience 0/2
[methodology | C2_lossweights_len256] Epoch 03 | train_loss: 1.7851 | val_loss: 1.9005 | val_acc: 0.5577 | patience 1/2
[methodology | C2_lossweights_len256] Early stopping.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb48"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;274bfcc233494decb96226f3fe7fa110&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb49"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;b80a5dc24b884fd4b07bd0940ace56fc&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: [&#39;classifier.bias&#39;, &#39;classifier.weight&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>[methodology | C3_combo_len256] Epoch 01 | train_loss: 1.6337 | val_loss: 1.9740 | val_acc: 0.2032 | patience 0/2
[methodology | C3_combo_len256] Epoch 02 | train_loss: 1.2531 | val_loss: 1.8831 | val_acc: 0.7278 | patience 0/2
[methodology | C3_combo_len256] Epoch 03 | train_loss: 1.0664 | val_loss: 1.9965 | val_acc: 0.7046 | patience 0/2
[methodology | C3_combo_len256] Epoch 04 | train_loss: 1.0050 | val_loss: 1.9554 | val_acc: 0.2954 | patience 1/2
[methodology | C3_combo_len256] Early stopping.
</code></pre>
</div>
<div class="output display_data">

  <div id="df-d512b98b-4d17-437e-9208-7e480898e56e" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>run</th>
      <th>max_len</th>
      <th>lr</th>
      <th>warmup</th>
      <th>sampler</th>
      <th>alpha</th>
      <th>loss_weights</th>
      <th>val_acc</th>
      <th>macro_f1</th>
      <th>val_loss</th>
      <th>recall_Design_Science_-_System_Design</th>
      <th>recall_Mixed_Methods</th>
      <th>recall_Qualitative</th>
      <th>recall_Theoretical_-_Conceptual</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>C3_combo_len256</td>
      <td>256</td>
      <td>0.000015</td>
      <td>0.1</td>
      <td>True</td>
      <td>0.5</td>
      <td>True</td>
      <td>0.727842</td>
      <td>0.554317</td>
      <td>1.8831</td>
      <td>0.773723</td>
      <td>0.574468</td>
      <td>0.444444</td>
      <td>0.690625</td>
    </tr>
    <tr>
      <th>1</th>
      <td>C1_baseline_len256</td>
      <td>256</td>
      <td>0.000020</td>
      <td>0.0</td>
      <td>False</td>
      <td>0.0</td>
      <td>False</td>
      <td>0.795882</td>
      <td>0.517314</td>
      <td>0.7590</td>
      <td>0.908029</td>
      <td>0.468085</td>
      <td>0.000000</td>
      <td>0.696875</td>
    </tr>
    <tr>
      <th>2</th>
      <td>C2_lossweights_len256</td>
      <td>256</td>
      <td>0.000020</td>
      <td>0.0</td>
      <td>False</td>
      <td>0.0</td>
      <td>True</td>
      <td>0.455685</td>
      <td>0.417329</td>
      <td>1.8565</td>
      <td>0.341606</td>
      <td>0.457447</td>
      <td>0.500000</td>
      <td>0.696875</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-d512b98b-4d17-437e-9208-7e480898e56e')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-d512b98b-4d17-437e-9208-7e480898e56e button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-d512b98b-4d17-437e-9208-7e480898e56e');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    <div id="df-e5851604-3eb5-41a6-8279-36f14331eb72">
      <button class="colab-df-quickchart" onclick="quickchart('df-e5851604-3eb5-41a6-8279-36f14331eb72')"
                title="Suggest charts"
                style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
      </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

      <script>
        async function quickchart(key) {
          const quickchartButtonEl =
            document.querySelector('#' + key + ' button');
          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
          quickchartButtonEl.classList.add('colab-df-spinner');
          try {
            const charts = await google.colab.kernel.invokeFunction(
                'suggestCharts', [key], {});
          } catch (error) {
            console.error('Error during call to suggestCharts:', error);
          }
          quickchartButtonEl.classList.remove('colab-df-spinner');
          quickchartButtonEl.classList.add('colab-df-quickchart-complete');
        }
        (() => {
          let quickchartButtonEl =
            document.querySelector('#df-e5851604-3eb5-41a6-8279-36f14331eb72 button');
          quickchartButtonEl.style.display =
            google.colab.kernel.accessAllowed ? 'block' : 'none';
        })();
      </script>
    </div>

    </div>
  </div>

</div>
<div class="output stream stdout">
<pre><code>Saved summary to: sciBERT_methodology_3run_summary_len256.csv
</code></pre>
</div>
</div>
<section id="heatmap-evaluation" class="cell markdown"
id="IOah3PLF-jFk">
<h3>Heatmap Evaluation</h3>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:439}"
id="nEXjwd9jo_AL" data-outputId="bd690810-dcb6-4d96-cdb9-25f9f0a17af5">
<div class="sourceCode" id="cb53"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Upload CSV</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> google.colab <span class="im">import</span> files</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>uploaded <span class="op">=</span> files.upload()</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> uploaded:</span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">&quot;No file uploaded.&quot;</span>)</span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a>fname, data <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(uploaded.items()))</span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(io.BytesIO(data))</span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Loaded: </span><span class="sc">{</span>fname<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-12"><a href="#cb53-12" aria-hidden="true" tabindex="-1"></a><span class="co">#  heatmap for SciBERT C-series</span></span>
<span id="cb53-13"><a href="#cb53-13" aria-hidden="true" tabindex="-1"></a>cols <span class="op">=</span> [</span>
<span id="cb53-14"><a href="#cb53-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;recall_Design_Science_-_System_Design&quot;</span>,</span>
<span id="cb53-15"><a href="#cb53-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;recall_Mixed_Methods&quot;</span>,</span>
<span id="cb53-16"><a href="#cb53-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;recall_Qualitative&quot;</span>,</span>
<span id="cb53-17"><a href="#cb53-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;recall_Theoretical_-_Conceptual&quot;</span>,</span>
<span id="cb53-18"><a href="#cb53-18" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb53-19"><a href="#cb53-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-20"><a href="#cb53-20" aria-hidden="true" tabindex="-1"></a>required <span class="op">=</span> {<span class="st">&quot;run&quot;</span>, <span class="op">*</span>cols}</span>
<span id="cb53-21"><a href="#cb53-21" aria-hidden="true" tabindex="-1"></a>missing <span class="op">=</span> required.difference(df.columns)</span>
<span id="cb53-22"><a href="#cb53-22" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> missing:</span>
<span id="cb53-23"><a href="#cb53-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f&quot;Missing columns in CSV: </span><span class="sc">{</span>missing<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb53-24"><a href="#cb53-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-25"><a href="#cb53-25" aria-hidden="true" tabindex="-1"></a>order <span class="op">=</span> [<span class="st">&quot;C1_baseline_len256&quot;</span>, <span class="st">&quot;C2_lossweights_len256&quot;</span>, <span class="st">&quot;C3_combo_len256&quot;</span>]</span>
<span id="cb53-26"><a href="#cb53-26" aria-hidden="true" tabindex="-1"></a>df_c <span class="op">=</span> df[df[<span class="st">&quot;run&quot;</span>].isin(order)].set_index(<span class="st">&quot;run&quot;</span>).loc[order].reset_index()</span>
<span id="cb53-27"><a href="#cb53-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-28"><a href="#cb53-28" aria-hidden="true" tabindex="-1"></a><span class="co"># axis labels</span></span>
<span id="cb53-29"><a href="#cb53-29" aria-hidden="true" tabindex="-1"></a>pretty <span class="op">=</span> [<span class="st">&quot;DesignScience/SystemDesign&quot;</span>, <span class="st">&quot;MixedMethods&quot;</span>, <span class="st">&quot;Qualitative&quot;</span>, <span class="st">&quot;Theoretical/Conceptual&quot;</span>]</span>
<span id="cb53-30"><a href="#cb53-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-31"><a href="#cb53-31" aria-hidden="true" tabindex="-1"></a><span class="co"># heatmap</span></span>
<span id="cb53-32"><a href="#cb53-32" aria-hidden="true" tabindex="-1"></a>mat <span class="op">=</span> df_c[cols].to_numpy()</span>
<span id="cb53-33"><a href="#cb53-33" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="fl">3.6</span>))</span>
<span id="cb53-34"><a href="#cb53-34" aria-hidden="true" tabindex="-1"></a>plt.imshow(mat, aspect<span class="op">=</span><span class="st">&quot;auto&quot;</span>)</span>
<span id="cb53-35"><a href="#cb53-35" aria-hidden="true" tabindex="-1"></a>plt.xticks(<span class="bu">range</span>(<span class="bu">len</span>(pretty)), pretty, rotation<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb53-36"><a href="#cb53-36" aria-hidden="true" tabindex="-1"></a>plt.yticks(<span class="bu">range</span>(<span class="bu">len</span>(order)), [<span class="st">&quot;SciBERT C1&quot;</span>, <span class="st">&quot;SciBERT C2&quot;</span>, <span class="st">&quot;SciBERT C3&quot;</span>])</span>
<span id="cb53-37"><a href="#cb53-37" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb53-38"><a href="#cb53-38" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;SciBERT — Per-class Recall (Methodology)&quot;</span>)</span>
<span id="cb53-39"><a href="#cb53-39" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb53-40"><a href="#cb53-40" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">

     <input type="file" id="files-63605e82-9334-44d0-9826-681c8731b5f3" name="files[]" multiple disabled
        style="border:none" />
     <output id="result-63605e82-9334-44d0-9826-681c8731b5f3">
      Upload widget is only available when the cell has been executed in the
      current browser session. Please rerun this cell to enable.
      </output>
      <script>// Copyright 2017 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

/**
 * @fileoverview Helpers for google.colab Python module.
 */
(function(scope) {
function span(text, styleAttributes = {}) {
  const element = document.createElement('span');
  element.textContent = text;
  for (const key of Object.keys(styleAttributes)) {
    element.style[key] = styleAttributes[key];
  }
  return element;
}

// Max number of bytes which will be uploaded at a time.
const MAX_PAYLOAD_SIZE = 100 * 1024;

function _uploadFiles(inputId, outputId) {
  const steps = uploadFilesStep(inputId, outputId);
  const outputElement = document.getElementById(outputId);
  // Cache steps on the outputElement to make it available for the next call
  // to uploadFilesContinue from Python.
  outputElement.steps = steps;

  return _uploadFilesContinue(outputId);
}

// This is roughly an async generator (not supported in the browser yet),
// where there are multiple asynchronous steps and the Python side is going
// to poll for completion of each step.
// This uses a Promise to block the python side on completion of each step,
// then passes the result of the previous step as the input to the next step.
function _uploadFilesContinue(outputId) {
  const outputElement = document.getElementById(outputId);
  const steps = outputElement.steps;

  const next = steps.next(outputElement.lastPromiseValue);
  return Promise.resolve(next.value.promise).then((value) => {
    // Cache the last promise value to make it available to the next
    // step of the generator.
    outputElement.lastPromiseValue = value;
    return next.value.response;
  });
}

/**
 * Generator function which is called between each async step of the upload
 * process.
 * @param {string} inputId Element ID of the input file picker element.
 * @param {string} outputId Element ID of the output display.
 * @return {!Iterable<!Object>} Iterable of next steps.
 */
function* uploadFilesStep(inputId, outputId) {
  const inputElement = document.getElementById(inputId);
  inputElement.disabled = false;

  const outputElement = document.getElementById(outputId);
  outputElement.innerHTML = '';

  const pickedPromise = new Promise((resolve) => {
    inputElement.addEventListener('change', (e) => {
      resolve(e.target.files);
    });
  });

  const cancel = document.createElement('button');
  inputElement.parentElement.appendChild(cancel);
  cancel.textContent = 'Cancel upload';
  const cancelPromise = new Promise((resolve) => {
    cancel.onclick = () => {
      resolve(null);
    };
  });

  // Wait for the user to pick the files.
  const files = yield {
    promise: Promise.race([pickedPromise, cancelPromise]),
    response: {
      action: 'starting',
    }
  };

  cancel.remove();

  // Disable the input element since further picks are not allowed.
  inputElement.disabled = true;

  if (!files) {
    return {
      response: {
        action: 'complete',
      }
    };
  }

  for (const file of files) {
    const li = document.createElement('li');
    li.append(span(file.name, {fontWeight: 'bold'}));
    li.append(span(
        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +
        `last modified: ${
            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :
                                    'n/a'} - `));
    const percent = span('0% done');
    li.appendChild(percent);

    outputElement.appendChild(li);

    const fileDataPromise = new Promise((resolve) => {
      const reader = new FileReader();
      reader.onload = (e) => {
        resolve(e.target.result);
      };
      reader.readAsArrayBuffer(file);
    });
    // Wait for the data to be ready.
    let fileData = yield {
      promise: fileDataPromise,
      response: {
        action: 'continue',
      }
    };

    // Use a chunked sending to avoid message size limits. See b/62115660.
    let position = 0;
    do {
      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);
      const chunk = new Uint8Array(fileData, position, length);
      position += length;

      const base64 = btoa(String.fromCharCode.apply(null, chunk));
      yield {
        response: {
          action: 'append',
          file: file.name,
          data: base64,
        },
      };

      let percentDone = fileData.byteLength === 0 ?
          100 :
          Math.round((position / fileData.byteLength) * 100);
      percent.textContent = `${percentDone}% done`;

    } while (position < fileData.byteLength);
  }

  // All done.
  yield {
    response: {
      action: 'complete',
    }
  };
}

scope.google = scope.google || {};
scope.google.colab = scope.google.colab || {};
scope.google.colab._files = {
  _uploadFiles,
  _uploadFilesContinue,
};
})(self);
</script> 
</div>
<div class="output stream stdout">
<pre><code>Saving A2_sciBERT_methodology_3run_summary_len256.csv to A2_sciBERT_methodology_3run_summary_len256.csv
Loaded: A2_sciBERT_methodology_3run_summary_len256.csv
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_e37543f3817e498792271d4afeefc0f0/d09368800646ea3611b7e411b38c21946ce93a3e.png" /></p>
</div>
</div>
<section id="43-roberta-model-1" class="cell markdown"
id="36BnBHcqFAcB">
<h2>4.3 Roberta Model 1</h2>
<p>I set up RoBERTa as a second transformer baseline for methodology
classification using the same recipe as SciBERT for a clean comparison:
an 80/20 split (seed=42), 512-token context to avoid truncation
confounds, AdamW (2e-5) with small batches and gradient clipping, and a
short 3-epoch run. Checkpoints were picked by validation accuracy for
stability, while macro-F1 and per-class recall were logged for later
analysis and plotting.</p>
<p>On this configuration the model reached val acc at about 0.806 and
macro-F1 at about 0.532. Per-class recall was strong for Design
Science/System Design (at about 0.90) and Theoretical/Conceptual (at
about 0.75), moderate for Mixed Methods (at about 0.48), and weak for
Qualitative (at 0) on this split. The pattern indicates RoBERTa’s
general-domain pretraining transfers well to terminology-rich
methodological cues, while very small or diffuse classes still require
targeted treatment.</p>
<p>What this leads to next. Building on this baseline, I run three
focused RoBERTa variants:</p>
<ul>
<li><p>D1 (baseline @256 tokens): halve the sequence length to test
whether a shorter window preserves performance while improving
efficiency (supported by the token-length study).</p></li>
<li><p>D2 (loss weights): introduce class-weighted loss to raise
minority recalls while monitoring for side effects on dominant
classes.</p></li>
<li><p>D3 (combo): combine reweighting with light warm-up/reshuffling to
see if gains compound or trade off.</p></li>
</ul>
<p>These controlled adjustments keep the backbone fixed and vary only
training bias/length, so any shifts in macro-F1 or per-class recall can
be attributed to the specific tweak rather than a wholesale change.</p>
</section>
<section id="label-enconding-and-tokenisation" class="cell markdown"
id="c8cQTyKYAzTQ">
<h3>Label Enconding and Tokenisation</h3>
<p>Similar to my SciBERT's settings I used the same 80/20 split with a
fixed seed so that RoBERTa Model 1 is comparable with SciBERT Model 1. I
encode the LabelEncoder to lock class order to ensure the per-class
recall columns line up across models.</p>
<p>I switch the backbone to roberta-base and tokenise to 512 tokens with
max-length padding. RoBERTa is pre-trained on a larger and more diverse
web corpus; the bet is that its sentence representations may capture
non-domain-specific cues that help when abstracts are concise or less
technical. Keeping 512 here mirrors the SciBERT Model 1 setup and avoids
a confound from sequence length.</p>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:241,&quot;referenced_widgets&quot;:[&quot;b412ea74e5d3410aa1d83bafb851aee1&quot;,&quot;5be5a152ab0c4f0f90fde761098d89d2&quot;,&quot;a085f74e40814d0493a8fadc9b136a1f&quot;,&quot;c8cd3500a16344a29959e3e928c96d4a&quot;,&quot;72c4f53c5f2748e0b7fac3726b7e4c2e&quot;,&quot;11f4194195e543bbbb14147842713e19&quot;,&quot;15e14f81143c4c9581c7201eb9164928&quot;,&quot;aa170df1206e4883987ea19f3c424789&quot;,&quot;77106a4a71e74db188696b32107d2cc2&quot;,&quot;c14df5f6e53543ae856315b525391a97&quot;,&quot;945369d4ba2747f7a5ae547f7fad8e34&quot;,&quot;e79e4240645a4974bee810d395a807d8&quot;,&quot;a774ca9d652b443ebd428e924a800b74&quot;,&quot;6a9503a05e544f2fbf66df61681ea493&quot;,&quot;42a6179aa8034a95ba5d38c91dbaba10&quot;,&quot;1320f4ba76994b908ff82937950cf2c9&quot;,&quot;eb5133d39cef4b5a8bacb645176f5386&quot;,&quot;0dabf70fb8de4aebadf8249f5c0ccdfa&quot;,&quot;6a651447818042d1a18a6c5209a56a86&quot;,&quot;ada6d5432f3f4df4a36262f63ed74898&quot;,&quot;7682b36f5bd14d2786973cc7419521db&quot;,&quot;b1757746c943408abdab75895c142521&quot;,&quot;3f8578ae9e5949fbbafb96044986ad75&quot;,&quot;9af5e6b580c840e09f3c123b95c1a68d&quot;,&quot;6aa09235b0d5442d86d9b274db22334d&quot;,&quot;e9835f4d85644003a0ddbf14fec6bef2&quot;,&quot;a20792ef81a5497a8c681aa25a29ce88&quot;,&quot;88d6dd7e558d42e8ae719c90aea700e8&quot;,&quot;f87905f29cb1495abb0d09ae2b8492df&quot;,&quot;9e6dbfd048ca4a64822adfb17cc91c70&quot;,&quot;f9810967d16d422a9cec2056a52571ce&quot;,&quot;1deabe6f896245368518b55c21fc72eb&quot;,&quot;f0f5c6a3767746419a7f9cd94d96349b&quot;,&quot;4347dc4bf71249d5bbd08517325a0ce5&quot;,&quot;87cb3b8fd8764f32a863f1716aa13f98&quot;,&quot;ddbf0d00ecd745138470a072ef80a48c&quot;,&quot;61395907aaf346339c784523da698c4c&quot;,&quot;bd2793bec08745a4bcdf12f7196c9353&quot;,&quot;e5a84c11de3b4fb1a1c6b2a10d5f4a56&quot;,&quot;fcb61418ab794a5c9bcc5b12c3fdb7a2&quot;,&quot;00afbe6a29204b28b59bcf207d1b18e2&quot;,&quot;5aa5502be41a46eaa4e2b63ab8a04923&quot;,&quot;0de60a5951824d09bf950e06a7ed1920&quot;,&quot;5421c341c9c4418ea1426931f448038b&quot;,&quot;f8725e0e6fe7403b93af5e0f5d34a5ee&quot;,&quot;129435d72c3b4596bc836835db446aa3&quot;,&quot;ef9858d582144245b0a0f016142cc5d3&quot;,&quot;e1f3e6fa631442df8613b4affc66cb68&quot;,&quot;2d41f6b4463443268a717babf1b807f4&quot;,&quot;a62d5fd2538240bb9b9441ec3e3cb5a1&quot;,&quot;f482528c9efb4223b8c2a15972f59c77&quot;,&quot;352219ca9aa34fa2afdf13a0fcbb378b&quot;,&quot;5f504b4467464e74b94cb607b248b3a2&quot;,&quot;b2c96bc28e414ee694311898aa20ebc7&quot;,&quot;c486447d49aa4d37baa25844393a2e28&quot;,&quot;ed11a109c1854d71b02fffa08c3783d2&quot;,&quot;83368b9edfe54192bf005faa3a6ca877&quot;,&quot;c1bb089fe3244dd8844c5e1ea2ebe9ab&quot;,&quot;413415a367b84c0bb42e3f6e312132fc&quot;,&quot;236d117e3c01462fb925c58b318e8a76&quot;,&quot;bbdeb2c99aa34da4a4f547029b3802d9&quot;,&quot;c85640c186ec49f6a819e27f74c8c239&quot;,&quot;a4c929fac46941a0a0843c9de0df7f8f&quot;,&quot;d0589f29e3a945f7bec538ce7cdf16c3&quot;,&quot;2f22b1e02c5248d1ae9df1c4409a6a33&quot;,&quot;cee59a3f8ff8476ead382bb09f552fc7&quot;,&quot;d3c1a2c5291c4e09b50f062623b88860&quot;,&quot;e855b36ca2bb427694418c50997bf6ca&quot;,&quot;962bb818567c49c7b00ed1020b941898&quot;,&quot;e3185c9d1d664870bbc1c1b5822fc7c0&quot;,&quot;cf45487dd31e40b191c3ece38285bafe&quot;,&quot;efbff827636e4ae096e9ad0f9e8e7893&quot;,&quot;a7abc50f968341f4b0c2a51c12bdfef7&quot;,&quot;c840142e9d1247d9bb5f1460b82d24ed&quot;,&quot;c3fcad1aa7bd48cc8a4a7a916406cf92&quot;,&quot;392083ed17d64701a9c9f7f8916dbc64&quot;,&quot;a57910382fe94d02be254a1ac4230479&quot;]}"
id="SE3nkVkAGrfq" data-outputId="d69ed2f9-cfe4-4d3b-eed3-1c078e28652e">
<div class="sourceCode" id="cb55"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Reproducibility</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> set_seed(seed<span class="op">=</span><span class="dv">42</span>):</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>    random.seed(seed)</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>    np.random.seed(seed)</span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>    torch.manual_seed(seed)</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>    torch.cuda.manual_seed_all(seed)</span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a>set_seed(<span class="dv">42</span>)</span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare methodology subset</span></span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a>df_m <span class="op">=</span> df[df[<span class="st">&#39;methodology&#39;</span>].notnull()].copy().reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb55-11"><a href="#cb55-11" aria-hidden="true" tabindex="-1"></a>le <span class="op">=</span> LabelEncoder()</span>
<span id="cb55-12"><a href="#cb55-12" aria-hidden="true" tabindex="-1"></a>df_m[<span class="st">&#39;label&#39;</span>] <span class="op">=</span> le.fit_transform(df_m[<span class="st">&#39;methodology&#39;</span>])</span>
<span id="cb55-13"><a href="#cb55-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-14"><a href="#cb55-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Dataset and split</span></span>
<span id="cb55-15"><a href="#cb55-15" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> Dataset.from_pandas(df_m[[<span class="st">&#39;processed_with_stopwords&#39;</span>, <span class="st">&#39;label&#39;</span>]])</span>
<span id="cb55-16"><a href="#cb55-16" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> dataset.train_test_split(test_size<span class="op">=</span><span class="fl">0.2</span>, seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb55-17"><a href="#cb55-17" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> dataset[<span class="st">&quot;train&quot;</span>], dataset[<span class="st">&quot;test&quot;</span>]</span>
<span id="cb55-18"><a href="#cb55-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-19"><a href="#cb55-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Tokenisation (RoBERTa)</span></span>
<span id="cb55-20"><a href="#cb55-20" aria-hidden="true" tabindex="-1"></a>model_name <span class="op">=</span> <span class="st">&quot;roberta-base&quot;</span></span>
<span id="cb55-21"><a href="#cb55-21" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_name)</span>
<span id="cb55-22"><a href="#cb55-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-23"><a href="#cb55-23" aria-hidden="true" tabindex="-1"></a>MAX_LEN <span class="op">=</span> <span class="dv">512</span></span>
<span id="cb55-24"><a href="#cb55-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-25"><a href="#cb55-25" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tokenize(example):</span>
<span id="cb55-26"><a href="#cb55-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tokenizer(</span>
<span id="cb55-27"><a href="#cb55-27" aria-hidden="true" tabindex="-1"></a>        example[<span class="st">&#39;processed_with_stopwords&#39;</span>],</span>
<span id="cb55-28"><a href="#cb55-28" aria-hidden="true" tabindex="-1"></a>        truncation<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb55-29"><a href="#cb55-29" aria-hidden="true" tabindex="-1"></a>        padding<span class="op">=</span><span class="st">&quot;max_length&quot;</span>,</span>
<span id="cb55-30"><a href="#cb55-30" aria-hidden="true" tabindex="-1"></a>        max_length<span class="op">=</span>MAX_LEN</span>
<span id="cb55-31"><a href="#cb55-31" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb55-32"><a href="#cb55-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-33"><a href="#cb55-33" aria-hidden="true" tabindex="-1"></a>train_ds <span class="op">=</span> train_ds.<span class="bu">map</span>(tokenize, batched<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb55-34"><a href="#cb55-34" aria-hidden="true" tabindex="-1"></a>val_ds   <span class="op">=</span> val_ds.<span class="bu">map</span>(tokenize,   batched<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb55-35"><a href="#cb55-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-36"><a href="#cb55-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Set format for PyTorch</span></span>
<span id="cb55-37"><a href="#cb55-37" aria-hidden="true" tabindex="-1"></a>cols <span class="op">=</span> [<span class="st">&quot;input_ids&quot;</span>, <span class="st">&quot;attention_mask&quot;</span>, <span class="st">&quot;label&quot;</span>]</span>
<span id="cb55-38"><a href="#cb55-38" aria-hidden="true" tabindex="-1"></a>train_ds.set_format(<span class="bu">type</span><span class="op">=</span><span class="st">&quot;torch&quot;</span>, columns<span class="op">=</span>cols)</span>
<span id="cb55-39"><a href="#cb55-39" aria-hidden="true" tabindex="-1"></a>val_ds.set_format(<span class="bu">type</span><span class="op">=</span><span class="st">&quot;torch&quot;</span>,   columns<span class="op">=</span>cols)</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb56"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;b412ea74e5d3410aa1d83bafb851aee1&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb57"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;e79e4240645a4974bee810d395a807d8&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb58"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;3f8578ae9e5949fbbafb96044986ad75&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb59"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;4347dc4bf71249d5bbd08517325a0ce5&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb60"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;f8725e0e6fe7403b93af5e0f5d34a5ee&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb61"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;ed11a109c1854d71b02fffa08c3783d2&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb62"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;d3c1a2c5291c4e09b50f062623b88860&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
</div>
<section id="dataloaders-and-checkpointing" class="cell markdown"
id="NynXhgxHA6sq">
<h3>Dataloaders and Checkpointing</h3>
<p>Batches are small (4) due to 512-token sequences; this is the stable
choice on Colab GPUs and keeps gradient noise manageable. I fine-tune
with AdamW (lr=2e-5) and clip gradients at 1.0 to guard against early
spikes while the classifier head is cold.</p>
<p>RoBERTa occasionally has a missing pad_token_id in the config; I set
it from the tokenizer to prevent masking warnings and ensure consistent
attention masks.</p>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:156,&quot;referenced_widgets&quot;:[&quot;492ff845e6c1406fab914510c6904677&quot;,&quot;dc3a5f12f6254eedb157e63d426034b3&quot;,&quot;93108c7b27d04a3ca08c6f2201bf3b0e&quot;,&quot;b1cf87aaf2584b238dcbfd5a34194018&quot;,&quot;7a0cf3dfa1c74f3bbdfbf0bdcbf81ad4&quot;,&quot;3a6f1eba591d4b20862788fe6f2c41e6&quot;,&quot;a7acf253c5824988a52175691f9fdc19&quot;,&quot;dddab921bd9644bb9c18070274915eeb&quot;,&quot;6f901326043e42f181ae43688af87d58&quot;,&quot;90dcce70df6b495b87497fb213983ae5&quot;,&quot;1178b8ef8fb64e23a9702466de84247f&quot;]}"
id="Se__7NcgGwOM" data-outputId="f719ef92-2e4f-4c9d-e8dd-6ae6b1ad7a70">
<div class="sourceCode" id="cb63"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DataLoaders</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(train_ds, batch_size<span class="op">=</span><span class="dv">4</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>val_loader   <span class="op">=</span> DataLoader(val_ds,   batch_size<span class="op">=</span><span class="dv">4</span>, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Model / Optimiser</span></span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">&quot;cuda&quot;</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">&quot;cpu&quot;</span>)</span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(</span>
<span id="cb63-8"><a href="#cb63-8" aria-hidden="true" tabindex="-1"></a>    model_name, num_labels<span class="op">=</span><span class="bu">len</span>(le.classes_)</span>
<span id="cb63-9"><a href="#cb63-9" aria-hidden="true" tabindex="-1"></a>).to(device)</span>
<span id="cb63-10"><a href="#cb63-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-11"><a href="#cb63-11" aria-hidden="true" tabindex="-1"></a><span class="co"># RoBERTa pad token safety check</span></span>
<span id="cb63-12"><a href="#cb63-12" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> model.config.pad_token_id <span class="kw">is</span> <span class="va">None</span> <span class="kw">and</span> tokenizer.pad_token_id <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb63-13"><a href="#cb63-13" aria-hidden="true" tabindex="-1"></a>    model.config.pad_token_id <span class="op">=</span> tokenizer.pad_token_id</span>
<span id="cb63-14"><a href="#cb63-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-15"><a href="#cb63-15" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> AdamW(model.parameters(), lr<span class="op">=</span><span class="fl">2e-5</span>)</span>
<span id="cb63-16"><a href="#cb63-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-17"><a href="#cb63-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Training + Validation per epoch</span></span>
<span id="cb63-18"><a href="#cb63-18" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb63-19"><a href="#cb63-19" aria-hidden="true" tabindex="-1"></a>best_val_acc <span class="op">=</span> <span class="op">-</span><span class="fl">1.0</span></span>
<span id="cb63-20"><a href="#cb63-20" aria-hidden="true" tabindex="-1"></a>best_state <span class="op">=</span> <span class="va">None</span></span>
<span id="cb63-21"><a href="#cb63-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-22"><a href="#cb63-22" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, epochs <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb63-23"><a href="#cb63-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Train</span></span>
<span id="cb63-24"><a href="#cb63-24" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb63-25"><a href="#cb63-25" aria-hidden="true" tabindex="-1"></a>    train_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb63-26"><a href="#cb63-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-27"><a href="#cb63-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch <span class="kw">in</span> train_loader:</span>
<span id="cb63-28"><a href="#cb63-28" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb63-29"><a href="#cb63-29" aria-hidden="true" tabindex="-1"></a>        batch <span class="op">=</span> {k: v.to(device) <span class="cf">for</span> k, v <span class="kw">in</span> batch.items()}</span>
<span id="cb63-30"><a href="#cb63-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-31"><a href="#cb63-31" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> model(</span>
<span id="cb63-32"><a href="#cb63-32" aria-hidden="true" tabindex="-1"></a>            input_ids<span class="op">=</span>batch[<span class="st">&quot;input_ids&quot;</span>],</span>
<span id="cb63-33"><a href="#cb63-33" aria-hidden="true" tabindex="-1"></a>            attention_mask<span class="op">=</span>batch[<span class="st">&quot;attention_mask&quot;</span>],</span>
<span id="cb63-34"><a href="#cb63-34" aria-hidden="true" tabindex="-1"></a>            labels<span class="op">=</span>batch[<span class="st">&quot;label&quot;</span>]</span>
<span id="cb63-35"><a href="#cb63-35" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb63-36"><a href="#cb63-36" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> outputs.loss</span>
<span id="cb63-37"><a href="#cb63-37" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb63-38"><a href="#cb63-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-39"><a href="#cb63-39" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Gradient clipping</span></span>
<span id="cb63-40"><a href="#cb63-40" aria-hidden="true" tabindex="-1"></a>        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb63-41"><a href="#cb63-41" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb63-42"><a href="#cb63-42" aria-hidden="true" tabindex="-1"></a>        train_loss <span class="op">+=</span> loss.item()</span>
<span id="cb63-43"><a href="#cb63-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-44"><a href="#cb63-44" aria-hidden="true" tabindex="-1"></a>    avg_train_loss <span class="op">=</span> train_loss <span class="op">/</span> <span class="bu">len</span>(train_loader)</span>
<span id="cb63-45"><a href="#cb63-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-46"><a href="#cb63-46" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Validate</span></span>
<span id="cb63-47"><a href="#cb63-47" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb63-48"><a href="#cb63-48" aria-hidden="true" tabindex="-1"></a>    val_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb63-49"><a href="#cb63-49" aria-hidden="true" tabindex="-1"></a>    val_preds, val_labels <span class="op">=</span> [], []</span>
<span id="cb63-50"><a href="#cb63-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-51"><a href="#cb63-51" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb63-52"><a href="#cb63-52" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> batch <span class="kw">in</span> val_loader:</span>
<span id="cb63-53"><a href="#cb63-53" aria-hidden="true" tabindex="-1"></a>            batch <span class="op">=</span> {k: v.to(device) <span class="cf">for</span> k, v <span class="kw">in</span> batch.items()}</span>
<span id="cb63-54"><a href="#cb63-54" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> model(</span>
<span id="cb63-55"><a href="#cb63-55" aria-hidden="true" tabindex="-1"></a>                input_ids<span class="op">=</span>batch[<span class="st">&quot;input_ids&quot;</span>],</span>
<span id="cb63-56"><a href="#cb63-56" aria-hidden="true" tabindex="-1"></a>                attention_mask<span class="op">=</span>batch[<span class="st">&quot;attention_mask&quot;</span>],</span>
<span id="cb63-57"><a href="#cb63-57" aria-hidden="true" tabindex="-1"></a>                labels<span class="op">=</span>batch[<span class="st">&quot;label&quot;</span>]</span>
<span id="cb63-58"><a href="#cb63-58" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb63-59"><a href="#cb63-59" aria-hidden="true" tabindex="-1"></a>            val_loss <span class="op">+=</span> outputs.loss.item()</span>
<span id="cb63-60"><a href="#cb63-60" aria-hidden="true" tabindex="-1"></a>            preds <span class="op">=</span> torch.argmax(outputs.logits, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb63-61"><a href="#cb63-61" aria-hidden="true" tabindex="-1"></a>            val_preds.extend(preds.cpu().numpy())</span>
<span id="cb63-62"><a href="#cb63-62" aria-hidden="true" tabindex="-1"></a>            val_labels.extend(batch[<span class="st">&quot;label&quot;</span>].cpu().numpy())</span>
<span id="cb63-63"><a href="#cb63-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-64"><a href="#cb63-64" aria-hidden="true" tabindex="-1"></a>    avg_val_loss <span class="op">=</span> val_loss <span class="op">/</span> <span class="bu">len</span>(val_loader)</span>
<span id="cb63-65"><a href="#cb63-65" aria-hidden="true" tabindex="-1"></a>    val_acc <span class="op">=</span> accuracy_score(val_labels, val_preds)</span>
<span id="cb63-66"><a href="#cb63-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-67"><a href="#cb63-67" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> val_acc <span class="op">&gt;</span> best_val_acc:</span>
<span id="cb63-68"><a href="#cb63-68" aria-hidden="true" tabindex="-1"></a>        best_val_acc <span class="op">=</span> val_acc</span>
<span id="cb63-69"><a href="#cb63-69" aria-hidden="true" tabindex="-1"></a>        best_state <span class="op">=</span> {k: v.detach().cpu().clone() <span class="cf">for</span> k, v <span class="kw">in</span> model.state_dict().items()}</span>
<span id="cb63-70"><a href="#cb63-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-71"><a href="#cb63-71" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Epoch </span><span class="sc">{</span>epoch<span class="sc">:02d}</span><span class="ss"> | train_loss: </span><span class="sc">{</span>avg_train_loss<span class="sc">:.4f}</span><span class="ss"> | &quot;</span></span>
<span id="cb63-72"><a href="#cb63-72" aria-hidden="true" tabindex="-1"></a>          <span class="ss">f&quot;val_loss: </span><span class="sc">{</span>avg_val_loss<span class="sc">:.4f}</span><span class="ss"> | val_acc: </span><span class="sc">{</span>val_acc<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb64"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;492ff845e6c1406fab914510c6904677&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: [&#39;classifier.dense.bias&#39;, &#39;classifier.dense.weight&#39;, &#39;classifier.out_proj.bias&#39;, &#39;classifier.out_proj.weight&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Epoch 01 | train_loss: 0.8051 | val_loss: 0.8655 | val_acc: 0.7529
Epoch 02 | train_loss: 0.7374 | val_loss: 0.8184 | val_acc: 0.7932
Epoch 03 | train_loss: 0.6601 | val_loss: 0.7511 | val_acc: 0.8057
</code></pre>
</div>
</div>
<section id="evaluation-and-logging" class="cell markdown"
id="CVrx9XUpA_s2">
<h3>Evaluation and Logging</h3>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="ibxF6vtRG0SS" data-outputId="b487cdb0-2901-4b23-deca-0b3a48bad22a">
<div class="sourceCode" id="cb67"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load best weights</span></span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> best_state <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>    model.load_state_dict(best_state)</span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a>preds, labels <span class="op">=</span> [], []</span>
<span id="cb67-7"><a href="#cb67-7" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb67-8"><a href="#cb67-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch <span class="kw">in</span> val_loader:</span>
<span id="cb67-9"><a href="#cb67-9" aria-hidden="true" tabindex="-1"></a>        batch <span class="op">=</span> {k: v.to(device) <span class="cf">for</span> k, v <span class="kw">in</span> batch.items()}</span>
<span id="cb67-10"><a href="#cb67-10" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> model(</span>
<span id="cb67-11"><a href="#cb67-11" aria-hidden="true" tabindex="-1"></a>            input_ids<span class="op">=</span>batch[<span class="st">&quot;input_ids&quot;</span>],</span>
<span id="cb67-12"><a href="#cb67-12" aria-hidden="true" tabindex="-1"></a>            attention_mask<span class="op">=</span>batch[<span class="st">&quot;attention_mask&quot;</span>],</span>
<span id="cb67-13"><a href="#cb67-13" aria-hidden="true" tabindex="-1"></a>        ).logits</span>
<span id="cb67-14"><a href="#cb67-14" aria-hidden="true" tabindex="-1"></a>        preds.extend(torch.argmax(logits, dim<span class="op">=-</span><span class="dv">1</span>).cpu().numpy())</span>
<span id="cb67-15"><a href="#cb67-15" aria-hidden="true" tabindex="-1"></a>        labels.extend(batch[<span class="st">&quot;label&quot;</span>].cpu().numpy())</span>
<span id="cb67-16"><a href="#cb67-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-17"><a href="#cb67-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Validation accuracy:&quot;</span>, accuracy_score(labels, preds))</span>
<span id="cb67-18"><a href="#cb67-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(labels, preds, target_names<span class="op">=</span>le.classes_))</span>
<span id="cb67-19"><a href="#cb67-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-20"><a href="#cb67-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Summary Table</span></span>
<span id="cb67-21"><a href="#cb67-21" aria-hidden="true" tabindex="-1"></a>val_acc <span class="op">=</span> accuracy_score(labels, preds)</span>
<span id="cb67-22"><a href="#cb67-22" aria-hidden="true" tabindex="-1"></a>report <span class="op">=</span> classification_report(labels, preds, target_names<span class="op">=</span>le.classes_, output_dict<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb67-23"><a href="#cb67-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-24"><a href="#cb67-24" aria-hidden="true" tabindex="-1"></a>row <span class="op">=</span> {</span>
<span id="cb67-25"><a href="#cb67-25" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;run&quot;</span>: <span class="st">&quot;roberta_base_methodology_1run_len512&quot;</span>,</span>
<span id="cb67-26"><a href="#cb67-26" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;max_len&quot;</span>: <span class="dv">512</span>,</span>
<span id="cb67-27"><a href="#cb67-27" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;lr&quot;</span>: <span class="fl">2e-5</span>,</span>
<span id="cb67-28"><a href="#cb67-28" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;train_loss&quot;</span>: avg_train_loss,</span>
<span id="cb67-29"><a href="#cb67-29" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;val_loss&quot;</span>: avg_val_loss,</span>
<span id="cb67-30"><a href="#cb67-30" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;val_acc&quot;</span>: val_acc,</span>
<span id="cb67-31"><a href="#cb67-31" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;macro_f1&quot;</span>: report[<span class="st">&quot;macro avg&quot;</span>][<span class="st">&quot;f1-score&quot;</span>]</span>
<span id="cb67-32"><a href="#cb67-32" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb67-33"><a href="#cb67-33" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> label <span class="kw">in</span> le.classes_:</span>
<span id="cb67-34"><a href="#cb67-34" aria-hidden="true" tabindex="-1"></a>    row[<span class="ss">f&quot;recall_</span><span class="sc">{</span>label<span class="sc">.</span>replace(<span class="st">&#39; &#39;</span>, <span class="st">&#39;_&#39;</span>)<span class="sc">}</span><span class="ss">&quot;</span>] <span class="op">=</span> report[label][<span class="st">&quot;recall&quot;</span>]</span>
<span id="cb67-35"><a href="#cb67-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-36"><a href="#cb67-36" aria-hidden="true" tabindex="-1"></a>df_summary <span class="op">=</span> pd.DataFrame([row])</span>
<span id="cb67-37"><a href="#cb67-37" aria-hidden="true" tabindex="-1"></a>csv_name <span class="op">=</span> <span class="ss">f&quot;roberta_methodology_1run_summary_len512.csv&quot;</span></span>
<span id="cb67-38"><a href="#cb67-38" aria-hidden="true" tabindex="-1"></a>df_summary.to_csv(csv_name, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb67-39"><a href="#cb67-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;</span><span class="ch">\n</span><span class="ss">Saved CSV summary to: </span><span class="sc">{</span>csv_name<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>
Validation accuracy: 0.8057296329453895
                                precision    recall  f1-score   support

Design Science / System Design       0.86      0.90      0.88       685
                 Mixed Methods       0.49      0.48      0.48        94
                   Qualitative       0.00      0.00      0.00        18
      Theoretical / Conceptual       0.78      0.75      0.77       320

                      accuracy                           0.81      1117
                     macro avg       0.53      0.53      0.53      1117
                  weighted avg       0.79      0.81      0.80      1117


Saved CSV summary to: roberta_methodology_1run_summary_len512.csv
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f&quot;{metric.capitalize()} is&quot;, len(result))
/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f&quot;{metric.capitalize()} is&quot;, len(result))
/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f&quot;{metric.capitalize()} is&quot;, len(result))
/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f&quot;{metric.capitalize()} is&quot;, len(result))
/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f&quot;{metric.capitalize()} is&quot;, len(result))
/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f&quot;{metric.capitalize()} is&quot;, len(result))
</code></pre>
</div>
</div>
<section id="44-roberta-extended-models-d1-d2-d3" class="cell markdown"
id="0s-fuUrmG6B2">
<h2>4.4 RoBERTa Extended Models (D1, D2, D3)</h2>
<p>Starting from the RoBERTa 512-token baseline, I shifted to a 256
token window (per the token length study) and only altered training bias
not the backbone to see whether minority recalls (Mixed Methods,
Qualitative) could be raised without sinking overall behaviour.</p>
<p>Setup:</p>
<ul>
<li><p>D1, baseline @256, Cross-entropy with label smoothing 0.05, 6%
warm-up, no sampler, no class weights. This is the un-rebalanced
control.</p></li>
<li><p>D2, class-weighted loss, Same schedule as D1, but the loss is
inverse-frequency weighted so rare classes contribute more
signal.</p></li>
<li><p>D3, sampler + class weights + longer warm-up,
WeightedRandomSampler (α = 0.5, cap = 6) to over-sample minority labels
plus class-weighted loss and a 10% warm-up. This tweaks what each batch
contains and how mistakes are penalised.</p></li>
</ul>
<p>Observation:</p>
<ul>
<li><p>D1 keeps major labels strong (DS/SD at about 0.92, TC at about
0.79) but minorities trail (MM at about 0.23, Qual at 0). Macro-F1 at
about 0.49, val acc at about 0.81.</p></li>
<li><p>D2 is the most balanced overall: macro-F1 at about 0.57 with the
highest accuracy (at about 0.83). DS/SD stays high (at about 0.88), MM
improves (at about 0.62), TC remains solid (at about 0.83); Qual still
doesn’t register on this split.</p></li>
<li><p>D3 finally moves Qualitative (at about 0.33) and bumps MM further
(at about 0.66), but DS/SD drops (at about 0.69) and TC softens (at
about 0.59), so accuracy falls; macro-F1 at about 0.52.</p></li>
</ul>
<p>Where this leaves the RoBERTa variants 256 tokens is a safe operating
point for abstracts, and loss-weighting alone (D2) gives the best trade
off meaningful minority gains without eroding dominant classes.</p>
</section>
<section id="set-up-and-utilities" class="cell markdown"
id="teKFco0j-eLJ">
<h3>Set Up and Utilities</h3>
</section>
<div class="cell code" id="v25aCyMzG9It">
<div class="sourceCode" id="cb70"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Reproducibility</span></span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> set_seed(seed<span class="op">=</span><span class="dv">42</span>):</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a>    random.seed(seed)</span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a>    np.random.seed(seed)</span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a>    torch.manual_seed(seed)</span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a>    torch.cuda.manual_seed_all(seed)</span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a>set_seed(<span class="dv">42</span>)</span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-10"><a href="#cb70-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Configuration Dataclass</span></span>
<span id="cb70-11"><a href="#cb70-11" aria-hidden="true" tabindex="-1"></a><span class="at">@dataclass</span></span>
<span id="cb70-12"><a href="#cb70-12" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> RunConfig:</span>
<span id="cb70-13"><a href="#cb70-13" aria-hidden="true" tabindex="-1"></a>    name: <span class="bu">str</span></span>
<span id="cb70-14"><a href="#cb70-14" aria-hidden="true" tabindex="-1"></a>    model_name: <span class="bu">str</span> <span class="op">=</span> <span class="st">&quot;roberta-base&quot;</span></span>
<span id="cb70-15"><a href="#cb70-15" aria-hidden="true" tabindex="-1"></a>    max_len: <span class="bu">int</span> <span class="op">=</span> <span class="dv">256</span></span>
<span id="cb70-16"><a href="#cb70-16" aria-hidden="true" tabindex="-1"></a>    batch_size: <span class="bu">int</span> <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb70-17"><a href="#cb70-17" aria-hidden="true" tabindex="-1"></a>    lr: <span class="bu">float</span> <span class="op">=</span> <span class="fl">2e-5</span></span>
<span id="cb70-18"><a href="#cb70-18" aria-hidden="true" tabindex="-1"></a>    weight_decay: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb70-19"><a href="#cb70-19" aria-hidden="true" tabindex="-1"></a>    epochs: <span class="bu">int</span> <span class="op">=</span> <span class="dv">6</span></span>
<span id="cb70-20"><a href="#cb70-20" aria-hidden="true" tabindex="-1"></a>    patience: <span class="bu">int</span> <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb70-21"><a href="#cb70-21" aria-hidden="true" tabindex="-1"></a>    label_smoothing: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb70-22"><a href="#cb70-22" aria-hidden="true" tabindex="-1"></a>    use_sampler: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span></span>
<span id="cb70-23"><a href="#cb70-23" aria-hidden="true" tabindex="-1"></a>    sampler_alpha: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb70-24"><a href="#cb70-24" aria-hidden="true" tabindex="-1"></a>    sampler_cap: <span class="bu">float</span> <span class="op">=</span> <span class="fl">6.0</span></span>
<span id="cb70-25"><a href="#cb70-25" aria-hidden="true" tabindex="-1"></a>    use_loss_weights: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span></span>
<span id="cb70-26"><a href="#cb70-26" aria-hidden="true" tabindex="-1"></a>    warmup_frac: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb70-27"><a href="#cb70-27" aria-hidden="true" tabindex="-1"></a>    device: <span class="bu">str</span> <span class="op">=</span> <span class="st">&quot;cuda&quot;</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">&quot;cpu&quot;</span></span>
<span id="cb70-28"><a href="#cb70-28" aria-hidden="true" tabindex="-1"></a>    num_workers: <span class="bu">int</span> <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb70-29"><a href="#cb70-29" aria-hidden="true" tabindex="-1"></a>    pin_memory: <span class="bu">bool</span> <span class="op">=</span> <span class="va">True</span></span></code></pre></div>
</div>
<section id="tokenisation-and-dataloaders" class="cell markdown"
id="Vm2D5XhX_nqP">
<h3>Tokenisation and DataLoaders</h3>
<p>I tokenise with RoBERTa’s tokenizer at 256 tokens using max-length
padding to keep batch shapes stable on Colab. The DataLoader is standard
shuffling for D1/D2; for D3 I build a WeightedRandomSampler from class
counts so minority labels appear more often in each batch (tempered by α
and capped, to avoid degeneracy). The loss matches each run: D1 uses
cross-entropy with label smoothing; D2 and D3 use class-weighted
cross-entropy, where weights are the normalised inverse of class
frequencies so rare labels contribute more signal without exploding the
scale.</p>
</section>
<div class="cell code" id="C4irxlNmKs2D">
<div class="sourceCode" id="cb71"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _tok_fn(tokenizer, max_len):</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _inner(ex):</span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> tokenizer(</span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a>            ex[<span class="st">&quot;processed_with_stopwords&quot;</span>],</span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a>            truncation<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a>            padding<span class="op">=</span><span class="st">&quot;max_length&quot;</span>,</span>
<span id="cb71-7"><a href="#cb71-7" aria-hidden="true" tabindex="-1"></a>            max_length<span class="op">=</span>max_len,</span>
<span id="cb71-8"><a href="#cb71-8" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb71-9"><a href="#cb71-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> _inner</span>
<span id="cb71-10"><a href="#cb71-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-11"><a href="#cb71-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_loaders(train_ds, val_ds, cfg: RunConfig, tokenizer, num_classes: <span class="bu">int</span>):</span>
<span id="cb71-12"><a href="#cb71-12" aria-hidden="true" tabindex="-1"></a>    train_tok <span class="op">=</span> train_ds.<span class="bu">map</span>(_tok_fn(tokenizer, cfg.max_len), batched<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb71-13"><a href="#cb71-13" aria-hidden="true" tabindex="-1"></a>    val_tok   <span class="op">=</span> val_ds.<span class="bu">map</span>(_tok_fn(tokenizer, cfg.max_len),   batched<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb71-14"><a href="#cb71-14" aria-hidden="true" tabindex="-1"></a>    cols <span class="op">=</span> [<span class="st">&quot;input_ids&quot;</span>,<span class="st">&quot;attention_mask&quot;</span>,<span class="st">&quot;label&quot;</span>]</span>
<span id="cb71-15"><a href="#cb71-15" aria-hidden="true" tabindex="-1"></a>    train_tok.set_format(<span class="bu">type</span><span class="op">=</span><span class="st">&quot;torch&quot;</span>, columns<span class="op">=</span>cols)</span>
<span id="cb71-16"><a href="#cb71-16" aria-hidden="true" tabindex="-1"></a>    val_tok.set_format(<span class="bu">type</span><span class="op">=</span><span class="st">&quot;torch&quot;</span>,   columns<span class="op">=</span>cols)</span>
<span id="cb71-17"><a href="#cb71-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-18"><a href="#cb71-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> cfg.use_sampler:</span>
<span id="cb71-19"><a href="#cb71-19" aria-hidden="true" tabindex="-1"></a>        train_labels <span class="op">=</span> np.array(train_tok[<span class="st">&quot;label&quot;</span>])</span>
<span id="cb71-20"><a href="#cb71-20" aria-hidden="true" tabindex="-1"></a>        class_counts <span class="op">=</span> np.bincount(train_labels, minlength<span class="op">=</span>num_classes)</span>
<span id="cb71-21"><a href="#cb71-21" aria-hidden="true" tabindex="-1"></a>        class_counts[class_counts <span class="op">==</span> <span class="dv">0</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb71-22"><a href="#cb71-22" aria-hidden="true" tabindex="-1"></a>        w_class <span class="op">=</span> <span class="fl">1.0</span> <span class="op">/</span> np.power(class_counts.astype(np.float64), cfg.sampler_alpha)</span>
<span id="cb71-23"><a href="#cb71-23" aria-hidden="true" tabindex="-1"></a>        w_class <span class="op">=</span> w_class <span class="op">/</span> w_class.mean()</span>
<span id="cb71-24"><a href="#cb71-24" aria-hidden="true" tabindex="-1"></a>        w_class <span class="op">=</span> np.minimum(w_class, cfg.sampler_cap)</span>
<span id="cb71-25"><a href="#cb71-25" aria-hidden="true" tabindex="-1"></a>        sample_weights <span class="op">=</span> w_class[train_labels]</span>
<span id="cb71-26"><a href="#cb71-26" aria-hidden="true" tabindex="-1"></a>        sampler <span class="op">=</span> WeightedRandomSampler(sample_weights, num_samples<span class="op">=</span><span class="bu">len</span>(sample_weights), replacement<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb71-27"><a href="#cb71-27" aria-hidden="true" tabindex="-1"></a>        train_loader <span class="op">=</span> DataLoader(train_tok, batch_size<span class="op">=</span>cfg.batch_size, sampler<span class="op">=</span>sampler,</span>
<span id="cb71-28"><a href="#cb71-28" aria-hidden="true" tabindex="-1"></a>                                  num_workers<span class="op">=</span>cfg.num_workers, pin_memory<span class="op">=</span>cfg.pin_memory)</span>
<span id="cb71-29"><a href="#cb71-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb71-30"><a href="#cb71-30" aria-hidden="true" tabindex="-1"></a>        train_loader <span class="op">=</span> DataLoader(train_tok, batch_size<span class="op">=</span>cfg.batch_size, shuffle<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb71-31"><a href="#cb71-31" aria-hidden="true" tabindex="-1"></a>                                  num_workers<span class="op">=</span>cfg.num_workers, pin_memory<span class="op">=</span>cfg.pin_memory)</span>
<span id="cb71-32"><a href="#cb71-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-33"><a href="#cb71-33" aria-hidden="true" tabindex="-1"></a>    val_loader <span class="op">=</span> DataLoader(val_tok, batch_size<span class="op">=</span>cfg.batch_size, shuffle<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb71-34"><a href="#cb71-34" aria-hidden="true" tabindex="-1"></a>                            num_workers<span class="op">=</span>cfg.num_workers, pin_memory<span class="op">=</span>cfg.pin_memory)</span>
<span id="cb71-35"><a href="#cb71-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> train_loader, val_loader</span>
<span id="cb71-36"><a href="#cb71-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-37"><a href="#cb71-37" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_loss(cfg: RunConfig, train_loader, num_classes: <span class="bu">int</span>):</span>
<span id="cb71-38"><a href="#cb71-38" aria-hidden="true" tabindex="-1"></a>    weight <span class="op">=</span> <span class="va">None</span></span>
<span id="cb71-39"><a href="#cb71-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> cfg.use_loss_weights:</span>
<span id="cb71-40"><a href="#cb71-40" aria-hidden="true" tabindex="-1"></a>        labels <span class="op">=</span> np.array(train_loader.dataset[<span class="st">&quot;label&quot;</span>])</span>
<span id="cb71-41"><a href="#cb71-41" aria-hidden="true" tabindex="-1"></a>        counts <span class="op">=</span> np.bincount(labels, minlength<span class="op">=</span>num_classes)</span>
<span id="cb71-42"><a href="#cb71-42" aria-hidden="true" tabindex="-1"></a>        counts[counts <span class="op">==</span> <span class="dv">0</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb71-43"><a href="#cb71-43" aria-hidden="true" tabindex="-1"></a>        raw_w  <span class="op">=</span> (<span class="bu">len</span>(labels) <span class="op">/</span> (num_classes <span class="op">*</span> counts.astype(np.float64)))</span>
<span id="cb71-44"><a href="#cb71-44" aria-hidden="true" tabindex="-1"></a>        norm_w <span class="op">=</span> raw_w <span class="op">/</span> raw_w.mean()</span>
<span id="cb71-45"><a href="#cb71-45" aria-hidden="true" tabindex="-1"></a>        weight <span class="op">=</span> torch.tensor(norm_w, dtype<span class="op">=</span>torch.<span class="bu">float</span>, device<span class="op">=</span>cfg.device)</span>
<span id="cb71-46"><a href="#cb71-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-47"><a href="#cb71-47" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb71-48"><a href="#cb71-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> nn.CrossEntropyLoss(weight<span class="op">=</span>weight, label_smoothing<span class="op">=</span>cfg.label_smoothing)</span>
<span id="cb71-49"><a href="#cb71-49" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">TypeError</span>:</span>
<span id="cb71-50"><a href="#cb71-50" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> nn.CrossEntropyLoss(weight<span class="op">=</span>weight)</span></code></pre></div>
</div>
<section id="runner" class="cell markdown" id="9WFgYX2rAium">
<h3>Runner</h3>
<p>For each config I fine-tune with AdamW, a linear warm-up (per the
run’s fraction), and gradient clipping at 1.0. I monitor validation loss
each epoch and use early stopping (patience=2) to avoid overfitting the
fold. After restoring the best-loss checkpoint, I compute accuracy,
macro-F1, and per-class recall via classification_report. Each run
writes a one-row summary to a CSV with the training knobs, val_acc,
macro_f1, val_loss, and the four recalls (Design Science/System Design,
Mixed Methods, Qualitative, Theoretical/Conceptual). Keeping this schema
identical to the SciBERT extended runs lets me drop these rows straight
into the Section 5 tables/plots (macro-F1 bars and per-class recall
heatmaps) without additional wrangling.</p>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:772,&quot;referenced_widgets&quot;:[&quot;fb7d16d7b85849b58c1bcecae1ef91be&quot;,&quot;85d39b9cf057466c8c94137d5ac2a6fa&quot;,&quot;6d7f4db2dd5c468cb11cf343b5c386df&quot;,&quot;49f8d4b3528a4efe99c39af7b6b50f14&quot;,&quot;e0a68a1bea004f219d00c9ec83414b76&quot;,&quot;67680755884d41c298e7ddc5504a1b1b&quot;,&quot;2b8fec1e7c0c415f86eec15bf7a6d09a&quot;,&quot;02a15d1c2e6c4c66af3e13f7d0341fde&quot;,&quot;3438aca1628c4b5eb98cccd3cc23a94a&quot;,&quot;8d4e095953784796bec904fbeb300561&quot;,&quot;42f9e5f1753a4222b8cf2ddc25e24a71&quot;,&quot;58f38624015441479d5c76e19fd4216b&quot;,&quot;f8c9db3b02d34617b6e5cf506b3c771b&quot;,&quot;732763dfdaa34a71908ce6111b7d0227&quot;,&quot;dae01fb71fd94bb897fc40681aefe6ec&quot;,&quot;bff0525c33a04859b70edcd820b2db50&quot;,&quot;658aa2d7062346dd87bdf4040307aed3&quot;,&quot;49734ba481a54839865f8881b4ffc8f6&quot;,&quot;eb5ce0cabd204fff9f866202b27c783f&quot;,&quot;e0b276095b8e40a8a45e4a928195b8a0&quot;,&quot;92d798a84e184f2790421801c49e9932&quot;,&quot;75a0925c6b5b4910a2ce11b74efb5eae&quot;,&quot;be94152a4b48460ca3a85e120c3e06f0&quot;,&quot;f5ac6f9d63a34b21b3502268bffce5a1&quot;,&quot;f1b0e441059148f2a41e667cf2073b98&quot;,&quot;0d8ce0947228436fb0e97646e1d2a93c&quot;,&quot;b39b9164ef754a69999ff632f3ff1e14&quot;,&quot;08f83fb2c95243e0945cb0cb2dca0491&quot;,&quot;91eb1ce2867543e2b9b681a44bbba709&quot;,&quot;373bc17d72774ead93fc9eba5aff4f2a&quot;,&quot;64b7375ab99744c28bceb74dc8df9074&quot;,&quot;4a25933b56b24b77b251ec35d34f5cdc&quot;,&quot;51889f99232a4a9f80ea2a49e86f584e&quot;,&quot;35227f820c30464f988c1702048d63e1&quot;,&quot;ca8994d615e044f9a016b450be02d17d&quot;,&quot;84663c45bec542759a796c38d7ef813c&quot;,&quot;5fcee7197c8b42dfa8190062be64b9fa&quot;,&quot;17e26269732748488476084a5db44885&quot;,&quot;762ecd7957cf4f4ab397bba29a1ce6ed&quot;,&quot;27647fc3c43f4ea5a09f76f9b03a7883&quot;,&quot;8ee23444f9b64dd88378d858608772ae&quot;,&quot;0d1f5dc90f1d4cf298baea58c58702d5&quot;,&quot;842c5969a60c433f9d8035a7bd7fd5fa&quot;,&quot;1e14720163f44e3695cc0dabdd007dce&quot;,&quot;954483e78a7b42cd9d6c64936ae05447&quot;,&quot;1ba0ec6dd23d45ec85a71f674c088735&quot;,&quot;ce825521656543f39a2b52251db2e299&quot;,&quot;8b5bd48d94a04fbb9bf52077a4b0b530&quot;,&quot;70382b083b134ae78f122c5d716a0ae8&quot;,&quot;72a18708f305448d8a2545cc6e87f0e3&quot;,&quot;fdfb619f62eb4955b297ef0556d492bc&quot;,&quot;7ab65923dca147269f2897a65008bdb8&quot;,&quot;6feb3cf33ac24e33ac18c7159629f564&quot;,&quot;eb0760e8067a46e9a21731363d07ad2d&quot;,&quot;71824d61ef744a71a4091fb2e94a06e7&quot;,&quot;ff266790b6264d8c885ceb12a9a6b9da&quot;,&quot;b6c3360ed21645f384e9e4cfde03237d&quot;,&quot;6bdd306bbeaf41789b788dffd8192924&quot;,&quot;e41780aa31e34eab90738c6b7571d63a&quot;,&quot;4490faefed154d44992bd36b536908bf&quot;,&quot;a1786828e3d04d689ab08fbb6b6522ee&quot;,&quot;efb3a6740d314b24aa02fc9166ac5ae2&quot;,&quot;02acfc45db3f4f63a59522b3823e0158&quot;,&quot;f6652a71654445e4a3c846131b515997&quot;,&quot;238a03f9f13f4a1e8a86f9316760714e&quot;,&quot;8e1980b3155e4550a842265427dc8aee&quot;]}"
id="uf879xcgKvwi" data-outputId="06501083-7284-4e7b-8802-0f8d44613809">
<div class="sourceCode" id="cb72"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> run_3_configs_for_label_roberta(df: pd.DataFrame, label_col: <span class="bu">str</span>) <span class="op">-&gt;</span> pd.DataFrame:</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> <span class="st">&quot;processed_with_stopwords&quot;</span> <span class="kw">in</span> df.columns <span class="kw">and</span> label_col <span class="kw">in</span> df.columns</span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a>    set_seed(<span class="dv">42</span>)</span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a>    df_task <span class="op">=</span> df[df[label_col].notnull()].copy().reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb72-6"><a href="#cb72-6" aria-hidden="true" tabindex="-1"></a>    le <span class="op">=</span> LabelEncoder()</span>
<span id="cb72-7"><a href="#cb72-7" aria-hidden="true" tabindex="-1"></a>    df_task[<span class="st">&quot;label&quot;</span>] <span class="op">=</span> le.fit_transform(df_task[label_col])</span>
<span id="cb72-8"><a href="#cb72-8" aria-hidden="true" tabindex="-1"></a>    num_classes <span class="op">=</span> <span class="bu">len</span>(le.classes_)</span>
<span id="cb72-9"><a href="#cb72-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-10"><a href="#cb72-10" aria-hidden="true" tabindex="-1"></a>    full_ds <span class="op">=</span> Dataset.from_pandas(df_task[[<span class="st">&quot;processed_with_stopwords&quot;</span>,<span class="st">&quot;label&quot;</span>]])</span>
<span id="cb72-11"><a href="#cb72-11" aria-hidden="true" tabindex="-1"></a>    splits  <span class="op">=</span> full_ds.train_test_split(test_size<span class="op">=</span><span class="fl">0.2</span>, seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb72-12"><a href="#cb72-12" aria-hidden="true" tabindex="-1"></a>    train_ds, val_ds <span class="op">=</span> splits[<span class="st">&quot;train&quot;</span>], splits[<span class="st">&quot;test&quot;</span>]</span>
<span id="cb72-13"><a href="#cb72-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-14"><a href="#cb72-14" aria-hidden="true" tabindex="-1"></a>    runs: List[RunConfig] <span class="op">=</span> [</span>
<span id="cb72-15"><a href="#cb72-15" aria-hidden="true" tabindex="-1"></a>        RunConfig(name<span class="op">=</span><span class="st">&quot;D1_baseline_len256&quot;</span>, lr<span class="op">=</span><span class="fl">3e-5</span>, warmup_frac<span class="op">=</span><span class="fl">0.06</span>, label_smoothing<span class="op">=</span><span class="fl">0.05</span>),</span>
<span id="cb72-16"><a href="#cb72-16" aria-hidden="true" tabindex="-1"></a>        RunConfig(name<span class="op">=</span><span class="st">&quot;D2_lossweights_len256&quot;</span>, lr<span class="op">=</span><span class="fl">2e-5</span>, warmup_frac<span class="op">=</span><span class="fl">0.06</span>, use_loss_weights<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb72-17"><a href="#cb72-17" aria-hidden="true" tabindex="-1"></a>        RunConfig(name<span class="op">=</span><span class="st">&quot;D3_combo_len256&quot;</span>, lr<span class="op">=</span><span class="fl">1e-5</span>, warmup_frac<span class="op">=</span><span class="fl">0.10</span>, use_sampler<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb72-18"><a href="#cb72-18" aria-hidden="true" tabindex="-1"></a>                  use_loss_weights<span class="op">=</span><span class="va">True</span>, sampler_alpha<span class="op">=</span><span class="fl">0.5</span>, sampler_cap<span class="op">=</span><span class="fl">6.0</span>),</span>
<span id="cb72-19"><a href="#cb72-19" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb72-20"><a href="#cb72-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> run_once(cfg: RunConfig) <span class="op">-&gt;</span> Dict[<span class="bu">str</span>, Any]:</span>
<span id="cb72-21"><a href="#cb72-21" aria-hidden="true" tabindex="-1"></a>        set_seed(<span class="dv">42</span>)</span>
<span id="cb72-22"><a href="#cb72-22" aria-hidden="true" tabindex="-1"></a>        t0 <span class="op">=</span> time.time()</span>
<span id="cb72-23"><a href="#cb72-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-24"><a href="#cb72-24" aria-hidden="true" tabindex="-1"></a>        tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(cfg.model_name, use_fast<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb72-25"><a href="#cb72-25" aria-hidden="true" tabindex="-1"></a>        train_loader, val_loader <span class="op">=</span> build_loaders(train_ds, val_ds, cfg, tokenizer, num_classes)</span>
<span id="cb72-26"><a href="#cb72-26" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(cfg.model_name, num_labels<span class="op">=</span>num_classes).to(cfg.device)</span>
<span id="cb72-27"><a href="#cb72-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> model.config.pad_token_id <span class="kw">is</span> <span class="va">None</span> <span class="kw">and</span> tokenizer.pad_token_id <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb72-28"><a href="#cb72-28" aria-hidden="true" tabindex="-1"></a>            model.config.pad_token_id <span class="op">=</span> tokenizer.pad_token_id</span>
<span id="cb72-29"><a href="#cb72-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-30"><a href="#cb72-30" aria-hidden="true" tabindex="-1"></a>        optimizer <span class="op">=</span> torch.optim.AdamW(model.parameters(), lr<span class="op">=</span>cfg.lr, weight_decay<span class="op">=</span>cfg.weight_decay)</span>
<span id="cb72-31"><a href="#cb72-31" aria-hidden="true" tabindex="-1"></a>        total_steps <span class="op">=</span> <span class="bu">len</span>(train_loader) <span class="op">*</span> cfg.epochs</span>
<span id="cb72-32"><a href="#cb72-32" aria-hidden="true" tabindex="-1"></a>        scheduler <span class="op">=</span> get_linear_schedule_with_warmup(</span>
<span id="cb72-33"><a href="#cb72-33" aria-hidden="true" tabindex="-1"></a>            optimizer,</span>
<span id="cb72-34"><a href="#cb72-34" aria-hidden="true" tabindex="-1"></a>            num_warmup_steps<span class="op">=</span><span class="bu">int</span>(cfg.warmup_frac <span class="op">*</span> total_steps),</span>
<span id="cb72-35"><a href="#cb72-35" aria-hidden="true" tabindex="-1"></a>            num_training_steps<span class="op">=</span>total_steps</span>
<span id="cb72-36"><a href="#cb72-36" aria-hidden="true" tabindex="-1"></a>        ) <span class="cf">if</span> cfg.warmup_frac <span class="kw">and</span> total_steps <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="va">None</span></span>
<span id="cb72-37"><a href="#cb72-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-38"><a href="#cb72-38" aria-hidden="true" tabindex="-1"></a>        loss_fct <span class="op">=</span> build_loss(cfg, train_loader, num_classes)</span>
<span id="cb72-39"><a href="#cb72-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-40"><a href="#cb72-40" aria-hidden="true" tabindex="-1"></a>        best_val_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">&quot;inf&quot;</span>)<span class="op">;</span> best_state <span class="op">=</span> <span class="va">None</span><span class="op">;</span> patience_ctr <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb72-41"><a href="#cb72-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-42"><a href="#cb72-42" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, cfg.epochs <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb72-43"><a href="#cb72-43" aria-hidden="true" tabindex="-1"></a>            model.train()<span class="op">;</span> tr_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb72-44"><a href="#cb72-44" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> batch <span class="kw">in</span> train_loader:</span>
<span id="cb72-45"><a href="#cb72-45" aria-hidden="true" tabindex="-1"></a>                optimizer.zero_grad()</span>
<span id="cb72-46"><a href="#cb72-46" aria-hidden="true" tabindex="-1"></a>                batch <span class="op">=</span> {k: v.to(cfg.device) <span class="cf">for</span> k, v <span class="kw">in</span> batch.items()}</span>
<span id="cb72-47"><a href="#cb72-47" aria-hidden="true" tabindex="-1"></a>                out <span class="op">=</span> model(input_ids<span class="op">=</span>batch[<span class="st">&quot;input_ids&quot;</span>], attention_mask<span class="op">=</span>batch[<span class="st">&quot;attention_mask&quot;</span>])</span>
<span id="cb72-48"><a href="#cb72-48" aria-hidden="true" tabindex="-1"></a>                loss <span class="op">=</span> loss_fct(out.logits, batch[<span class="st">&quot;label&quot;</span>])</span>
<span id="cb72-49"><a href="#cb72-49" aria-hidden="true" tabindex="-1"></a>                loss.backward()</span>
<span id="cb72-50"><a href="#cb72-50" aria-hidden="true" tabindex="-1"></a>                torch.nn.utils.clip_grad_norm_(model.parameters(), <span class="fl">1.0</span>)</span>
<span id="cb72-51"><a href="#cb72-51" aria-hidden="true" tabindex="-1"></a>                optimizer.step()</span>
<span id="cb72-52"><a href="#cb72-52" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> scheduler <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>: scheduler.step()</span>
<span id="cb72-53"><a href="#cb72-53" aria-hidden="true" tabindex="-1"></a>                tr_loss <span class="op">+=</span> loss.item()</span>
<span id="cb72-54"><a href="#cb72-54" aria-hidden="true" tabindex="-1"></a>            avg_tr <span class="op">=</span> tr_loss <span class="op">/</span> <span class="bu">max</span>(<span class="dv">1</span>, <span class="bu">len</span>(train_loader))</span>
<span id="cb72-55"><a href="#cb72-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-56"><a href="#cb72-56" aria-hidden="true" tabindex="-1"></a>            model.<span class="bu">eval</span>()<span class="op">;</span> va_loss <span class="op">=</span> <span class="fl">0.0</span><span class="op">;</span> preds, labels <span class="op">=</span> [], []</span>
<span id="cb72-57"><a href="#cb72-57" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> torch.no_grad():</span>
<span id="cb72-58"><a href="#cb72-58" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> batch <span class="kw">in</span> val_loader:</span>
<span id="cb72-59"><a href="#cb72-59" aria-hidden="true" tabindex="-1"></a>                    batch <span class="op">=</span> {k: v.to(cfg.device) <span class="cf">for</span> k, v <span class="kw">in</span> batch.items()}</span>
<span id="cb72-60"><a href="#cb72-60" aria-hidden="true" tabindex="-1"></a>                    out <span class="op">=</span> model(input_ids<span class="op">=</span>batch[<span class="st">&quot;input_ids&quot;</span>], attention_mask<span class="op">=</span>batch[<span class="st">&quot;attention_mask&quot;</span>])</span>
<span id="cb72-61"><a href="#cb72-61" aria-hidden="true" tabindex="-1"></a>                    loss <span class="op">=</span> loss_fct(out.logits, batch[<span class="st">&quot;label&quot;</span>])</span>
<span id="cb72-62"><a href="#cb72-62" aria-hidden="true" tabindex="-1"></a>                    va_loss <span class="op">+=</span> loss.item()</span>
<span id="cb72-63"><a href="#cb72-63" aria-hidden="true" tabindex="-1"></a>                    preds.extend(torch.argmax(out.logits, dim<span class="op">=-</span><span class="dv">1</span>).cpu().numpy())</span>
<span id="cb72-64"><a href="#cb72-64" aria-hidden="true" tabindex="-1"></a>                    labels.extend(batch[<span class="st">&quot;label&quot;</span>].cpu().numpy())</span>
<span id="cb72-65"><a href="#cb72-65" aria-hidden="true" tabindex="-1"></a>            avg_va <span class="op">=</span> va_loss <span class="op">/</span> <span class="bu">max</span>(<span class="dv">1</span>, <span class="bu">len</span>(val_loader))</span>
<span id="cb72-66"><a href="#cb72-66" aria-hidden="true" tabindex="-1"></a>            val_acc <span class="op">=</span> accuracy_score(labels, preds)</span>
<span id="cb72-67"><a href="#cb72-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-68"><a href="#cb72-68" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot;[</span><span class="sc">{</span>label_col<span class="sc">}</span><span class="ss"> | </span><span class="sc">{</span>cfg<span class="sc">.</span>name<span class="sc">}</span><span class="ss">] Epoch </span><span class="sc">{</span>epoch<span class="sc">:02d}</span><span class="ss"> | train_loss: </span><span class="sc">{</span>avg_tr<span class="sc">:.4f}</span><span class="ss"> | &quot;</span></span>
<span id="cb72-69"><a href="#cb72-69" aria-hidden="true" tabindex="-1"></a>                  <span class="ss">f&quot;val_loss: </span><span class="sc">{</span>avg_va<span class="sc">:.4f}</span><span class="ss"> | val_acc: </span><span class="sc">{</span>val_acc<span class="sc">:.4f}</span><span class="ss"> | patience </span><span class="sc">{</span>patience_ctr<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>cfg<span class="sc">.</span>patience<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb72-70"><a href="#cb72-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-71"><a href="#cb72-71" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> avg_va <span class="op">&lt;</span> best_val_loss:</span>
<span id="cb72-72"><a href="#cb72-72" aria-hidden="true" tabindex="-1"></a>                best_val_loss <span class="op">=</span> avg_va</span>
<span id="cb72-73"><a href="#cb72-73" aria-hidden="true" tabindex="-1"></a>                best_state <span class="op">=</span> {k: v.detach().cpu().clone() <span class="cf">for</span> k, v <span class="kw">in</span> model.state_dict().items()}</span>
<span id="cb72-74"><a href="#cb72-74" aria-hidden="true" tabindex="-1"></a>                patience_ctr <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb72-75"><a href="#cb72-75" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb72-76"><a href="#cb72-76" aria-hidden="true" tabindex="-1"></a>                patience_ctr <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb72-77"><a href="#cb72-77" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> patience_ctr <span class="op">&gt;=</span> cfg.patience:</span>
<span id="cb72-78"><a href="#cb72-78" aria-hidden="true" tabindex="-1"></a>                    <span class="bu">print</span>(<span class="ss">f&quot;[</span><span class="sc">{</span>label_col<span class="sc">}</span><span class="ss"> | </span><span class="sc">{</span>cfg<span class="sc">.</span>name<span class="sc">}</span><span class="ss">] Early stopping.&quot;</span>)</span>
<span id="cb72-79"><a href="#cb72-79" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">break</span></span>
<span id="cb72-80"><a href="#cb72-80" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> best_state <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb72-81"><a href="#cb72-81" aria-hidden="true" tabindex="-1"></a>            model.load_state_dict(best_state)</span>
<span id="cb72-82"><a href="#cb72-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-83"><a href="#cb72-83" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">eval</span>()<span class="op">;</span> preds, labels <span class="op">=</span> [], []</span>
<span id="cb72-84"><a href="#cb72-84" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb72-85"><a href="#cb72-85" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> batch <span class="kw">in</span> val_loader:</span>
<span id="cb72-86"><a href="#cb72-86" aria-hidden="true" tabindex="-1"></a>                batch <span class="op">=</span> {k: v.to(cfg.device) <span class="cf">for</span> k, v <span class="kw">in</span> batch.items()}</span>
<span id="cb72-87"><a href="#cb72-87" aria-hidden="true" tabindex="-1"></a>                logits <span class="op">=</span> model(input_ids<span class="op">=</span>batch[<span class="st">&quot;input_ids&quot;</span>], attention_mask<span class="op">=</span>batch[<span class="st">&quot;attention_mask&quot;</span>]).logits</span>
<span id="cb72-88"><a href="#cb72-88" aria-hidden="true" tabindex="-1"></a>                preds.extend(torch.argmax(logits, dim<span class="op">=-</span><span class="dv">1</span>).cpu().numpy())</span>
<span id="cb72-89"><a href="#cb72-89" aria-hidden="true" tabindex="-1"></a>                labels.extend(batch[<span class="st">&quot;label&quot;</span>].cpu().numpy())</span>
<span id="cb72-90"><a href="#cb72-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-91"><a href="#cb72-91" aria-hidden="true" tabindex="-1"></a>        rep <span class="op">=</span> classification_report(labels, preds, target_names<span class="op">=</span><span class="bu">list</span>(le.classes_),</span>
<span id="cb72-92"><a href="#cb72-92" aria-hidden="true" tabindex="-1"></a>                                    output_dict<span class="op">=</span><span class="va">True</span>, zero_division<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb72-93"><a href="#cb72-93" aria-hidden="true" tabindex="-1"></a>        macro_f1 <span class="op">=</span> rep[<span class="st">&quot;macro avg&quot;</span>][<span class="st">&quot;f1-score&quot;</span>]</span>
<span id="cb72-94"><a href="#cb72-94" aria-hidden="true" tabindex="-1"></a>        per_class <span class="op">=</span> {<span class="ss">f&quot;recall_</span><span class="sc">{</span>cls<span class="sc">.</span>replace(<span class="st">&#39;/&#39;</span>, <span class="st">&#39;-&#39;</span>)<span class="sc">.</span>replace(<span class="st">&#39; &#39;</span>, <span class="st">&#39;_&#39;</span>)<span class="sc">}</span><span class="ss">&quot;</span>: rep[cls][<span class="st">&quot;recall&quot;</span>] <span class="cf">for</span> cls <span class="kw">in</span> le.classes_}</span>
<span id="cb72-95"><a href="#cb72-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-96"><a href="#cb72-96" aria-hidden="true" tabindex="-1"></a>        row <span class="op">=</span> {</span>
<span id="cb72-97"><a href="#cb72-97" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;run&quot;</span>: cfg.name, <span class="st">&quot;max_len&quot;</span>: cfg.max_len, <span class="st">&quot;lr&quot;</span>: cfg.lr,</span>
<span id="cb72-98"><a href="#cb72-98" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;warmup&quot;</span>: cfg.warmup_frac, <span class="st">&quot;sampler&quot;</span>: cfg.use_sampler,</span>
<span id="cb72-99"><a href="#cb72-99" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;alpha&quot;</span>: cfg.sampler_alpha <span class="cf">if</span> cfg.use_sampler <span class="cf">else</span> <span class="fl">0.0</span>,</span>
<span id="cb72-100"><a href="#cb72-100" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;loss_weights&quot;</span>: cfg.use_loss_weights, <span class="st">&quot;val_acc&quot;</span>: rep[<span class="st">&quot;accuracy&quot;</span>],</span>
<span id="cb72-101"><a href="#cb72-101" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;macro_f1&quot;</span>: macro_f1, <span class="st">&quot;val_loss&quot;</span>: <span class="bu">round</span>(best_val_loss, <span class="dv">4</span>)</span>
<span id="cb72-102"><a href="#cb72-102" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb72-103"><a href="#cb72-103" aria-hidden="true" tabindex="-1"></a>        row.update(per_class)</span>
<span id="cb72-104"><a href="#cb72-104" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> row</span>
<span id="cb72-105"><a href="#cb72-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-106"><a href="#cb72-106" aria-hidden="true" tabindex="-1"></a>    rows <span class="op">=</span> [run_once(cfg) <span class="cf">for</span> cfg <span class="kw">in</span> runs]</span>
<span id="cb72-107"><a href="#cb72-107" aria-hidden="true" tabindex="-1"></a>    summary <span class="op">=</span> pd.DataFrame(rows).sort_values(by<span class="op">=</span>[<span class="st">&quot;macro_f1&quot;</span>, <span class="st">&quot;val_acc&quot;</span>], ascending<span class="op">=</span><span class="va">False</span>).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb72-108"><a href="#cb72-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-109"><a href="#cb72-109" aria-hidden="true" tabindex="-1"></a>    front <span class="op">=</span> [<span class="st">&quot;run&quot;</span>, <span class="st">&quot;max_len&quot;</span>, <span class="st">&quot;lr&quot;</span>, <span class="st">&quot;warmup&quot;</span>, <span class="st">&quot;sampler&quot;</span>, <span class="st">&quot;alpha&quot;</span>, <span class="st">&quot;loss_weights&quot;</span>, <span class="st">&quot;val_acc&quot;</span>, <span class="st">&quot;macro_f1&quot;</span>, <span class="st">&quot;val_loss&quot;</span>]</span>
<span id="cb72-110"><a href="#cb72-110" aria-hidden="true" tabindex="-1"></a>    recalls <span class="op">=</span> [c <span class="cf">for</span> c <span class="kw">in</span> summary.columns <span class="cf">if</span> c.startswith(<span class="st">&quot;recall_&quot;</span>)]</span>
<span id="cb72-111"><a href="#cb72-111" aria-hidden="true" tabindex="-1"></a>    summary <span class="op">=</span> summary[front <span class="op">+</span> recalls]</span>
<span id="cb72-112"><a href="#cb72-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-113"><a href="#cb72-113" aria-hidden="true" tabindex="-1"></a>    display(summary)</span>
<span id="cb72-114"><a href="#cb72-114" aria-hidden="true" tabindex="-1"></a>    out_csv <span class="op">=</span> <span class="ss">f&quot;roBERTa_</span><span class="sc">{</span>label_col<span class="sc">}</span><span class="ss">_D123_summary_len256.csv&quot;</span></span>
<span id="cb72-115"><a href="#cb72-115" aria-hidden="true" tabindex="-1"></a>    summary.to_csv(out_csv, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb72-116"><a href="#cb72-116" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Saved summary to: </span><span class="sc">{</span>out_csv<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb72-117"><a href="#cb72-117" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> summary</span>
<span id="cb72-118"><a href="#cb72-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-119"><a href="#cb72-119" aria-hidden="true" tabindex="-1"></a><span class="co"># Run for &quot;methodology&quot; label</span></span>
<span id="cb72-120"><a href="#cb72-120" aria-hidden="true" tabindex="-1"></a>summary_methodology <span class="op">=</span> run_3_configs_for_label_roberta(df, <span class="st">&quot;methodology&quot;</span>)</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb73"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;fb7d16d7b85849b58c1bcecae1ef91be&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb74"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;58f38624015441479d5c76e19fd4216b&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: [&#39;classifier.dense.bias&#39;, &#39;classifier.dense.weight&#39;, &#39;classifier.out_proj.bias&#39;, &#39;classifier.out_proj.weight&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>[methodology | D1_baseline_len256] Epoch 01 | train_loss: 0.8922 | val_loss: 0.8550 | val_acc: 0.7538 | patience 0/2
[methodology | D1_baseline_len256] Epoch 02 | train_loss: 0.8023 | val_loss: 0.8692 | val_acc: 0.7645 | patience 0/2
[methodology | D1_baseline_len256] Epoch 03 | train_loss: 0.7653 | val_loss: 0.8305 | val_acc: 0.7833 | patience 1/2
[methodology | D1_baseline_len256] Epoch 04 | train_loss: 0.7035 | val_loss: 0.7584 | val_acc: 0.7968 | patience 0/2
[methodology | D1_baseline_len256] Epoch 05 | train_loss: 0.6317 | val_loss: 0.7445 | val_acc: 0.8093 | patience 0/2
[methodology | D1_baseline_len256] Epoch 06 | train_loss: 0.5802 | val_loss: 0.7514 | val_acc: 0.8245 | patience 0/2
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb77"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;be94152a4b48460ca3a85e120c3e06f0&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb78"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;35227f820c30464f988c1702048d63e1&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: [&#39;classifier.dense.bias&#39;, &#39;classifier.dense.weight&#39;, &#39;classifier.out_proj.bias&#39;, &#39;classifier.out_proj.weight&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>[methodology | D2_lossweights_len256] Epoch 01 | train_loss: 1.1331 | val_loss: 1.1528 | val_acc: 0.7619 | patience 0/2
[methodology | D2_lossweights_len256] Epoch 02 | train_loss: 1.0618 | val_loss: 0.9688 | val_acc: 0.8093 | patience 0/2
[methodology | D2_lossweights_len256] Epoch 03 | train_loss: 0.9128 | val_loss: 0.9445 | val_acc: 0.8326 | patience 0/2
[methodology | D2_lossweights_len256] Epoch 04 | train_loss: 0.7617 | val_loss: 1.0519 | val_acc: 0.8371 | patience 0/2
[methodology | D2_lossweights_len256] Epoch 05 | train_loss: 0.6045 | val_loss: 1.1705 | val_acc: 0.8389 | patience 1/2
[methodology | D2_lossweights_len256] Early stopping.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb81"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;954483e78a7b42cd9d6c64936ae05447&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb82"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;ff266790b6264d8c885ceb12a9a6b9da&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: [&#39;classifier.dense.bias&#39;, &#39;classifier.dense.weight&#39;, &#39;classifier.out_proj.bias&#39;, &#39;classifier.out_proj.weight&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>[methodology | D3_combo_len256] Epoch 01 | train_loss: 1.2340 | val_loss: 1.0149 | val_acc: 0.6509 | patience 0/2
[methodology | D3_combo_len256] Epoch 02 | train_loss: 0.7737 | val_loss: 1.2235 | val_acc: 0.7538 | patience 0/2
[methodology | D3_combo_len256] Epoch 03 | train_loss: 0.5177 | val_loss: 1.2021 | val_acc: 0.8039 | patience 1/2
[methodology | D3_combo_len256] Early stopping.
</code></pre>
</div>
<div class="output display_data">

  <div id="df-116e992b-a3c6-4216-ab4a-ae5e0e5232c0" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>run</th>
      <th>max_len</th>
      <th>lr</th>
      <th>warmup</th>
      <th>sampler</th>
      <th>alpha</th>
      <th>loss_weights</th>
      <th>val_acc</th>
      <th>macro_f1</th>
      <th>val_loss</th>
      <th>recall_Design_Science_-_System_Design</th>
      <th>recall_Mixed_Methods</th>
      <th>recall_Qualitative</th>
      <th>recall_Theoretical_-_Conceptual</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>D2_lossweights_len256</td>
      <td>256</td>
      <td>0.00002</td>
      <td>0.06</td>
      <td>False</td>
      <td>0.0</td>
      <td>True</td>
      <td>0.832587</td>
      <td>0.573381</td>
      <td>0.9445</td>
      <td>0.884672</td>
      <td>0.617021</td>
      <td>0.000000</td>
      <td>0.831250</td>
    </tr>
    <tr>
      <th>1</th>
      <td>D3_combo_len256</td>
      <td>256</td>
      <td>0.00001</td>
      <td>0.10</td>
      <td>True</td>
      <td>0.5</td>
      <td>True</td>
      <td>0.650850</td>
      <td>0.521147</td>
      <td>1.0149</td>
      <td>0.686131</td>
      <td>0.659574</td>
      <td>0.333333</td>
      <td>0.590625</td>
    </tr>
    <tr>
      <th>2</th>
      <td>D1_baseline_len256</td>
      <td>256</td>
      <td>0.00003</td>
      <td>0.06</td>
      <td>False</td>
      <td>0.0</td>
      <td>False</td>
      <td>0.809311</td>
      <td>0.493228</td>
      <td>0.7445</td>
      <td>0.919708</td>
      <td>0.234043</td>
      <td>0.000000</td>
      <td>0.787500</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-116e992b-a3c6-4216-ab4a-ae5e0e5232c0')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-116e992b-a3c6-4216-ab4a-ae5e0e5232c0 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-116e992b-a3c6-4216-ab4a-ae5e0e5232c0');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    <div id="df-bb35c26f-b9de-4afe-9c61-50e3e3344a80">
      <button class="colab-df-quickchart" onclick="quickchart('df-bb35c26f-b9de-4afe-9c61-50e3e3344a80')"
                title="Suggest charts"
                style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
      </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

      <script>
        async function quickchart(key) {
          const quickchartButtonEl =
            document.querySelector('#' + key + ' button');
          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
          quickchartButtonEl.classList.add('colab-df-spinner');
          try {
            const charts = await google.colab.kernel.invokeFunction(
                'suggestCharts', [key], {});
          } catch (error) {
            console.error('Error during call to suggestCharts:', error);
          }
          quickchartButtonEl.classList.remove('colab-df-spinner');
          quickchartButtonEl.classList.add('colab-df-quickchart-complete');
        }
        (() => {
          let quickchartButtonEl =
            document.querySelector('#df-bb35c26f-b9de-4afe-9c61-50e3e3344a80 button');
          quickchartButtonEl.style.display =
            google.colab.kernel.accessAllowed ? 'block' : 'none';
        })();
      </script>
    </div>

    </div>
  </div>

</div>
<div class="output stream stdout">
<pre><code>Saved summary to: roBERTa_methodology_D123_summary_len256.csv
</code></pre>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:439}"
id="645ffhOL5qnp" data-outputId="91952afc-5c50-4a60-c1bd-353775e345eb">
<div class="sourceCode" id="cb86"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Upload CSV</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> google.colab <span class="im">import</span> files</span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a>uploaded <span class="op">=</span> files.upload()</span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> uploaded:</span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">&quot;No file uploaded.&quot;</span>)</span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-8"><a href="#cb86-8" aria-hidden="true" tabindex="-1"></a><span class="co"># multiple files uploaded</span></span>
<span id="cb86-9"><a href="#cb86-9" aria-hidden="true" tabindex="-1"></a>fname, data <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(uploaded.items()))</span>
<span id="cb86-10"><a href="#cb86-10" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(io.BytesIO(data))</span>
<span id="cb86-11"><a href="#cb86-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Loaded: </span><span class="sc">{</span>fname<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb86-12"><a href="#cb86-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-13"><a href="#cb86-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Build heatmap for RoBERTa</span></span>
<span id="cb86-14"><a href="#cb86-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Required columns</span></span>
<span id="cb86-15"><a href="#cb86-15" aria-hidden="true" tabindex="-1"></a>cols <span class="op">=</span> [</span>
<span id="cb86-16"><a href="#cb86-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;recall_Design_Science_-_System_Design&quot;</span>,</span>
<span id="cb86-17"><a href="#cb86-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;recall_Mixed_Methods&quot;</span>,</span>
<span id="cb86-18"><a href="#cb86-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;recall_Qualitative&quot;</span>,</span>
<span id="cb86-19"><a href="#cb86-19" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;recall_Theoretical_-_Conceptual&quot;</span>,</span>
<span id="cb86-20"><a href="#cb86-20" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb86-21"><a href="#cb86-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-22"><a href="#cb86-22" aria-hidden="true" tabindex="-1"></a>required <span class="op">=</span> {<span class="st">&quot;run&quot;</span>, <span class="op">*</span>cols}</span>
<span id="cb86-23"><a href="#cb86-23" aria-hidden="true" tabindex="-1"></a>missing <span class="op">=</span> required.difference(df.columns)</span>
<span id="cb86-24"><a href="#cb86-24" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> missing:</span>
<span id="cb86-25"><a href="#cb86-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f&quot;Missing columns in CSV: </span><span class="sc">{</span>missing<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb86-26"><a href="#cb86-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-27"><a href="#cb86-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-28"><a href="#cb86-28" aria-hidden="true" tabindex="-1"></a>order <span class="op">=</span> [<span class="st">&quot;D1_baseline_len256&quot;</span>, <span class="st">&quot;D2_lossweights_len256&quot;</span>, <span class="st">&quot;D3_combo_len256&quot;</span>]</span>
<span id="cb86-29"><a href="#cb86-29" aria-hidden="true" tabindex="-1"></a>df_c <span class="op">=</span> df[df[<span class="st">&quot;run&quot;</span>].isin(order)].set_index(<span class="st">&quot;run&quot;</span>).loc[order].reset_index()</span>
<span id="cb86-30"><a href="#cb86-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-31"><a href="#cb86-31" aria-hidden="true" tabindex="-1"></a><span class="co"># axis labels</span></span>
<span id="cb86-32"><a href="#cb86-32" aria-hidden="true" tabindex="-1"></a>pretty <span class="op">=</span> [<span class="st">&quot;DesignScience/SystemDesign&quot;</span>, <span class="st">&quot;MixedMethods&quot;</span>, <span class="st">&quot;Qualitative&quot;</span>, <span class="st">&quot;Theoretical/Conceptual&quot;</span>]</span>
<span id="cb86-33"><a href="#cb86-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-34"><a href="#cb86-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot heatmap</span></span>
<span id="cb86-35"><a href="#cb86-35" aria-hidden="true" tabindex="-1"></a>mat <span class="op">=</span> df_c[cols].to_numpy()</span>
<span id="cb86-36"><a href="#cb86-36" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="fl">3.6</span>))</span>
<span id="cb86-37"><a href="#cb86-37" aria-hidden="true" tabindex="-1"></a>plt.imshow(mat, aspect<span class="op">=</span><span class="st">&quot;auto&quot;</span>)</span>
<span id="cb86-38"><a href="#cb86-38" aria-hidden="true" tabindex="-1"></a>plt.xticks(<span class="bu">range</span>(<span class="bu">len</span>(pretty)), pretty, rotation<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb86-39"><a href="#cb86-39" aria-hidden="true" tabindex="-1"></a>plt.yticks(<span class="bu">range</span>(<span class="bu">len</span>(order)), [<span class="st">&quot;RoBERTa D1&quot;</span>, <span class="st">&quot;RoBERTa D2&quot;</span>, <span class="st">&quot;RoBERTa D3&quot;</span>])</span>
<span id="cb86-40"><a href="#cb86-40" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb86-41"><a href="#cb86-41" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;RoBERTa — Per-class Recall (Methodology)&quot;</span>)</span>
<span id="cb86-42"><a href="#cb86-42" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb86-43"><a href="#cb86-43" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">

     <input type="file" id="files-8134a70d-2ff4-4dfc-b9e4-3071c48435dc" name="files[]" multiple disabled
        style="border:none" />
     <output id="result-8134a70d-2ff4-4dfc-b9e4-3071c48435dc">
      Upload widget is only available when the cell has been executed in the
      current browser session. Please rerun this cell to enable.
      </output>
      <script>// Copyright 2017 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

/**
 * @fileoverview Helpers for google.colab Python module.
 */
(function(scope) {
function span(text, styleAttributes = {}) {
  const element = document.createElement('span');
  element.textContent = text;
  for (const key of Object.keys(styleAttributes)) {
    element.style[key] = styleAttributes[key];
  }
  return element;
}

// Max number of bytes which will be uploaded at a time.
const MAX_PAYLOAD_SIZE = 100 * 1024;

function _uploadFiles(inputId, outputId) {
  const steps = uploadFilesStep(inputId, outputId);
  const outputElement = document.getElementById(outputId);
  // Cache steps on the outputElement to make it available for the next call
  // to uploadFilesContinue from Python.
  outputElement.steps = steps;

  return _uploadFilesContinue(outputId);
}

// This is roughly an async generator (not supported in the browser yet),
// where there are multiple asynchronous steps and the Python side is going
// to poll for completion of each step.
// This uses a Promise to block the python side on completion of each step,
// then passes the result of the previous step as the input to the next step.
function _uploadFilesContinue(outputId) {
  const outputElement = document.getElementById(outputId);
  const steps = outputElement.steps;

  const next = steps.next(outputElement.lastPromiseValue);
  return Promise.resolve(next.value.promise).then((value) => {
    // Cache the last promise value to make it available to the next
    // step of the generator.
    outputElement.lastPromiseValue = value;
    return next.value.response;
  });
}

/**
 * Generator function which is called between each async step of the upload
 * process.
 * @param {string} inputId Element ID of the input file picker element.
 * @param {string} outputId Element ID of the output display.
 * @return {!Iterable<!Object>} Iterable of next steps.
 */
function* uploadFilesStep(inputId, outputId) {
  const inputElement = document.getElementById(inputId);
  inputElement.disabled = false;

  const outputElement = document.getElementById(outputId);
  outputElement.innerHTML = '';

  const pickedPromise = new Promise((resolve) => {
    inputElement.addEventListener('change', (e) => {
      resolve(e.target.files);
    });
  });

  const cancel = document.createElement('button');
  inputElement.parentElement.appendChild(cancel);
  cancel.textContent = 'Cancel upload';
  const cancelPromise = new Promise((resolve) => {
    cancel.onclick = () => {
      resolve(null);
    };
  });

  // Wait for the user to pick the files.
  const files = yield {
    promise: Promise.race([pickedPromise, cancelPromise]),
    response: {
      action: 'starting',
    }
  };

  cancel.remove();

  // Disable the input element since further picks are not allowed.
  inputElement.disabled = true;

  if (!files) {
    return {
      response: {
        action: 'complete',
      }
    };
  }

  for (const file of files) {
    const li = document.createElement('li');
    li.append(span(file.name, {fontWeight: 'bold'}));
    li.append(span(
        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +
        `last modified: ${
            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :
                                    'n/a'} - `));
    const percent = span('0% done');
    li.appendChild(percent);

    outputElement.appendChild(li);

    const fileDataPromise = new Promise((resolve) => {
      const reader = new FileReader();
      reader.onload = (e) => {
        resolve(e.target.result);
      };
      reader.readAsArrayBuffer(file);
    });
    // Wait for the data to be ready.
    let fileData = yield {
      promise: fileDataPromise,
      response: {
        action: 'continue',
      }
    };

    // Use a chunked sending to avoid message size limits. See b/62115660.
    let position = 0;
    do {
      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);
      const chunk = new Uint8Array(fileData, position, length);
      position += length;

      const base64 = btoa(String.fromCharCode.apply(null, chunk));
      yield {
        response: {
          action: 'append',
          file: file.name,
          data: base64,
        },
      };

      let percentDone = fileData.byteLength === 0 ?
          100 :
          Math.round((position / fileData.byteLength) * 100);
      percent.textContent = `${percentDone}% done`;

    } while (position < fileData.byteLength);
  }

  // All done.
  yield {
    response: {
      action: 'complete',
    }
  };
}

scope.google = scope.google || {};
scope.google.colab = scope.google.colab || {};
scope.google.colab._files = {
  _uploadFiles,
  _uploadFilesContinue,
};
})(self);
</script> 
</div>
<div class="output stream stdout">
<pre><code>Saving B2_roBERTa_methodology_D123_summary_len256.csv to B2_roBERTa_methodology_D123_summary_len256.csv
Loaded: B2_roBERTa_methodology_D123_summary_len256.csv
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_e37543f3817e498792271d4afeefc0f0/dffa49225d1cd51462db7e65ea2b0f2556e13413.png" /></p>
</div>
</div>
<section id="45-distilbert-model-1" class="cell markdown"
id="VJ_Z3uWHtSvU">
<h2>4.5 DistilBERT Model 1</h2>
<p>I set up DistilBERT as a lighter transformer baseline using the same
recipe as the other Model 1 runs for a fair comparison: an 80/20 split
(seed=42), 512-token context to avoid truncation effects, AdamW (2e-5)
with small batches and gradient clipping, and a short 3-epoch fine-tune.
I select the checkpoint by validation accuracy for stability, while
logging macro-F1 and per-class recall to feed into later plots.</p>
<p>On this configuration the model reached val acc at about 0.829 and
macro-F1 at about 0.56. Recall was strong for Theoretical/Conceptual (at
about 0.85) and Design Science/System Design (at about 0.88), and
notably higher on Mixed Methods (at about 0.56) than the other
baselines, while Qualitative remained low on this split. The result
shows that even a compact encoder can capture most methodology cues well
when given full-abstract context, offering a solid speed/size trade-off
without a large drop in headline metrics.</p>
<p>With a compact model delivering near-SciBERT accuracy and fast
runtime, I keep the training recipe fixed and move on to the extended
DistilBERT variants (E1–E3) to test whether mild rebalancing and
schedule tweaks can raise minority recalls without paying a large
stability cost.</p>
</section>
<section id="tokenisation" class="cell markdown" id="O4XVBpB4estL">
<h3>Tokenisation</h3>
<p>Tokenisation uses distilbert-base-uncased at max_len=512 with
padding="max_length" and truncation matching the other Model 1 baselines
so differences come from pretraining rather than preprocessing.</p>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:209,&quot;referenced_widgets&quot;:[&quot;3d6700ea3d9a4278a7884ebb0447a117&quot;,&quot;a0e677d3dd7d41c3a7a9e3e911b6aa36&quot;,&quot;d121b530152b459284617fc9eadd7af8&quot;,&quot;23e7d6d0851942739f261709dfea7c16&quot;,&quot;3eadfdcd62ca4d129b6de93f1ca5d5cb&quot;,&quot;546e3a5311544bc4a12e417299415a13&quot;,&quot;c2aaad8810874f68abcec4d46cb14fe7&quot;,&quot;d7c74bb0d01942b0b6f32f52dd863605&quot;,&quot;1f9e6ae988cb4f2fa7ae842a72ac4b12&quot;,&quot;388c1241ddd84fb6bd08dc314e3d36d5&quot;,&quot;bbf3f7c2539144a383e0307939be00e9&quot;,&quot;d59feddf10da4d4fb35196dff059f04f&quot;,&quot;eabbd52073e14231b0a320bb9ab87e65&quot;,&quot;1fcc8b1285e045019218462d99b0b667&quot;,&quot;1adadc69fc1b48e8ba97668277c297fc&quot;,&quot;be3bf6612cc14270b4bebeac888b4427&quot;,&quot;8542a6ec4be44fd9a25f065c3784352c&quot;,&quot;bf8b89fa822444bc91c81d7338b56764&quot;,&quot;69bdce1b7f8940d28a721dd3192558ed&quot;,&quot;e0f67ea437aa4ec9aba862238f6b00da&quot;,&quot;d9801698b41a4ca3b74406fbf54af6d3&quot;,&quot;3cdc11dc8f384ebfb816851aee59320d&quot;,&quot;38d45f8df9a24efaa03ab07ab806813b&quot;,&quot;dcd183f5fe0f4a87b030dbd821a9d0b5&quot;,&quot;144e0de115e8491f82b9783782051883&quot;,&quot;45f5a4b718e24d5ab3d875057f4d9bf6&quot;,&quot;24a2436b9fe745b1a0554259cb2d0bec&quot;,&quot;6a967687ecfc4da0b82bb21b13c47248&quot;,&quot;6260133de810404cadf2aeca3cec605e&quot;,&quot;935c0325cb004d36a736711b4003bf73&quot;,&quot;929e16ae2b9f4fea884c32b97fef2d5b&quot;,&quot;dc618fbe0317477cb69f1b20baa85713&quot;,&quot;50366cce07d441c89f986d5223b31580&quot;,&quot;2378864aa3fd4e599ca9be0a0253f8ab&quot;,&quot;fd354046096f4701ae0bb4f9f881d428&quot;,&quot;41f20f94e0a24d41a0cfb60754bfe56a&quot;,&quot;b0a4e05510e14cb6a025313594d4f749&quot;,&quot;9cf9f67bd878496f9ca060dfddb96431&quot;,&quot;050cc1e212684e99987b3a8cab413ea1&quot;,&quot;7f844e5e0cfa4ee8a57911ee9f4f78ae&quot;,&quot;c04c6cd32dac4997a0d3636f4c001057&quot;,&quot;12b4d392396442d28d69c6224539b919&quot;,&quot;c0817a2e22244ed891eb68d979ea2f7d&quot;,&quot;6716842a233b406e9e8d649889c3b038&quot;,&quot;ea2f6a79e6fc47fb8b88cb3431781c4e&quot;,&quot;7dfc2fa6e9cc43f58dfe995cbd20a779&quot;,&quot;d4b33588dcbe49c4836e408de78b1e2c&quot;,&quot;cb52222cf0c84f9db5babff907d57f1c&quot;,&quot;ed0eb861bed84b9fb854c4924f75f465&quot;,&quot;4894befee3d0463b88c5cc20f001e4e6&quot;,&quot;d2671c0fce7243bf840a56f4a6e877fe&quot;,&quot;0b8c3a2a94624185bcb7c6c9a7a7b471&quot;,&quot;2a708834c6ea4c01b479cbf2ffe20b3c&quot;,&quot;5adb8ca94cba4451a370c53555104017&quot;,&quot;7566fbca378b41daad3453dde86c09b2&quot;,&quot;42af08c30fd9426ebc881e4c36f273ca&quot;,&quot;19f0e97bee274abfb80ad751f66374d6&quot;,&quot;a10d7362cd3249139b9f285f7496b86a&quot;,&quot;0144878a248b4e2182a52b8ea5c7a16d&quot;,&quot;68e8d585524e4b7191bfab04d14af5d9&quot;,&quot;04db6148a47c42b7982e0fb5820c8bc5&quot;,&quot;aaff9f085fb846a7b17b717adcfba971&quot;,&quot;e03111f18a6044b5ade90b94bb29dc3c&quot;,&quot;5a96c7d04dfd49b1af1b64d5f985cc36&quot;,&quot;074eb5976992409fbca4d516fdab6edf&quot;,&quot;45e3ae271d1b4d3ca33df05441f97b12&quot;]}"
id="8EoKZKxUtV0b" data-outputId="332e5254-e2a5-4c16-efaf-8ee6c3bc7100">
<div class="sourceCode" id="cb88"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Reproducibility</span></span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> set_seed(seed<span class="op">=</span><span class="dv">42</span>):</span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a>    random.seed(seed)</span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a>    np.random.seed(seed)</span>
<span id="cb88-5"><a href="#cb88-5" aria-hidden="true" tabindex="-1"></a>    torch.manual_seed(seed)</span>
<span id="cb88-6"><a href="#cb88-6" aria-hidden="true" tabindex="-1"></a>    torch.cuda.manual_seed_all(seed)</span>
<span id="cb88-7"><a href="#cb88-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-8"><a href="#cb88-8" aria-hidden="true" tabindex="-1"></a>set_seed(<span class="dv">42</span>)</span>
<span id="cb88-9"><a href="#cb88-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-10"><a href="#cb88-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Load and preprocess</span></span>
<span id="cb88-11"><a href="#cb88-11" aria-hidden="true" tabindex="-1"></a>df_m <span class="op">=</span> df[df[<span class="st">&#39;methodology&#39;</span>].notnull()].copy().reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb88-12"><a href="#cb88-12" aria-hidden="true" tabindex="-1"></a>le <span class="op">=</span> LabelEncoder()</span>
<span id="cb88-13"><a href="#cb88-13" aria-hidden="true" tabindex="-1"></a>df_m[<span class="st">&#39;label&#39;</span>] <span class="op">=</span> le.fit_transform(df_m[<span class="st">&#39;methodology&#39;</span>])</span>
<span id="cb88-14"><a href="#cb88-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-15"><a href="#cb88-15" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> Dataset.from_pandas(df_m[[<span class="st">&#39;processed_with_stopwords&#39;</span>, <span class="st">&#39;label&#39;</span>]])</span>
<span id="cb88-16"><a href="#cb88-16" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> dataset.train_test_split(test_size<span class="op">=</span><span class="fl">0.2</span>, seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb88-17"><a href="#cb88-17" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> dataset[<span class="st">&quot;train&quot;</span>], dataset[<span class="st">&quot;test&quot;</span>]</span>
<span id="cb88-18"><a href="#cb88-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-19"><a href="#cb88-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Tokenisation</span></span>
<span id="cb88-20"><a href="#cb88-20" aria-hidden="true" tabindex="-1"></a>model_name <span class="op">=</span> <span class="st">&quot;distilbert-base-uncased&quot;</span></span>
<span id="cb88-21"><a href="#cb88-21" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_name)</span>
<span id="cb88-22"><a href="#cb88-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-23"><a href="#cb88-23" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tokenize(example):</span>
<span id="cb88-24"><a href="#cb88-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tokenizer(</span>
<span id="cb88-25"><a href="#cb88-25" aria-hidden="true" tabindex="-1"></a>        example[<span class="st">&#39;processed_with_stopwords&#39;</span>],</span>
<span id="cb88-26"><a href="#cb88-26" aria-hidden="true" tabindex="-1"></a>        truncation<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb88-27"><a href="#cb88-27" aria-hidden="true" tabindex="-1"></a>        padding<span class="op">=</span><span class="st">&quot;max_length&quot;</span>,</span>
<span id="cb88-28"><a href="#cb88-28" aria-hidden="true" tabindex="-1"></a>        max_length<span class="op">=</span><span class="dv">512</span></span>
<span id="cb88-29"><a href="#cb88-29" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb88-30"><a href="#cb88-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-31"><a href="#cb88-31" aria-hidden="true" tabindex="-1"></a>train_ds <span class="op">=</span> train_ds.<span class="bu">map</span>(tokenize, batched<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb88-32"><a href="#cb88-32" aria-hidden="true" tabindex="-1"></a>val_ds   <span class="op">=</span> val_ds.<span class="bu">map</span>(tokenize, batched<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb88-33"><a href="#cb88-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-34"><a href="#cb88-34" aria-hidden="true" tabindex="-1"></a>cols <span class="op">=</span> [<span class="st">&quot;input_ids&quot;</span>, <span class="st">&quot;attention_mask&quot;</span>, <span class="st">&quot;label&quot;</span>]</span>
<span id="cb88-35"><a href="#cb88-35" aria-hidden="true" tabindex="-1"></a>train_ds.set_format(<span class="bu">type</span><span class="op">=</span><span class="st">&quot;torch&quot;</span>, columns<span class="op">=</span>cols)</span>
<span id="cb88-36"><a href="#cb88-36" aria-hidden="true" tabindex="-1"></a>val_ds.set_format(<span class="bu">type</span><span class="op">=</span><span class="st">&quot;torch&quot;</span>, columns<span class="op">=</span>cols)</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb89"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;3d6700ea3d9a4278a7884ebb0447a117&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb90"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;d59feddf10da4d4fb35196dff059f04f&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb91"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;38d45f8df9a24efaa03ab07ab806813b&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb92"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;2378864aa3fd4e599ca9be0a0253f8ab&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb93"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;ea2f6a79e6fc47fb8b88cb3431781c4e&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb94"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;42af08c30fd9426ebc881e4c36f273ca&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
</div>
<section id="training-loop" class="cell markdown" id="RSGUcW0xezpc">
<h3>Training Loop</h3>
<p>I build PyTorch DataLoaders (batch=4),
AutoModelForSequenceClassification with AdamW(2e-5), and clip grads at
1.0. I track val accuracy each epoch and remember the best weights,
short schedules on modest data tend to overfit if trained longer;
picking the best epoch acts as a light early-stopping guard.</p>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:156,&quot;referenced_widgets&quot;:[&quot;728fc84e031747a2a570ee9ccb2c59da&quot;,&quot;80aa7cad04c24b7080e02a20d0f973f8&quot;,&quot;c9dc34126217432ca700909ca7000a09&quot;,&quot;7e34d90db3804402968e3dfeae71ef74&quot;,&quot;de713ba077b0446eb06aa4cbed5e72f9&quot;,&quot;837fee6a5d0d4d9d891ee1c441aa5e8f&quot;,&quot;5b184f127e3249018179a0b8247fa577&quot;,&quot;aa72af087eca4f358873845a84f0092c&quot;,&quot;86a57bba702e400586eb70b139af67e6&quot;,&quot;05cd9a93ca2f43e6ab4ff1244b8e731e&quot;,&quot;eb4fe2b09b4e4891ae83f65e130c0755&quot;]}"
id="J0qQ49fVtzTa" data-outputId="1e108e9f-843c-43db-a360-617de8ce5795">
<div class="sourceCode" id="cb95"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Dataloaders</span></span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(train_ds, batch_size<span class="op">=</span><span class="dv">4</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb95-3"><a href="#cb95-3" aria-hidden="true" tabindex="-1"></a>val_loader   <span class="op">=</span> DataLoader(val_ds, batch_size<span class="op">=</span><span class="dv">4</span>, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb95-4"><a href="#cb95-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-5"><a href="#cb95-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Model / Optimiser</span></span>
<span id="cb95-6"><a href="#cb95-6" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">&quot;cuda&quot;</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">&quot;cpu&quot;</span>)</span>
<span id="cb95-7"><a href="#cb95-7" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(</span>
<span id="cb95-8"><a href="#cb95-8" aria-hidden="true" tabindex="-1"></a>    model_name, num_labels<span class="op">=</span><span class="bu">len</span>(le.classes_)</span>
<span id="cb95-9"><a href="#cb95-9" aria-hidden="true" tabindex="-1"></a>).to(device)</span>
<span id="cb95-10"><a href="#cb95-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-11"><a href="#cb95-11" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> AdamW(model.parameters(), lr<span class="op">=</span><span class="fl">2e-5</span>)</span>
<span id="cb95-12"><a href="#cb95-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-13"><a href="#cb95-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Training</span></span>
<span id="cb95-14"><a href="#cb95-14" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb95-15"><a href="#cb95-15" aria-hidden="true" tabindex="-1"></a>best_val_acc <span class="op">=</span> <span class="op">-</span><span class="fl">1.0</span></span>
<span id="cb95-16"><a href="#cb95-16" aria-hidden="true" tabindex="-1"></a>best_state <span class="op">=</span> <span class="va">None</span></span>
<span id="cb95-17"><a href="#cb95-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-18"><a href="#cb95-18" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, epochs <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb95-19"><a href="#cb95-19" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb95-20"><a href="#cb95-20" aria-hidden="true" tabindex="-1"></a>    train_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb95-21"><a href="#cb95-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch <span class="kw">in</span> train_loader:</span>
<span id="cb95-22"><a href="#cb95-22" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb95-23"><a href="#cb95-23" aria-hidden="true" tabindex="-1"></a>        batch <span class="op">=</span> {k: v.to(device) <span class="cf">for</span> k, v <span class="kw">in</span> batch.items()}</span>
<span id="cb95-24"><a href="#cb95-24" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> model(</span>
<span id="cb95-25"><a href="#cb95-25" aria-hidden="true" tabindex="-1"></a>                input_ids<span class="op">=</span>batch[<span class="st">&quot;input_ids&quot;</span>],</span>
<span id="cb95-26"><a href="#cb95-26" aria-hidden="true" tabindex="-1"></a>                attention_mask<span class="op">=</span>batch[<span class="st">&quot;attention_mask&quot;</span>],</span>
<span id="cb95-27"><a href="#cb95-27" aria-hidden="true" tabindex="-1"></a>                labels<span class="op">=</span>batch[<span class="st">&quot;label&quot;</span>]</span>
<span id="cb95-28"><a href="#cb95-28" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb95-29"><a href="#cb95-29" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> outputs.loss</span>
<span id="cb95-30"><a href="#cb95-30" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb95-31"><a href="#cb95-31" aria-hidden="true" tabindex="-1"></a>        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb95-32"><a href="#cb95-32" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb95-33"><a href="#cb95-33" aria-hidden="true" tabindex="-1"></a>        train_loss <span class="op">+=</span> loss.item()</span>
<span id="cb95-34"><a href="#cb95-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-35"><a href="#cb95-35" aria-hidden="true" tabindex="-1"></a>    avg_train_loss <span class="op">=</span> train_loss <span class="op">/</span> <span class="bu">len</span>(train_loader)</span>
<span id="cb95-36"><a href="#cb95-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-37"><a href="#cb95-37" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Validation</span></span>
<span id="cb95-38"><a href="#cb95-38" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb95-39"><a href="#cb95-39" aria-hidden="true" tabindex="-1"></a>    val_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb95-40"><a href="#cb95-40" aria-hidden="true" tabindex="-1"></a>    val_preds, val_labels <span class="op">=</span> [], []</span>
<span id="cb95-41"><a href="#cb95-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-42"><a href="#cb95-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb95-43"><a href="#cb95-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> batch <span class="kw">in</span> val_loader:</span>
<span id="cb95-44"><a href="#cb95-44" aria-hidden="true" tabindex="-1"></a>            batch <span class="op">=</span> {k: v.to(device) <span class="cf">for</span> k, v <span class="kw">in</span> batch.items()}</span>
<span id="cb95-45"><a href="#cb95-45" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> model(</span>
<span id="cb95-46"><a href="#cb95-46" aria-hidden="true" tabindex="-1"></a>                input_ids<span class="op">=</span>batch[<span class="st">&quot;input_ids&quot;</span>],</span>
<span id="cb95-47"><a href="#cb95-47" aria-hidden="true" tabindex="-1"></a>                attention_mask<span class="op">=</span>batch[<span class="st">&quot;attention_mask&quot;</span>],</span>
<span id="cb95-48"><a href="#cb95-48" aria-hidden="true" tabindex="-1"></a>                labels<span class="op">=</span>batch[<span class="st">&quot;label&quot;</span>]</span>
<span id="cb95-49"><a href="#cb95-49" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb95-50"><a href="#cb95-50" aria-hidden="true" tabindex="-1"></a>            val_loss <span class="op">+=</span> outputs.loss.item()</span>
<span id="cb95-51"><a href="#cb95-51" aria-hidden="true" tabindex="-1"></a>            preds <span class="op">=</span> torch.argmax(outputs.logits, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb95-52"><a href="#cb95-52" aria-hidden="true" tabindex="-1"></a>            val_preds.extend(preds.cpu().numpy())</span>
<span id="cb95-53"><a href="#cb95-53" aria-hidden="true" tabindex="-1"></a>            val_labels.extend(batch[<span class="st">&quot;label&quot;</span>].cpu().numpy())</span>
<span id="cb95-54"><a href="#cb95-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-55"><a href="#cb95-55" aria-hidden="true" tabindex="-1"></a>    avg_val_loss <span class="op">=</span> val_loss <span class="op">/</span> <span class="bu">len</span>(val_loader)</span>
<span id="cb95-56"><a href="#cb95-56" aria-hidden="true" tabindex="-1"></a>    val_acc <span class="op">=</span> accuracy_score(val_labels, val_preds)</span>
<span id="cb95-57"><a href="#cb95-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-58"><a href="#cb95-58" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> val_acc <span class="op">&gt;</span> best_val_acc:</span>
<span id="cb95-59"><a href="#cb95-59" aria-hidden="true" tabindex="-1"></a>        best_val_acc <span class="op">=</span> val_acc</span>
<span id="cb95-60"><a href="#cb95-60" aria-hidden="true" tabindex="-1"></a>        best_state <span class="op">=</span> {k: v.detach().cpu().clone() <span class="cf">for</span> k, v <span class="kw">in</span> model.state_dict().items()}</span>
<span id="cb95-61"><a href="#cb95-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-62"><a href="#cb95-62" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Epoch </span><span class="sc">{</span>epoch<span class="sc">:02d}</span><span class="ss"> | train_loss: </span><span class="sc">{</span>avg_train_loss<span class="sc">:.4f}</span><span class="ss"> | val_loss: </span><span class="sc">{</span>avg_val_loss<span class="sc">:.4f}</span><span class="ss"> | val_acc: </span><span class="sc">{</span>val_acc<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb96"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;728fc84e031747a2a570ee9ccb2c59da&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: [&#39;classifier.bias&#39;, &#39;classifier.weight&#39;, &#39;pre_classifier.bias&#39;, &#39;pre_classifier.weight&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Epoch 01 | train_loss: 0.7041 | val_loss: 0.7227 | val_acc: 0.7878
Epoch 02 | train_loss: 0.5476 | val_loss: 0.6577 | val_acc: 0.8201
Epoch 03 | train_loss: 0.4154 | val_loss: 0.6752 | val_acc: 0.8290
</code></pre>
</div>
</div>
<section id="evaluation-and-logging" class="cell markdown"
id="OrtHKyddfFKa">
<h3>Evaluation and Logging</h3>
<p>After restoring the best state, I compute the classification report
and extract: val_acc, macro-F1, and per-class recall for the four
methodology labels. I export a one-row CSV this keeps plotting code
simple and makes the DistilBERT row drop-in compatible to be used
later.</p>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="qYsLceP4t5_F" data-outputId="d5a6244f-2c4d-4085-bad1-f8c19f289ec1">
<div class="sourceCode" id="cb99"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load best model</span></span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> best_state <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb99-3"><a href="#cb99-3" aria-hidden="true" tabindex="-1"></a>    model.load_state_dict(best_state)</span>
<span id="cb99-4"><a href="#cb99-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-5"><a href="#cb99-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Final Evaluation</span></span>
<span id="cb99-6"><a href="#cb99-6" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb99-7"><a href="#cb99-7" aria-hidden="true" tabindex="-1"></a>preds, labels <span class="op">=</span> [], []</span>
<span id="cb99-8"><a href="#cb99-8" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb99-9"><a href="#cb99-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch <span class="kw">in</span> val_loader:</span>
<span id="cb99-10"><a href="#cb99-10" aria-hidden="true" tabindex="-1"></a>        batch <span class="op">=</span> {k: v.to(device) <span class="cf">for</span> k, v <span class="kw">in</span> batch.items()}</span>
<span id="cb99-11"><a href="#cb99-11" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> model(</span>
<span id="cb99-12"><a href="#cb99-12" aria-hidden="true" tabindex="-1"></a>            input_ids<span class="op">=</span>batch[<span class="st">&quot;input_ids&quot;</span>],</span>
<span id="cb99-13"><a href="#cb99-13" aria-hidden="true" tabindex="-1"></a>            attention_mask<span class="op">=</span>batch[<span class="st">&quot;attention_mask&quot;</span>]</span>
<span id="cb99-14"><a href="#cb99-14" aria-hidden="true" tabindex="-1"></a>        ).logits</span>
<span id="cb99-15"><a href="#cb99-15" aria-hidden="true" tabindex="-1"></a>        predictions <span class="op">=</span> torch.argmax(logits, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb99-16"><a href="#cb99-16" aria-hidden="true" tabindex="-1"></a>        preds.extend(predictions.cpu().numpy())</span>
<span id="cb99-17"><a href="#cb99-17" aria-hidden="true" tabindex="-1"></a>        labels.extend(batch[<span class="st">&quot;label&quot;</span>].cpu().numpy())</span>
<span id="cb99-18"><a href="#cb99-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-19"><a href="#cb99-19" aria-hidden="true" tabindex="-1"></a>val_acc <span class="op">=</span> accuracy_score(labels, preds)</span>
<span id="cb99-20"><a href="#cb99-20" aria-hidden="true" tabindex="-1"></a>report <span class="op">=</span> classification_report(labels, preds, target_names<span class="op">=</span>le.classes_, output_dict<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb99-21"><a href="#cb99-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-22"><a href="#cb99-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Print report to console</span></span>
<span id="cb99-23"><a href="#cb99-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Validation accuracy:&quot;</span>, val_acc)</span>
<span id="cb99-24"><a href="#cb99-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(labels, preds, target_names<span class="op">=</span>le.classes_))</span>
<span id="cb99-25"><a href="#cb99-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-26"><a href="#cb99-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Build Summary Table and Export CSV</span></span>
<span id="cb99-27"><a href="#cb99-27" aria-hidden="true" tabindex="-1"></a>row <span class="op">=</span> {</span>
<span id="cb99-28"><a href="#cb99-28" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;run&quot;</span>: <span class="st">&quot;distilbert_base_len512&quot;</span>,</span>
<span id="cb99-29"><a href="#cb99-29" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;max_len&quot;</span>: <span class="dv">512</span>,</span>
<span id="cb99-30"><a href="#cb99-30" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;lr&quot;</span>: <span class="fl">2e-5</span>,</span>
<span id="cb99-31"><a href="#cb99-31" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;train_loss&quot;</span>: avg_train_loss,</span>
<span id="cb99-32"><a href="#cb99-32" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;val_loss&quot;</span>: avg_val_loss,</span>
<span id="cb99-33"><a href="#cb99-33" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;val_acc&quot;</span>: val_acc,</span>
<span id="cb99-34"><a href="#cb99-34" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;macro_f1&quot;</span>: report[<span class="st">&quot;macro avg&quot;</span>][<span class="st">&quot;f1-score&quot;</span>]</span>
<span id="cb99-35"><a href="#cb99-35" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb99-36"><a href="#cb99-36" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> label <span class="kw">in</span> le.classes_:</span>
<span id="cb99-37"><a href="#cb99-37" aria-hidden="true" tabindex="-1"></a>    row[<span class="ss">f&quot;recall_</span><span class="sc">{</span>label<span class="sc">.</span>replace(<span class="st">&#39; &#39;</span>, <span class="st">&#39;_&#39;</span>)<span class="sc">}</span><span class="ss">&quot;</span>] <span class="op">=</span> report[label][<span class="st">&quot;recall&quot;</span>]</span>
<span id="cb99-38"><a href="#cb99-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-39"><a href="#cb99-39" aria-hidden="true" tabindex="-1"></a>df_summary <span class="op">=</span> pd.DataFrame([row])</span>
<span id="cb99-40"><a href="#cb99-40" aria-hidden="true" tabindex="-1"></a>csv_name <span class="op">=</span> <span class="st">&quot;distilBERT_methodology_1run_summary_len512.csv&quot;</span></span>
<span id="cb99-41"><a href="#cb99-41" aria-hidden="true" tabindex="-1"></a>df_summary.to_csv(csv_name, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb99-42"><a href="#cb99-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;</span><span class="ch">\n</span><span class="ss">Saved CSV summary to: </span><span class="sc">{</span>csv_name<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>
Validation accuracy: 0.8290062667860341
                                precision    recall  f1-score   support

Design Science / System Design       0.92      0.88      0.90       685
                 Mixed Methods       0.56      0.56      0.56        94
                   Qualitative       0.00      0.00      0.00        18
      Theoretical / Conceptual       0.74      0.85      0.79       320

                      accuracy                           0.83      1117
                     macro avg       0.55      0.57      0.56      1117
                  weighted avg       0.82      0.83      0.82      1117


Saved CSV summary to: distilBERT_methodology_1run_summary_len512.csv
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f&quot;{metric.capitalize()} is&quot;, len(result))
/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f&quot;{metric.capitalize()} is&quot;, len(result))
/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f&quot;{metric.capitalize()} is&quot;, len(result))
/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f&quot;{metric.capitalize()} is&quot;, len(result))
/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f&quot;{metric.capitalize()} is&quot;, len(result))
/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f&quot;{metric.capitalize()} is&quot;, len(result))
</code></pre>
</div>
</div>
<section id="46-distilbert-extended-models-e1-e2-e3"
class="cell markdown" id="0wpTK9fjtn53">
<h2>4.6 DistilBERT Extended Models (E1, E2, E3)</h2>
<p>After confirming DistilBERT is competitive at 512 tokens, I re-ran it
at 256 tokens (supported by the token-length study) and varied only the
optimisation bias, not the architecture, to test whether we can lift
minority recalls without sacrificing overall reliability.</p>
<p>Setup:</p>
<ul>
<li><p>E1 (baseline @ 256): plain cross-entropy, no warm-up, no class
weights, no sampler. Control run at the shorter sequence
length.</p></li>
<li><p>E2 (scheduler): same as E1 plus 10% linear warm-up to stabilise
the first few hundred updates when the classifier head is
untrained.</p></li>
<li><p>E3 (class-weighted loss): same as E1 with inverse-frequency class
weights in the loss to increase gradient signal for rarer labels. (No
sampler.)</p></li>
</ul>
<p>Observation:</p>
<ul>
<li><p>E1 gives the best balance (macro-F1 at about 0.562; DS/SD at
about 0.94, MM at about 0.43, Qual at about 0.06, TC at about
0.72).</p></li>
<li><p>E2 slightly improves overall accuracy (val acc at about 0.826)
and MM recall (at about 0.47) but lowers macro-F1 (at about 0.546)
because Qualitative drops to zero on this split.</p></li>
<li><p>E3 increases the penalty on mistakes for rarer labels but,
without a sampler, doesn’t reliably lift minority recall here; macro-F1
falls (at about 0.474).</p></li>
</ul>
<p>These runs confirm that 256 tokens is a safe operating point for
DistilBERT on abstracts and that light schedule tweaks (warm-up) help
stability, while class-weighted loss alone is insufficient to close the
gap on the smallest class.</p>
</section>
<section id="configuaration" class="cell markdown" id="GFw1YisTct8a">
<h3>Configuaration</h3>
<p>A small RunConfig dataclass centralises everything that defines a
run: model name (distilbert-base-uncased), max sequence length (256),
batch size, learning rate, warm up fraction, and whether class weights
are used. This keeps experiments reproducible and makes it easy to
change a single factor at a time. The tokenize_fn wraps the DistilBERT
tokenizer with truncation and max-length padding so batches are uniform
and memory predictable. The build_loss function returns either plain
cross entropy (E1, E2) or a class weighted variant (E3). I compute
inverse frequency weights from the training split and normalise them so
the average weight is one; that preserves loss scale and keeps gradient
magnitudes comparable across runs.</p>
</section>
<div class="cell code" id="7n3Avgmytrna">
<div class="sourceCode" id="cb102"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Reproducibility</span></span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> set_seed(seed<span class="op">=</span><span class="dv">42</span>):</span>
<span id="cb102-3"><a href="#cb102-3" aria-hidden="true" tabindex="-1"></a>    random.seed(seed)<span class="op">;</span> np.random.seed(seed)</span>
<span id="cb102-4"><a href="#cb102-4" aria-hidden="true" tabindex="-1"></a>    torch.manual_seed(seed)<span class="op">;</span> torch.cuda.manual_seed_all(seed)</span>
<span id="cb102-5"><a href="#cb102-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb102-6"><a href="#cb102-6" aria-hidden="true" tabindex="-1"></a>set_seed(<span class="dv">42</span>)</span>
<span id="cb102-7"><a href="#cb102-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb102-8"><a href="#cb102-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Config</span></span>
<span id="cb102-9"><a href="#cb102-9" aria-hidden="true" tabindex="-1"></a><span class="at">@dataclass</span></span>
<span id="cb102-10"><a href="#cb102-10" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> RunConfig:</span>
<span id="cb102-11"><a href="#cb102-11" aria-hidden="true" tabindex="-1"></a>    name: <span class="bu">str</span></span>
<span id="cb102-12"><a href="#cb102-12" aria-hidden="true" tabindex="-1"></a>    model_name: <span class="bu">str</span> <span class="op">=</span> <span class="st">&quot;distilbert-base-uncased&quot;</span></span>
<span id="cb102-13"><a href="#cb102-13" aria-hidden="true" tabindex="-1"></a>    max_len: <span class="bu">int</span> <span class="op">=</span> <span class="dv">256</span></span>
<span id="cb102-14"><a href="#cb102-14" aria-hidden="true" tabindex="-1"></a>    batch_size: <span class="bu">int</span> <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb102-15"><a href="#cb102-15" aria-hidden="true" tabindex="-1"></a>    lr: <span class="bu">float</span> <span class="op">=</span> <span class="fl">2e-5</span></span>
<span id="cb102-16"><a href="#cb102-16" aria-hidden="true" tabindex="-1"></a>    weight_decay: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb102-17"><a href="#cb102-17" aria-hidden="true" tabindex="-1"></a>    epochs: <span class="bu">int</span> <span class="op">=</span> <span class="dv">6</span></span>
<span id="cb102-18"><a href="#cb102-18" aria-hidden="true" tabindex="-1"></a>    patience: <span class="bu">int</span> <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb102-19"><a href="#cb102-19" aria-hidden="true" tabindex="-1"></a>    warmup_frac: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb102-20"><a href="#cb102-20" aria-hidden="true" tabindex="-1"></a>    use_loss_weights: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span></span>
<span id="cb102-21"><a href="#cb102-21" aria-hidden="true" tabindex="-1"></a>    use_sampler: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span></span>
<span id="cb102-22"><a href="#cb102-22" aria-hidden="true" tabindex="-1"></a>    sampler_alpha: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb102-23"><a href="#cb102-23" aria-hidden="true" tabindex="-1"></a>    device: <span class="bu">str</span> <span class="op">=</span> <span class="st">&quot;cuda&quot;</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">&quot;cpu&quot;</span></span>
<span id="cb102-24"><a href="#cb102-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb102-25"><a href="#cb102-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Tokeniser and Loss</span></span>
<span id="cb102-26"><a href="#cb102-26" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tokenize_fn(tokenizer, max_len):</span>
<span id="cb102-27"><a href="#cb102-27" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> f(example):</span>
<span id="cb102-28"><a href="#cb102-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> tokenizer(</span>
<span id="cb102-29"><a href="#cb102-29" aria-hidden="true" tabindex="-1"></a>            example[<span class="st">&quot;processed_with_stopwords&quot;</span>],</span>
<span id="cb102-30"><a href="#cb102-30" aria-hidden="true" tabindex="-1"></a>            truncation<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb102-31"><a href="#cb102-31" aria-hidden="true" tabindex="-1"></a>            padding<span class="op">=</span><span class="st">&quot;max_length&quot;</span>,</span>
<span id="cb102-32"><a href="#cb102-32" aria-hidden="true" tabindex="-1"></a>            max_length<span class="op">=</span>max_len,</span>
<span id="cb102-33"><a href="#cb102-33" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb102-34"><a href="#cb102-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> f</span>
<span id="cb102-35"><a href="#cb102-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb102-36"><a href="#cb102-36" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_loss(cfg: RunConfig, label_counts: np.ndarray):</span>
<span id="cb102-37"><a href="#cb102-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> cfg.use_loss_weights:</span>
<span id="cb102-38"><a href="#cb102-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> nn.CrossEntropyLoss()</span>
<span id="cb102-39"><a href="#cb102-39" aria-hidden="true" tabindex="-1"></a>    weights <span class="op">=</span> <span class="fl">1.0</span> <span class="op">/</span> (label_counts <span class="op">+</span> <span class="fl">1e-5</span>)</span>
<span id="cb102-40"><a href="#cb102-40" aria-hidden="true" tabindex="-1"></a>    norm_weights <span class="op">=</span> weights <span class="op">/</span> weights.mean()</span>
<span id="cb102-41"><a href="#cb102-41" aria-hidden="true" tabindex="-1"></a>    weight_tensor <span class="op">=</span> torch.tensor(norm_weights, dtype<span class="op">=</span>torch.<span class="bu">float</span>).to(cfg.device)</span>
<span id="cb102-42"><a href="#cb102-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> nn.CrossEntropyLoss(weight<span class="op">=</span>weight_tensor)</span></code></pre></div>
</div>
<section id="runner" class="cell markdown" id="8jF7v3JkdHzF">
<h3>Runner</h3>
<p>The runner creates a single 80/20 split (seed=42) for the chosen
label and reuses it across E1–E3 so differences reflect training bias
only. Training proceeds for up to six epochs with gradient clipping at
1.0; validation loss is monitored each epoch and the best state is kept
with patience set to two epochs. This criterion is conservative and
model-agnostic, which helps when comparing heterogeneous tweaks. After
training, the best checkpoint is reloaded and evaluated to produce
accuracy, macro-F1, and per-class recalls.</p>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:720,&quot;referenced_widgets&quot;:[&quot;403b1597989c47399b10b64febd6e387&quot;,&quot;fde4c5652cd1455f9597e67a323b1a81&quot;,&quot;a3b0938ccf5b4d578fb7dcda5499324f&quot;,&quot;1de2b93b68f14091a6b15f6fa0109602&quot;,&quot;7da5b25da3684ce698c4fa46c33e41cd&quot;,&quot;23d4252b2ffe49f782cb35e9d2cd1f78&quot;,&quot;266f33e4820d4bf0bb1efc81f5b83e94&quot;,&quot;70d7e08fb4644a1280b6d6b1487e4f6a&quot;,&quot;7770469581374df4ac3cdcc3b80bda2b&quot;,&quot;c95cb03a8d2749ce86fe5b79fa361287&quot;,&quot;751de12975ae4533a8397b8c6a2d4d2a&quot;,&quot;72a5020717b4453c93908a7f141b95b1&quot;,&quot;707dfbc473924999a3f198b730e044a8&quot;,&quot;68955a5a46ad4fb8af18885c96c83a58&quot;,&quot;bd4f10622b0e4081b210c1cef929f6bb&quot;,&quot;0551f6f42a79408098af6fdea525ba29&quot;,&quot;a86e41bbc4f14850b17a386f26b749f8&quot;,&quot;5434e751cdf349b6891660c9a8d4559e&quot;,&quot;e8f92d6ce0fb437d9f23cee0a3b66b9b&quot;,&quot;68de6d994ff748aabd06a18d03ffd413&quot;,&quot;bd89f03408334bc48b9fc365c71ff51c&quot;,&quot;472770d0d84846e3bd1dbc4c92c70a78&quot;,&quot;9df6796438f746c8b2f52c22f6a66e8c&quot;,&quot;882a0290b2504946ae098becb191eb40&quot;,&quot;bb58a421e39f4e51b5f93bcdd48fd24a&quot;,&quot;eee9ea0f99ef49229afc47081f99084d&quot;,&quot;ba1f1f3a890e49d48a4c93999e44e387&quot;,&quot;c4ecb8fb9f134a38a3ef440af28e27fa&quot;,&quot;45fa287b8e4e44d5b38c5862bc95f049&quot;,&quot;c592f9f1eb494d86af6063b3116e3ef6&quot;,&quot;e0dad93f484544778fff0a2540ba0c91&quot;,&quot;a7f09877142449de9eec57181b7debf4&quot;,&quot;0e6e1a6618a547ae82c886f15ec05362&quot;,&quot;2bd5e5f581464f08813dc5f5b388beda&quot;,&quot;1f399a2a36f94e129570939850308bb3&quot;,&quot;3ec8fe7d708a419391b55e5dfe9c5682&quot;,&quot;69ea207f433240d1b0b2f6cfffab2873&quot;,&quot;0bc5c74038b54d5783e9027ee5245c52&quot;,&quot;e5adde82cd1a4ee78ce316e5deb6b736&quot;,&quot;e30404c9722544aa906b7669337b74a1&quot;,&quot;79616f14725f41099ef6232a3267dfe6&quot;,&quot;8a9b561e41624af49651e8925698a9ec&quot;,&quot;0eaa403d5dda487aa9d8e308bec132bd&quot;,&quot;363221e080964e52b28f5713a349c29f&quot;,&quot;77fd71a44a78442186fd49786ee10bba&quot;,&quot;e6bc3dbafc2748bbb902eeb04f91bd7e&quot;,&quot;84f48c40e4cf4e5a8512e96c979598eb&quot;,&quot;75e34e57a0534c3d93757154f81dffe0&quot;,&quot;a290f7ebba07486e82362f327c81566e&quot;,&quot;063a8fd157fe4b489eda801315c2794f&quot;,&quot;fc4b3cba2d2a4d9fb97b416fa8c6cfb8&quot;,&quot;207c6c7608144bdd9d0eb26b2a81ca06&quot;,&quot;5ed997baed3646309697334a0140618f&quot;,&quot;638a2169d3b84294aa1fd79c06a4dd69&quot;,&quot;237b59d8cb5744368ac8e1738c273762&quot;,&quot;cc01e0aa25eb45bab5e58c593128b9b0&quot;,&quot;5329600d09c44ff6a464fad541ef0a6d&quot;,&quot;574c968936cf4901903644b75ecea00f&quot;,&quot;d539894f91404fd882419af475afa118&quot;,&quot;aa867aa877d94fa1aa0caf54e4f6c672&quot;,&quot;b19a4b5ef10d43f18bac2b8b4593d8d9&quot;,&quot;a84e5a033e8940d2a930452ff3924eb8&quot;,&quot;bedd98b9abe549f2a795f739738f2f6b&quot;,&quot;dc118f2ef4e44d78b7f5d7713ca26399&quot;,&quot;53e1edc6831d414f9d24aa6f64e3c3d4&quot;,&quot;efeeaca121ac48d3bb6c298e5e5279d7&quot;]}"
id="JQbQmw_pugwJ" data-outputId="0b354609-7f8d-4024-d75e-fa27638b8816">
<div class="sourceCode" id="cb103"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Main Runner</span></span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> run_3_configs_for_label_distilbert(df: pd.DataFrame, label_col: <span class="bu">str</span>):</span>
<span id="cb103-3"><a href="#cb103-3" aria-hidden="true" tabindex="-1"></a>    set_seed(<span class="dv">42</span>)</span>
<span id="cb103-4"><a href="#cb103-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> <span class="st">&#39;processed_with_stopwords&#39;</span> <span class="kw">in</span> df.columns</span>
<span id="cb103-5"><a href="#cb103-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-6"><a href="#cb103-6" aria-hidden="true" tabindex="-1"></a>    df_task <span class="op">=</span> df[df[label_col].notnull()].copy().reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb103-7"><a href="#cb103-7" aria-hidden="true" tabindex="-1"></a>    le <span class="op">=</span> LabelEncoder()</span>
<span id="cb103-8"><a href="#cb103-8" aria-hidden="true" tabindex="-1"></a>    df_task[<span class="st">&#39;label&#39;</span>] <span class="op">=</span> le.fit_transform(df_task[label_col])</span>
<span id="cb103-9"><a href="#cb103-9" aria-hidden="true" tabindex="-1"></a>    num_classes <span class="op">=</span> <span class="bu">len</span>(le.classes_)</span>
<span id="cb103-10"><a href="#cb103-10" aria-hidden="true" tabindex="-1"></a>    full_ds <span class="op">=</span> Dataset.from_pandas(df_task[[<span class="st">&#39;processed_with_stopwords&#39;</span>, <span class="st">&#39;label&#39;</span>]])</span>
<span id="cb103-11"><a href="#cb103-11" aria-hidden="true" tabindex="-1"></a>    splits <span class="op">=</span> full_ds.train_test_split(test_size<span class="op">=</span><span class="fl">0.2</span>, seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb103-12"><a href="#cb103-12" aria-hidden="true" tabindex="-1"></a>    train_ds, val_ds <span class="op">=</span> splits[<span class="st">&#39;train&#39;</span>], splits[<span class="st">&#39;test&#39;</span>]</span>
<span id="cb103-13"><a href="#cb103-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-14"><a href="#cb103-14" aria-hidden="true" tabindex="-1"></a>    runs <span class="op">=</span> [</span>
<span id="cb103-15"><a href="#cb103-15" aria-hidden="true" tabindex="-1"></a>        RunConfig(name<span class="op">=</span><span class="st">&quot;E1_len256&quot;</span>),</span>
<span id="cb103-16"><a href="#cb103-16" aria-hidden="true" tabindex="-1"></a>        RunConfig(name<span class="op">=</span><span class="st">&quot;E2_scheduler_len256&quot;</span>, warmup_frac<span class="op">=</span><span class="fl">0.1</span>),</span>
<span id="cb103-17"><a href="#cb103-17" aria-hidden="true" tabindex="-1"></a>        RunConfig(name<span class="op">=</span><span class="st">&quot;E3_classweights_len256&quot;</span>, use_loss_weights<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb103-18"><a href="#cb103-18" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb103-19"><a href="#cb103-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-20"><a href="#cb103-20" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> []</span>
<span id="cb103-21"><a href="#cb103-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> cfg <span class="kw">in</span> runs:</span>
<span id="cb103-22"><a href="#cb103-22" aria-hidden="true" tabindex="-1"></a>        set_seed(<span class="dv">42</span>)</span>
<span id="cb103-23"><a href="#cb103-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-24"><a href="#cb103-24" aria-hidden="true" tabindex="-1"></a>        tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(cfg.model_name)</span>
<span id="cb103-25"><a href="#cb103-25" aria-hidden="true" tabindex="-1"></a>        tokenized_train <span class="op">=</span> train_ds.<span class="bu">map</span>(tokenize_fn(tokenizer, cfg.max_len), batched<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb103-26"><a href="#cb103-26" aria-hidden="true" tabindex="-1"></a>        tokenized_val <span class="op">=</span> val_ds.<span class="bu">map</span>(tokenize_fn(tokenizer, cfg.max_len), batched<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb103-27"><a href="#cb103-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-28"><a href="#cb103-28" aria-hidden="true" tabindex="-1"></a>        tokenized_train.set_format(<span class="bu">type</span><span class="op">=</span><span class="st">&#39;torch&#39;</span>, columns<span class="op">=</span>[<span class="st">&#39;input_ids&#39;</span>, <span class="st">&#39;attention_mask&#39;</span>, <span class="st">&#39;label&#39;</span>])</span>
<span id="cb103-29"><a href="#cb103-29" aria-hidden="true" tabindex="-1"></a>        tokenized_val.set_format(<span class="bu">type</span><span class="op">=</span><span class="st">&#39;torch&#39;</span>, columns<span class="op">=</span>[<span class="st">&#39;input_ids&#39;</span>, <span class="st">&#39;attention_mask&#39;</span>, <span class="st">&#39;label&#39;</span>])</span>
<span id="cb103-30"><a href="#cb103-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-31"><a href="#cb103-31" aria-hidden="true" tabindex="-1"></a>        train_loader <span class="op">=</span> DataLoader(tokenized_train, batch_size<span class="op">=</span>cfg.batch_size, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb103-32"><a href="#cb103-32" aria-hidden="true" tabindex="-1"></a>        val_loader <span class="op">=</span> DataLoader(tokenized_val, batch_size<span class="op">=</span>cfg.batch_size)</span>
<span id="cb103-33"><a href="#cb103-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-34"><a href="#cb103-34" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(cfg.model_name, num_labels<span class="op">=</span>num_classes).to(cfg.device)</span>
<span id="cb103-35"><a href="#cb103-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-36"><a href="#cb103-36" aria-hidden="true" tabindex="-1"></a>        optimizer <span class="op">=</span> torch.optim.AdamW(model.parameters(), lr<span class="op">=</span>cfg.lr, weight_decay<span class="op">=</span>cfg.weight_decay)</span>
<span id="cb103-37"><a href="#cb103-37" aria-hidden="true" tabindex="-1"></a>        total_steps <span class="op">=</span> <span class="bu">len</span>(train_loader) <span class="op">*</span> cfg.epochs</span>
<span id="cb103-38"><a href="#cb103-38" aria-hidden="true" tabindex="-1"></a>        scheduler <span class="op">=</span> get_linear_schedule_with_warmup(</span>
<span id="cb103-39"><a href="#cb103-39" aria-hidden="true" tabindex="-1"></a>            optimizer,</span>
<span id="cb103-40"><a href="#cb103-40" aria-hidden="true" tabindex="-1"></a>            num_warmup_steps<span class="op">=</span><span class="bu">int</span>(cfg.warmup_frac <span class="op">*</span> total_steps),</span>
<span id="cb103-41"><a href="#cb103-41" aria-hidden="true" tabindex="-1"></a>            num_training_steps<span class="op">=</span>total_steps</span>
<span id="cb103-42"><a href="#cb103-42" aria-hidden="true" tabindex="-1"></a>        ) <span class="cf">if</span> cfg.warmup_frac <span class="cf">else</span> <span class="va">None</span></span>
<span id="cb103-43"><a href="#cb103-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-44"><a href="#cb103-44" aria-hidden="true" tabindex="-1"></a>        label_counts <span class="op">=</span> np.bincount(df_task[<span class="st">&#39;label&#39;</span>], minlength<span class="op">=</span>num_classes)</span>
<span id="cb103-45"><a href="#cb103-45" aria-hidden="true" tabindex="-1"></a>        loss_fct <span class="op">=</span> build_loss(cfg, label_counts)</span>
<span id="cb103-46"><a href="#cb103-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-47"><a href="#cb103-47" aria-hidden="true" tabindex="-1"></a>        best_val_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">&#39;inf&#39;</span>)<span class="op">;</span> best_state <span class="op">=</span> <span class="va">None</span><span class="op">;</span> patience_ctr <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb103-48"><a href="#cb103-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, cfg.epochs <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb103-49"><a href="#cb103-49" aria-hidden="true" tabindex="-1"></a>            model.train()<span class="op">;</span> total_train_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb103-50"><a href="#cb103-50" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> batch <span class="kw">in</span> train_loader:</span>
<span id="cb103-51"><a href="#cb103-51" aria-hidden="true" tabindex="-1"></a>                optimizer.zero_grad()</span>
<span id="cb103-52"><a href="#cb103-52" aria-hidden="true" tabindex="-1"></a>                batch <span class="op">=</span> {k: v.to(cfg.device) <span class="cf">for</span> k, v <span class="kw">in</span> batch.items()}</span>
<span id="cb103-53"><a href="#cb103-53" aria-hidden="true" tabindex="-1"></a>                outputs <span class="op">=</span> model(input_ids<span class="op">=</span>batch[<span class="st">&#39;input_ids&#39;</span>], attention_mask<span class="op">=</span>batch[<span class="st">&#39;attention_mask&#39;</span>])</span>
<span id="cb103-54"><a href="#cb103-54" aria-hidden="true" tabindex="-1"></a>                loss <span class="op">=</span> loss_fct(outputs.logits, batch[<span class="st">&#39;label&#39;</span>])</span>
<span id="cb103-55"><a href="#cb103-55" aria-hidden="true" tabindex="-1"></a>                loss.backward()</span>
<span id="cb103-56"><a href="#cb103-56" aria-hidden="true" tabindex="-1"></a>                torch.nn.utils.clip_grad_norm_(model.parameters(), <span class="fl">1.0</span>)</span>
<span id="cb103-57"><a href="#cb103-57" aria-hidden="true" tabindex="-1"></a>                optimizer.step()</span>
<span id="cb103-58"><a href="#cb103-58" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> scheduler: scheduler.step()</span>
<span id="cb103-59"><a href="#cb103-59" aria-hidden="true" tabindex="-1"></a>                total_train_loss <span class="op">+=</span> loss.item()</span>
<span id="cb103-60"><a href="#cb103-60" aria-hidden="true" tabindex="-1"></a>            avg_train_loss <span class="op">=</span> total_train_loss <span class="op">/</span> <span class="bu">len</span>(train_loader)</span>
<span id="cb103-61"><a href="#cb103-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-62"><a href="#cb103-62" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Validation</span></span>
<span id="cb103-63"><a href="#cb103-63" aria-hidden="true" tabindex="-1"></a>            model.<span class="bu">eval</span>()<span class="op">;</span> total_val_loss, preds, labels <span class="op">=</span> <span class="dv">0</span>, [], []</span>
<span id="cb103-64"><a href="#cb103-64" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> torch.no_grad():</span>
<span id="cb103-65"><a href="#cb103-65" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> batch <span class="kw">in</span> val_loader:</span>
<span id="cb103-66"><a href="#cb103-66" aria-hidden="true" tabindex="-1"></a>                    batch <span class="op">=</span> {k: v.to(cfg.device) <span class="cf">for</span> k, v <span class="kw">in</span> batch.items()}</span>
<span id="cb103-67"><a href="#cb103-67" aria-hidden="true" tabindex="-1"></a>                    outputs <span class="op">=</span> model(input_ids<span class="op">=</span>batch[<span class="st">&quot;input_ids&quot;</span>], attention_mask<span class="op">=</span>batch[<span class="st">&quot;attention_mask&quot;</span>])</span>
<span id="cb103-68"><a href="#cb103-68" aria-hidden="true" tabindex="-1"></a>                    loss <span class="op">=</span> loss_fct(outputs.logits, batch[<span class="st">&quot;label&quot;</span>])</span>
<span id="cb103-69"><a href="#cb103-69" aria-hidden="true" tabindex="-1"></a>                    total_val_loss <span class="op">+=</span> loss.item()</span>
<span id="cb103-70"><a href="#cb103-70" aria-hidden="true" tabindex="-1"></a>                    preds.extend(torch.argmax(outputs.logits, dim<span class="op">=-</span><span class="dv">1</span>).cpu().numpy())</span>
<span id="cb103-71"><a href="#cb103-71" aria-hidden="true" tabindex="-1"></a>                    labels.extend(batch[<span class="st">&quot;label&quot;</span>].cpu().numpy())</span>
<span id="cb103-72"><a href="#cb103-72" aria-hidden="true" tabindex="-1"></a>            avg_val_loss <span class="op">=</span> total_val_loss <span class="op">/</span> <span class="bu">len</span>(val_loader)</span>
<span id="cb103-73"><a href="#cb103-73" aria-hidden="true" tabindex="-1"></a>            val_acc <span class="op">=</span> accuracy_score(labels, preds)</span>
<span id="cb103-74"><a href="#cb103-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-75"><a href="#cb103-75" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot;[</span><span class="sc">{</span>cfg<span class="sc">.</span>name<span class="sc">}</span><span class="ss">] Epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss"> | train_loss: </span><span class="sc">{</span>avg_train_loss<span class="sc">:.4f}</span><span class="ss"> | val_loss: </span><span class="sc">{</span>avg_val_loss<span class="sc">:.4f}</span><span class="ss"> | val_acc: </span><span class="sc">{</span>val_acc<span class="sc">:.4f}</span><span class="ss"> | patience </span><span class="sc">{</span>patience_ctr<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>cfg<span class="sc">.</span>patience<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb103-76"><a href="#cb103-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-77"><a href="#cb103-77" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> avg_val_loss <span class="op">&lt;</span> best_val_loss:</span>
<span id="cb103-78"><a href="#cb103-78" aria-hidden="true" tabindex="-1"></a>                best_val_loss <span class="op">=</span> avg_val_loss</span>
<span id="cb103-79"><a href="#cb103-79" aria-hidden="true" tabindex="-1"></a>                best_state <span class="op">=</span> {k: v.detach().cpu().clone() <span class="cf">for</span> k, v <span class="kw">in</span> model.state_dict().items()}</span>
<span id="cb103-80"><a href="#cb103-80" aria-hidden="true" tabindex="-1"></a>                patience_ctr <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb103-81"><a href="#cb103-81" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb103-82"><a href="#cb103-82" aria-hidden="true" tabindex="-1"></a>                patience_ctr <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb103-83"><a href="#cb103-83" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> patience_ctr <span class="op">&gt;=</span> cfg.patience:</span>
<span id="cb103-84"><a href="#cb103-84" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">break</span></span>
<span id="cb103-85"><a href="#cb103-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-86"><a href="#cb103-86" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Final Evaluation</span></span>
<span id="cb103-87"><a href="#cb103-87" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> best_state:</span>
<span id="cb103-88"><a href="#cb103-88" aria-hidden="true" tabindex="-1"></a>            model.load_state_dict(best_state)</span>
<span id="cb103-89"><a href="#cb103-89" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">eval</span>()<span class="op">;</span> preds, labels <span class="op">=</span> [], []</span>
<span id="cb103-90"><a href="#cb103-90" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb103-91"><a href="#cb103-91" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> batch <span class="kw">in</span> val_loader:</span>
<span id="cb103-92"><a href="#cb103-92" aria-hidden="true" tabindex="-1"></a>                batch <span class="op">=</span> {k: v.to(cfg.device) <span class="cf">for</span> k, v <span class="kw">in</span> batch.items()}</span>
<span id="cb103-93"><a href="#cb103-93" aria-hidden="true" tabindex="-1"></a>                logits <span class="op">=</span> model(input_ids<span class="op">=</span>batch[<span class="st">&quot;input_ids&quot;</span>], attention_mask<span class="op">=</span>batch[<span class="st">&quot;attention_mask&quot;</span>]).logits</span>
<span id="cb103-94"><a href="#cb103-94" aria-hidden="true" tabindex="-1"></a>                preds.extend(torch.argmax(logits, dim<span class="op">=-</span><span class="dv">1</span>).cpu().numpy())</span>
<span id="cb103-95"><a href="#cb103-95" aria-hidden="true" tabindex="-1"></a>                labels.extend(batch[<span class="st">&quot;label&quot;</span>].cpu().numpy())</span>
<span id="cb103-96"><a href="#cb103-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-97"><a href="#cb103-97" aria-hidden="true" tabindex="-1"></a>        report <span class="op">=</span> classification_report(labels, preds, target_names<span class="op">=</span><span class="bu">list</span>(le.classes_), output_dict<span class="op">=</span><span class="va">True</span>, zero_division<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb103-98"><a href="#cb103-98" aria-hidden="true" tabindex="-1"></a>        macro_f1 <span class="op">=</span> report[<span class="st">&quot;macro avg&quot;</span>][<span class="st">&quot;f1-score&quot;</span>]</span>
<span id="cb103-99"><a href="#cb103-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-100"><a href="#cb103-100" aria-hidden="true" tabindex="-1"></a>        row <span class="op">=</span> {</span>
<span id="cb103-101"><a href="#cb103-101" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;run&quot;</span>: cfg.name,</span>
<span id="cb103-102"><a href="#cb103-102" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;max_len&quot;</span>: cfg.max_len,</span>
<span id="cb103-103"><a href="#cb103-103" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;lr&quot;</span>: cfg.lr,</span>
<span id="cb103-104"><a href="#cb103-104" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;warmup&quot;</span>: cfg.warmup_frac,</span>
<span id="cb103-105"><a href="#cb103-105" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;sampler&quot;</span>: cfg.use_sampler,</span>
<span id="cb103-106"><a href="#cb103-106" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;alpha&quot;</span>: cfg.sampler_alpha,</span>
<span id="cb103-107"><a href="#cb103-107" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;loss_weights&quot;</span>: cfg.use_loss_weights,</span>
<span id="cb103-108"><a href="#cb103-108" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;val_acc&quot;</span>: report[<span class="st">&quot;accuracy&quot;</span>],</span>
<span id="cb103-109"><a href="#cb103-109" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;macro_f1&quot;</span>: macro_f1,</span>
<span id="cb103-110"><a href="#cb103-110" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;val_loss&quot;</span>: <span class="bu">round</span>(best_val_loss, <span class="dv">4</span>),</span>
<span id="cb103-111"><a href="#cb103-111" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb103-112"><a href="#cb103-112" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> cls <span class="kw">in</span> le.classes_:</span>
<span id="cb103-113"><a href="#cb103-113" aria-hidden="true" tabindex="-1"></a>            safe_name <span class="op">=</span> cls.replace(<span class="st">&quot;/&quot;</span>, <span class="st">&quot;-&quot;</span>).replace(<span class="st">&quot; &quot;</span>, <span class="st">&quot;_&quot;</span>)</span>
<span id="cb103-114"><a href="#cb103-114" aria-hidden="true" tabindex="-1"></a>            row[<span class="ss">f&quot;recall_</span><span class="sc">{</span>safe_name<span class="sc">}</span><span class="ss">&quot;</span>] <span class="op">=</span> report[cls][<span class="st">&quot;recall&quot;</span>]</span>
<span id="cb103-115"><a href="#cb103-115" aria-hidden="true" tabindex="-1"></a>        results.append(row)</span>
<span id="cb103-116"><a href="#cb103-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-117"><a href="#cb103-117" aria-hidden="true" tabindex="-1"></a>    df_summary <span class="op">=</span> pd.DataFrame(results).sort_values(by<span class="op">=</span>[<span class="st">&quot;macro_f1&quot;</span>,<span class="st">&quot;val_acc&quot;</span>], ascending<span class="op">=</span><span class="va">False</span>).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb103-118"><a href="#cb103-118" aria-hidden="true" tabindex="-1"></a>    front <span class="op">=</span> [<span class="st">&quot;run&quot;</span>,<span class="st">&quot;max_len&quot;</span>,<span class="st">&quot;lr&quot;</span>,<span class="st">&quot;warmup&quot;</span>,<span class="st">&quot;sampler&quot;</span>,<span class="st">&quot;alpha&quot;</span>,<span class="st">&quot;loss_weights&quot;</span>,<span class="st">&quot;val_acc&quot;</span>,<span class="st">&quot;macro_f1&quot;</span>,<span class="st">&quot;val_loss&quot;</span>]</span>
<span id="cb103-119"><a href="#cb103-119" aria-hidden="true" tabindex="-1"></a>    recall_cols <span class="op">=</span> [c <span class="cf">for</span> c <span class="kw">in</span> df_summary.columns <span class="cf">if</span> c.startswith(<span class="st">&quot;recall_&quot;</span>)]</span>
<span id="cb103-120"><a href="#cb103-120" aria-hidden="true" tabindex="-1"></a>    df_summary <span class="op">=</span> df_summary[front <span class="op">+</span> recall_cols]</span>
<span id="cb103-121"><a href="#cb103-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-122"><a href="#cb103-122" aria-hidden="true" tabindex="-1"></a>    out_csv <span class="op">=</span> <span class="ss">f&quot;distilBERT_</span><span class="sc">{</span>label_col<span class="sc">}</span><span class="ss">_E123_summary_len256.csv&quot;</span></span>
<span id="cb103-123"><a href="#cb103-123" aria-hidden="true" tabindex="-1"></a>    df_summary.to_csv(out_csv, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb103-124"><a href="#cb103-124" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;</span><span class="ch">\n</span><span class="ss">Saved summary to: </span><span class="sc">{</span>out_csv<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb103-125"><a href="#cb103-125" aria-hidden="true" tabindex="-1"></a>    display(df_summary)</span>
<span id="cb103-126"><a href="#cb103-126" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df_summary</span>
<span id="cb103-127"><a href="#cb103-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-128"><a href="#cb103-128" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the experiment</span></span>
<span id="cb103-129"><a href="#cb103-129" aria-hidden="true" tabindex="-1"></a>df_summary <span class="op">=</span> run_3_configs_for_label_distilbert(df, <span class="st">&quot;methodology&quot;</span>)</span>
<span id="cb103-130"><a href="#cb103-130" aria-hidden="true" tabindex="-1"></a><span class="co"># Export to CSV</span></span>
<span id="cb103-131"><a href="#cb103-131" aria-hidden="true" tabindex="-1"></a>df_summary.to_csv(<span class="st">&quot;distilBERT_methodology_E123_summary.csv&quot;</span>, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb103-132"><a href="#cb103-132" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Saved summary to: distilBERT_methodology_E123_summary.csv&quot;</span>)</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb104"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;403b1597989c47399b10b64febd6e387&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb105"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;72a5020717b4453c93908a7f141b95b1&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: [&#39;classifier.bias&#39;, &#39;classifier.weight&#39;, &#39;pre_classifier.bias&#39;, &#39;pre_classifier.weight&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>[E1_len256] Epoch 1 | train_loss: 0.7109 | val_loss: 0.7078 | val_acc: 0.7842 | patience 0/2
[E1_len256] Epoch 2 | train_loss: 0.5366 | val_loss: 0.6884 | val_acc: 0.8201 | patience 0/2
[E1_len256] Epoch 3 | train_loss: 0.4152 | val_loss: 0.7050 | val_acc: 0.8183 | patience 0/2
[E1_len256] Epoch 4 | train_loss: 0.3037 | val_loss: 0.8426 | val_acc: 0.8371 | patience 1/2
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb108"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;9df6796438f746c8b2f52c22f6a66e8c&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb109"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;2bd5e5f581464f08813dc5f5b388beda&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: [&#39;classifier.bias&#39;, &#39;classifier.weight&#39;, &#39;pre_classifier.bias&#39;, &#39;pre_classifier.weight&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>[E2_scheduler_len256] Epoch 1 | train_loss: 0.7872 | val_loss: 0.7535 | val_acc: 0.7672 | patience 0/2
[E2_scheduler_len256] Epoch 2 | train_loss: 0.5770 | val_loss: 0.6076 | val_acc: 0.8263 | patience 0/2
[E2_scheduler_len256] Epoch 3 | train_loss: 0.4148 | val_loss: 0.7104 | val_acc: 0.8263 | patience 0/2
[E2_scheduler_len256] Epoch 4 | train_loss: 0.2859 | val_loss: 0.8340 | val_acc: 0.8371 | patience 1/2
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb112"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;77fd71a44a78442186fd49786ee10bba&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb113"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;cc01e0aa25eb45bab5e58c593128b9b0&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: [&#39;classifier.bias&#39;, &#39;classifier.weight&#39;, &#39;pre_classifier.bias&#39;, &#39;pre_classifier.weight&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>[E3_classweights_len256] Epoch 1 | train_loss: 1.0332 | val_loss: 1.0185 | val_acc: 0.7914 | patience 0/2
[E3_classweights_len256] Epoch 2 | train_loss: 0.8714 | val_loss: 1.0202 | val_acc: 0.8236 | patience 0/2
[E3_classweights_len256] Epoch 3 | train_loss: 0.6899 | val_loss: 1.1439 | val_acc: 0.8147 | patience 1/2

Saved summary to: distilBERT_methodology_E123_summary_len256.csv
</code></pre>
</div>
<div class="output display_data">

  <div id="df-dffc8131-9db8-4022-b29d-bac7552cbd75" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>run</th>
      <th>max_len</th>
      <th>lr</th>
      <th>warmup</th>
      <th>sampler</th>
      <th>alpha</th>
      <th>loss_weights</th>
      <th>val_acc</th>
      <th>macro_f1</th>
      <th>val_loss</th>
      <th>recall_Design_Science_-_System_Design</th>
      <th>recall_Mixed_Methods</th>
      <th>recall_Qualitative</th>
      <th>recall_Theoretical_-_Conceptual</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>E1_len256</td>
      <td>256</td>
      <td>0.00002</td>
      <td>0.0</td>
      <td>False</td>
      <td>0.0</td>
      <td>False</td>
      <td>0.820054</td>
      <td>0.561651</td>
      <td>0.6884</td>
      <td>0.943066</td>
      <td>0.425532</td>
      <td>0.055556</td>
      <td>0.715625</td>
    </tr>
    <tr>
      <th>1</th>
      <td>E2_scheduler_len256</td>
      <td>256</td>
      <td>0.00002</td>
      <td>0.1</td>
      <td>False</td>
      <td>0.0</td>
      <td>False</td>
      <td>0.826321</td>
      <td>0.546284</td>
      <td>0.6076</td>
      <td>0.908029</td>
      <td>0.468085</td>
      <td>0.000000</td>
      <td>0.803125</td>
    </tr>
    <tr>
      <th>2</th>
      <td>E3_classweights_len256</td>
      <td>256</td>
      <td>0.00002</td>
      <td>0.0</td>
      <td>False</td>
      <td>0.0</td>
      <td>True</td>
      <td>0.791406</td>
      <td>0.474184</td>
      <td>1.0185</td>
      <td>0.929927</td>
      <td>0.202128</td>
      <td>0.000000</td>
      <td>0.712500</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-dffc8131-9db8-4022-b29d-bac7552cbd75')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-dffc8131-9db8-4022-b29d-bac7552cbd75 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-dffc8131-9db8-4022-b29d-bac7552cbd75');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    <div id="df-6498090b-7a43-49a9-8152-b1e06a323777">
      <button class="colab-df-quickchart" onclick="quickchart('df-6498090b-7a43-49a9-8152-b1e06a323777')"
                title="Suggest charts"
                style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
      </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

      <script>
        async function quickchart(key) {
          const quickchartButtonEl =
            document.querySelector('#' + key + ' button');
          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
          quickchartButtonEl.classList.add('colab-df-spinner');
          try {
            const charts = await google.colab.kernel.invokeFunction(
                'suggestCharts', [key], {});
          } catch (error) {
            console.error('Error during call to suggestCharts:', error);
          }
          quickchartButtonEl.classList.remove('colab-df-spinner');
          quickchartButtonEl.classList.add('colab-df-quickchart-complete');
        }
        (() => {
          let quickchartButtonEl =
            document.querySelector('#df-6498090b-7a43-49a9-8152-b1e06a323777 button');
          quickchartButtonEl.style.display =
            google.colab.kernel.accessAllowed ? 'block' : 'none';
        })();
      </script>
    </div>

    </div>
  </div>

</div>
<div class="output stream stdout">
<pre><code>Saved summary to: distilBERT_methodology_E123_summary.csv
</code></pre>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:439}"
id="lOKIGigF6XWg" data-outputId="b9561b43-1f85-4399-eda4-648182452c1f">
<div class="sourceCode" id="cb117"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Upload CSV</span></span>
<span id="cb117-2"><a href="#cb117-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> google.colab <span class="im">import</span> files</span>
<span id="cb117-3"><a href="#cb117-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb117-4"><a href="#cb117-4" aria-hidden="true" tabindex="-1"></a>uploaded <span class="op">=</span> files.upload()</span>
<span id="cb117-5"><a href="#cb117-5" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> uploaded:</span>
<span id="cb117-6"><a href="#cb117-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">&quot;No file uploaded.&quot;</span>)</span>
<span id="cb117-7"><a href="#cb117-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb117-8"><a href="#cb117-8" aria-hidden="true" tabindex="-1"></a><span class="co"># multiple files upload</span></span>
<span id="cb117-9"><a href="#cb117-9" aria-hidden="true" tabindex="-1"></a>fname, data <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(uploaded.items()))</span>
<span id="cb117-10"><a href="#cb117-10" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(io.BytesIO(data))</span>
<span id="cb117-11"><a href="#cb117-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Loaded: </span><span class="sc">{</span>fname<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb117-12"><a href="#cb117-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb117-13"><a href="#cb117-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Build heatmap for DistilBERT</span></span>
<span id="cb117-14"><a href="#cb117-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Required columns</span></span>
<span id="cb117-15"><a href="#cb117-15" aria-hidden="true" tabindex="-1"></a>cols <span class="op">=</span> [</span>
<span id="cb117-16"><a href="#cb117-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;recall_Design_Science_-_System_Design&quot;</span>,</span>
<span id="cb117-17"><a href="#cb117-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;recall_Mixed_Methods&quot;</span>,</span>
<span id="cb117-18"><a href="#cb117-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;recall_Qualitative&quot;</span>,</span>
<span id="cb117-19"><a href="#cb117-19" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;recall_Theoretical_-_Conceptual&quot;</span>,</span>
<span id="cb117-20"><a href="#cb117-20" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb117-21"><a href="#cb117-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb117-22"><a href="#cb117-22" aria-hidden="true" tabindex="-1"></a>required <span class="op">=</span> {<span class="st">&quot;run&quot;</span>, <span class="op">*</span>cols}</span>
<span id="cb117-23"><a href="#cb117-23" aria-hidden="true" tabindex="-1"></a>missing <span class="op">=</span> required.difference(df.columns)</span>
<span id="cb117-24"><a href="#cb117-24" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> missing:</span>
<span id="cb117-25"><a href="#cb117-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f&quot;Missing columns in CSV: </span><span class="sc">{</span>missing<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb117-26"><a href="#cb117-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb117-27"><a href="#cb117-27" aria-hidden="true" tabindex="-1"></a>order <span class="op">=</span> [<span class="st">&quot;E1_len256&quot;</span>, <span class="st">&quot;E2_scheduler_len256&quot;</span>, <span class="st">&quot;E3_classweights_len256&quot;</span>]</span>
<span id="cb117-28"><a href="#cb117-28" aria-hidden="true" tabindex="-1"></a>df_c <span class="op">=</span> df[df[<span class="st">&quot;run&quot;</span>].isin(order)].set_index(<span class="st">&quot;run&quot;</span>).loc[order].reset_index()</span>
<span id="cb117-29"><a href="#cb117-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb117-30"><a href="#cb117-30" aria-hidden="true" tabindex="-1"></a><span class="co"># axis labels</span></span>
<span id="cb117-31"><a href="#cb117-31" aria-hidden="true" tabindex="-1"></a>pretty <span class="op">=</span> [<span class="st">&quot;DesignScience/SystemDesign&quot;</span>, <span class="st">&quot;MixedMethods&quot;</span>, <span class="st">&quot;Qualitative&quot;</span>, <span class="st">&quot;Theoretical/Conceptual&quot;</span>]</span>
<span id="cb117-32"><a href="#cb117-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb117-33"><a href="#cb117-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot heatmap</span></span>
<span id="cb117-34"><a href="#cb117-34" aria-hidden="true" tabindex="-1"></a>mat <span class="op">=</span> df_c[cols].to_numpy()</span>
<span id="cb117-35"><a href="#cb117-35" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="fl">3.6</span>))</span>
<span id="cb117-36"><a href="#cb117-36" aria-hidden="true" tabindex="-1"></a>plt.imshow(mat, aspect<span class="op">=</span><span class="st">&quot;auto&quot;</span>)</span>
<span id="cb117-37"><a href="#cb117-37" aria-hidden="true" tabindex="-1"></a>plt.xticks(<span class="bu">range</span>(<span class="bu">len</span>(pretty)), pretty, rotation<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb117-38"><a href="#cb117-38" aria-hidden="true" tabindex="-1"></a>plt.yticks(<span class="bu">range</span>(<span class="bu">len</span>(order)), [<span class="st">&quot;DistilBERT E1&quot;</span>, <span class="st">&quot;DistilBERT E2&quot;</span>, <span class="st">&quot;DistilBERT E3&quot;</span>])</span>
<span id="cb117-39"><a href="#cb117-39" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb117-40"><a href="#cb117-40" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;DistilBERT — Per-class Recall (Methodology)&quot;</span>)</span>
<span id="cb117-41"><a href="#cb117-41" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb117-42"><a href="#cb117-42" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">

     <input type="file" id="files-dbf843b4-94ec-461d-a603-1ac32f491b43" name="files[]" multiple disabled
        style="border:none" />
     <output id="result-dbf843b4-94ec-461d-a603-1ac32f491b43">
      Upload widget is only available when the cell has been executed in the
      current browser session. Please rerun this cell to enable.
      </output>
      <script>// Copyright 2017 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

/**
 * @fileoverview Helpers for google.colab Python module.
 */
(function(scope) {
function span(text, styleAttributes = {}) {
  const element = document.createElement('span');
  element.textContent = text;
  for (const key of Object.keys(styleAttributes)) {
    element.style[key] = styleAttributes[key];
  }
  return element;
}

// Max number of bytes which will be uploaded at a time.
const MAX_PAYLOAD_SIZE = 100 * 1024;

function _uploadFiles(inputId, outputId) {
  const steps = uploadFilesStep(inputId, outputId);
  const outputElement = document.getElementById(outputId);
  // Cache steps on the outputElement to make it available for the next call
  // to uploadFilesContinue from Python.
  outputElement.steps = steps;

  return _uploadFilesContinue(outputId);
}

// This is roughly an async generator (not supported in the browser yet),
// where there are multiple asynchronous steps and the Python side is going
// to poll for completion of each step.
// This uses a Promise to block the python side on completion of each step,
// then passes the result of the previous step as the input to the next step.
function _uploadFilesContinue(outputId) {
  const outputElement = document.getElementById(outputId);
  const steps = outputElement.steps;

  const next = steps.next(outputElement.lastPromiseValue);
  return Promise.resolve(next.value.promise).then((value) => {
    // Cache the last promise value to make it available to the next
    // step of the generator.
    outputElement.lastPromiseValue = value;
    return next.value.response;
  });
}

/**
 * Generator function which is called between each async step of the upload
 * process.
 * @param {string} inputId Element ID of the input file picker element.
 * @param {string} outputId Element ID of the output display.
 * @return {!Iterable<!Object>} Iterable of next steps.
 */
function* uploadFilesStep(inputId, outputId) {
  const inputElement = document.getElementById(inputId);
  inputElement.disabled = false;

  const outputElement = document.getElementById(outputId);
  outputElement.innerHTML = '';

  const pickedPromise = new Promise((resolve) => {
    inputElement.addEventListener('change', (e) => {
      resolve(e.target.files);
    });
  });

  const cancel = document.createElement('button');
  inputElement.parentElement.appendChild(cancel);
  cancel.textContent = 'Cancel upload';
  const cancelPromise = new Promise((resolve) => {
    cancel.onclick = () => {
      resolve(null);
    };
  });

  // Wait for the user to pick the files.
  const files = yield {
    promise: Promise.race([pickedPromise, cancelPromise]),
    response: {
      action: 'starting',
    }
  };

  cancel.remove();

  // Disable the input element since further picks are not allowed.
  inputElement.disabled = true;

  if (!files) {
    return {
      response: {
        action: 'complete',
      }
    };
  }

  for (const file of files) {
    const li = document.createElement('li');
    li.append(span(file.name, {fontWeight: 'bold'}));
    li.append(span(
        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +
        `last modified: ${
            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :
                                    'n/a'} - `));
    const percent = span('0% done');
    li.appendChild(percent);

    outputElement.appendChild(li);

    const fileDataPromise = new Promise((resolve) => {
      const reader = new FileReader();
      reader.onload = (e) => {
        resolve(e.target.result);
      };
      reader.readAsArrayBuffer(file);
    });
    // Wait for the data to be ready.
    let fileData = yield {
      promise: fileDataPromise,
      response: {
        action: 'continue',
      }
    };

    // Use a chunked sending to avoid message size limits. See b/62115660.
    let position = 0;
    do {
      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);
      const chunk = new Uint8Array(fileData, position, length);
      position += length;

      const base64 = btoa(String.fromCharCode.apply(null, chunk));
      yield {
        response: {
          action: 'append',
          file: file.name,
          data: base64,
        },
      };

      let percentDone = fileData.byteLength === 0 ?
          100 :
          Math.round((position / fileData.byteLength) * 100);
      percent.textContent = `${percentDone}% done`;

    } while (position < fileData.byteLength);
  }

  // All done.
  yield {
    response: {
      action: 'complete',
    }
  };
}

scope.google = scope.google || {};
scope.google.colab = scope.google.colab || {};
scope.google.colab._files = {
  _uploadFiles,
  _uploadFilesContinue,
};
})(self);
</script> 
</div>
<div class="output stream stdout">
<pre><code>Saving C2_distilBERT_methodology_E123_summary.csv to C2_distilBERT_methodology_E123_summary.csv
Loaded: C2_distilBERT_methodology_E123_summary.csv
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_e37543f3817e498792271d4afeefc0f0/661c137ed6f15c16c9fb2d9b97a51b2267888e27.png" /></p>
</div>
</div>
<section id="5-model-comparisons" class="cell markdown"
id="k0Mug62OKqn_">
<h1>5. Model Comparisons</h1>
<p>This section compare baselines and extensions using the same
preprocessed data and the same 80/20 split (seed=42). The goal is to
show outcomes side-by-side and explain what those outcomes mean for the
project.</p>
<p>Evaluation lens.</p>
<ul>
<li><p>Macro-F1 (equal weight per class). This reflects the project’s
need to recognise all methodology types rather than optimise only for
the majority label.</p></li>
<li><p>Overall validation accuracy (stability) and per-class recall (who
benefits or suffers).</p></li>
<li><p>Identical preprocessing; fixed token length within each
comparison (512 for the “Model 1” baselines; 256 for extended C/D/E
runs); same random seed; and no re-tuning between models beyond the
planned knobs in Section 4.</p></li>
</ul>
<p>In this section we discuss the following:</p>
<ul>
<li><p>5.1 TF-IDF vs SciBERT Model 1. A head-to-head to show what modern
pretraining buys over a strong linear baseline using identical labels
and metrics.</p></li>
<li><p>5.2 Transformer Model 1’s. SciBERT vs RoBERTa vs DistilBERT at
the same setup to separate architecture/pretraining effects from
training tricks.</p></li>
<li><p>5.3 All Models, Macro-F1. A single horizontal bar chart for every
run (baselines + C/D/E variants) to reveal the ranking at a
glance.</p></li>
<li><p>5.4 All Models, Per-Class Recall. A heatmap to inspect
trade-offs: e.g., whether gains on Mixed Methods or Qualitative come at
the expense of Design Science / System Design.</p></li>
</ul>
<p>The comparisons prioritise models that lift minority recalls without
collapsing majority performance. In practice, that means macro-F1 leads
the decision, with recall heatmaps as the tie-breaker. You’ll see that
the baseline SciBERT Model 1 remains a strong all-rounder under this
lens; some RoBERTa and DistilBERT variants provide interesting
trade-offs (e.g., slightly higher accuracy or better recall on specific
classes) that are worth noting depending on deployment constraints.</p>
</section>
<section id="51-tf-idf-vs-transformer-scibert-model-1"
class="cell markdown" id="w2dOdoX4uMNl">
<h2>5.1 TF-IDF vs Transformer (SciBERT Model 1)</h2>
<p>I put SciBERT Model 1 against two TF-IDF baselines (TF-IDF Basic and
TF-IDF KFold). All use the same label space and evaluation on the
methodology task.</p>
<ul>
<li><p>Macro-F1: SciBERT ≈ 0.59 vs TF-IDF ≈ 0.39 / 0.38.</p></li>
<li><p>Val. accuracy: SciBERT ≈ 0.82 vs TF-IDF ≈ 0.756–0.759.</p></li>
<li><p>Per-class recall:</p>
<ul>
<li>Design Science/System Design: 0.946 (SciBERT) vs ~0.931 (both
TF-IDF).</li>
<li>Mixed Methods: ~0.35 (SciBERT) vs 0.044 / 0.018 (TF-IDF).</li>
<li>Qualitative: ~0.17 (SciBERT) vs 0.00 / 0.00 (TF-IDF).</li>
<li>Theoretical/Conceptual: ~0.73 (SciBERT) vs ~0.57 / 0.59
(TF-IDF).</li>
</ul></li>
</ul>
<p>The bar and radar charts tell the same story: TF-IDF holds up on the
majority class (DS/SD) but collapses on the small, diffuse categories
(Mixed Methods, Qualitative). SciBERT’s contextual representations
pretrained on scientific text recover signal that isn’t tied to specific
keywords (e.g., multi-clause descriptions of study design, hedging, or
reasoning verbs), so minority recalls rise without losing the strong
DS/SD performance. Cross-validation on TF-IDF doesn’t fix the issue
because the limitation is representational, not just variance from a
single split.</p>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:694}"
id="wNL_8iSCHGLn" data-outputId="34c1ed5a-90d3-492d-aa74-d358966dc7c1">
<div class="sourceCode" id="cb119"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> google.colab <span class="im">import</span> files</span>
<span id="cb119-2"><a href="#cb119-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Upload one or more CSVs</span></span>
<span id="cb119-3"><a href="#cb119-3" aria-hidden="true" tabindex="-1"></a>up <span class="op">=</span> files.upload()</span>
<span id="cb119-4"><a href="#cb119-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-5"><a href="#cb119-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Read → keep only TF-IDF metric set → stack</span></span>
<span id="cb119-6"><a href="#cb119-6" aria-hidden="true" tabindex="-1"></a>dfs <span class="op">=</span> []</span>
<span id="cb119-7"><a href="#cb119-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _, data <span class="kw">in</span> up.items():</span>
<span id="cb119-8"><a href="#cb119-8" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> pd.read_csv(io.BytesIO(data))</span>
<span id="cb119-9"><a href="#cb119-9" aria-hidden="true" tabindex="-1"></a>    keep <span class="op">=</span> [c <span class="cf">for</span> c <span class="kw">in</span> df.columns <span class="cf">if</span> c <span class="op">==</span> <span class="st">&quot;run&quot;</span> <span class="kw">or</span> c <span class="kw">in</span> (<span class="st">&quot;val_acc&quot;</span>, <span class="st">&quot;macro_f1&quot;</span>) <span class="kw">or</span> c.lower().startswith(<span class="st">&quot;recall_&quot;</span>)]</span>
<span id="cb119-10"><a href="#cb119-10" aria-hidden="true" tabindex="-1"></a>    dfs.append(df[keep])</span>
<span id="cb119-11"><a href="#cb119-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-12"><a href="#cb119-12" aria-hidden="true" tabindex="-1"></a>combined <span class="op">=</span> pd.concat(dfs, ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb119-13"><a href="#cb119-13" aria-hidden="true" tabindex="-1"></a>combined <span class="op">=</span> combined[</span>
<span id="cb119-14"><a href="#cb119-14" aria-hidden="true" tabindex="-1"></a>    [<span class="st">&quot;run&quot;</span>]</span>
<span id="cb119-15"><a href="#cb119-15" aria-hidden="true" tabindex="-1"></a>    <span class="op">+</span> [c <span class="cf">for</span> c <span class="kw">in</span> (<span class="st">&quot;val_acc&quot;</span>, <span class="st">&quot;macro_f1&quot;</span>) <span class="cf">if</span> c <span class="kw">in</span> combined.columns]</span>
<span id="cb119-16"><a href="#cb119-16" aria-hidden="true" tabindex="-1"></a>    <span class="op">+</span> [c <span class="cf">for</span> c <span class="kw">in</span> combined.columns <span class="cf">if</span> c.lower().startswith(<span class="st">&quot;recall_&quot;</span>)]</span>
<span id="cb119-17"><a href="#cb119-17" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb119-18"><a href="#cb119-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-19"><a href="#cb119-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Rename recalls for display</span></span>
<span id="cb119-20"><a href="#cb119-20" aria-hidden="true" tabindex="-1"></a>combined <span class="op">=</span> combined.rename(columns<span class="op">=</span>{</span>
<span id="cb119-21"><a href="#cb119-21" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;recall_Design_Science_/_System_Design&quot;</span>: <span class="st">&quot;Recall_DS/SD&quot;</span>,</span>
<span id="cb119-22"><a href="#cb119-22" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;recall_Mixed_Methods&quot;</span>: <span class="st">&quot;Recall_MM&quot;</span>,</span>
<span id="cb119-23"><a href="#cb119-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;recall_Qualitative&quot;</span>: <span class="st">&quot;Recall_Qual&quot;</span>,</span>
<span id="cb119-24"><a href="#cb119-24" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;recall_Theoretical_/_Conceptual&quot;</span>: <span class="st">&quot;Recall_TC&quot;</span>,</span>
<span id="cb119-25"><a href="#cb119-25" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb119-26"><a href="#cb119-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-27"><a href="#cb119-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Round + show</span></span>
<span id="cb119-28"><a href="#cb119-28" aria-hidden="true" tabindex="-1"></a>num_cols <span class="op">=</span> combined.select_dtypes(<span class="st">&quot;number&quot;</span>).columns</span>
<span id="cb119-29"><a href="#cb119-29" aria-hidden="true" tabindex="-1"></a>combined[num_cols] <span class="op">=</span> combined[num_cols].<span class="bu">round</span>(<span class="dv">6</span>)</span>
<span id="cb119-30"><a href="#cb119-30" aria-hidden="true" tabindex="-1"></a>display(combined)</span>
<span id="cb119-31"><a href="#cb119-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-32"><a href="#cb119-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb119-33"><a href="#cb119-33" aria-hidden="true" tabindex="-1"></a>metrics <span class="op">=</span> [c <span class="cf">for</span> c <span class="kw">in</span> [<span class="st">&quot;val_acc&quot;</span>,<span class="st">&quot;macro_f1&quot;</span>,<span class="st">&quot;Recall_DS/SD&quot;</span>,<span class="st">&quot;Recall_MM&quot;</span>,<span class="st">&quot;Recall_Qual&quot;</span>,<span class="st">&quot;Recall_TC&quot;</span>] <span class="cf">if</span> c <span class="kw">in</span> combined.columns]</span>
<span id="cb119-34"><a href="#cb119-34" aria-hidden="true" tabindex="-1"></a>combined.set_index(<span class="st">&quot;run&quot;</span>)[metrics].plot(kind<span class="op">=</span><span class="st">&quot;bar&quot;</span>, figsize<span class="op">=</span>(<span class="dv">12</span>,<span class="dv">6</span>), rot<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb119-35"><a href="#cb119-35" aria-hidden="true" tabindex="-1"></a>plt.ylim(<span class="dv">0</span>, <span class="fl">1.05</span>)<span class="op">;</span> plt.grid(axis<span class="op">=</span><span class="st">&quot;y&quot;</span>, linestyle<span class="op">=</span><span class="st">&quot;--&quot;</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)<span class="op">;</span> plt.tight_layout()<span class="op">;</span> plt.show()</span></code></pre></div>
<div class="output display_data">

     <input type="file" id="files-c845c27e-51bf-4b1e-9e56-468f386660b6" name="files[]" multiple disabled
        style="border:none" />
     <output id="result-c845c27e-51bf-4b1e-9e56-468f386660b6">
      Upload widget is only available when the cell has been executed in the
      current browser session. Please rerun this cell to enable.
      </output>
      <script>// Copyright 2017 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

/**
 * @fileoverview Helpers for google.colab Python module.
 */
(function(scope) {
function span(text, styleAttributes = {}) {
  const element = document.createElement('span');
  element.textContent = text;
  for (const key of Object.keys(styleAttributes)) {
    element.style[key] = styleAttributes[key];
  }
  return element;
}

// Max number of bytes which will be uploaded at a time.
const MAX_PAYLOAD_SIZE = 100 * 1024;

function _uploadFiles(inputId, outputId) {
  const steps = uploadFilesStep(inputId, outputId);
  const outputElement = document.getElementById(outputId);
  // Cache steps on the outputElement to make it available for the next call
  // to uploadFilesContinue from Python.
  outputElement.steps = steps;

  return _uploadFilesContinue(outputId);
}

// This is roughly an async generator (not supported in the browser yet),
// where there are multiple asynchronous steps and the Python side is going
// to poll for completion of each step.
// This uses a Promise to block the python side on completion of each step,
// then passes the result of the previous step as the input to the next step.
function _uploadFilesContinue(outputId) {
  const outputElement = document.getElementById(outputId);
  const steps = outputElement.steps;

  const next = steps.next(outputElement.lastPromiseValue);
  return Promise.resolve(next.value.promise).then((value) => {
    // Cache the last promise value to make it available to the next
    // step of the generator.
    outputElement.lastPromiseValue = value;
    return next.value.response;
  });
}

/**
 * Generator function which is called between each async step of the upload
 * process.
 * @param {string} inputId Element ID of the input file picker element.
 * @param {string} outputId Element ID of the output display.
 * @return {!Iterable<!Object>} Iterable of next steps.
 */
function* uploadFilesStep(inputId, outputId) {
  const inputElement = document.getElementById(inputId);
  inputElement.disabled = false;

  const outputElement = document.getElementById(outputId);
  outputElement.innerHTML = '';

  const pickedPromise = new Promise((resolve) => {
    inputElement.addEventListener('change', (e) => {
      resolve(e.target.files);
    });
  });

  const cancel = document.createElement('button');
  inputElement.parentElement.appendChild(cancel);
  cancel.textContent = 'Cancel upload';
  const cancelPromise = new Promise((resolve) => {
    cancel.onclick = () => {
      resolve(null);
    };
  });

  // Wait for the user to pick the files.
  const files = yield {
    promise: Promise.race([pickedPromise, cancelPromise]),
    response: {
      action: 'starting',
    }
  };

  cancel.remove();

  // Disable the input element since further picks are not allowed.
  inputElement.disabled = true;

  if (!files) {
    return {
      response: {
        action: 'complete',
      }
    };
  }

  for (const file of files) {
    const li = document.createElement('li');
    li.append(span(file.name, {fontWeight: 'bold'}));
    li.append(span(
        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +
        `last modified: ${
            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :
                                    'n/a'} - `));
    const percent = span('0% done');
    li.appendChild(percent);

    outputElement.appendChild(li);

    const fileDataPromise = new Promise((resolve) => {
      const reader = new FileReader();
      reader.onload = (e) => {
        resolve(e.target.result);
      };
      reader.readAsArrayBuffer(file);
    });
    // Wait for the data to be ready.
    let fileData = yield {
      promise: fileDataPromise,
      response: {
        action: 'continue',
      }
    };

    // Use a chunked sending to avoid message size limits. See b/62115660.
    let position = 0;
    do {
      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);
      const chunk = new Uint8Array(fileData, position, length);
      position += length;

      const base64 = btoa(String.fromCharCode.apply(null, chunk));
      yield {
        response: {
          action: 'append',
          file: file.name,
          data: base64,
        },
      };

      let percentDone = fileData.byteLength === 0 ?
          100 :
          Math.round((position / fileData.byteLength) * 100);
      percent.textContent = `${percentDone}% done`;

    } while (position < fileData.byteLength);
  }

  // All done.
  yield {
    response: {
      action: 'complete',
    }
  };
}

scope.google = scope.google || {};
scope.google.colab = scope.google.colab || {};
scope.google.colab._files = {
  _uploadFiles,
  _uploadFilesContinue,
};
})(self);
</script> 
</div>
<div class="output stream stdout">
<pre><code>Saving A1_scibert_methodology_1run_summary_len512.csv to A1_scibert_methodology_1run_summary_len512 (4).csv
Saving tfidf_basic_methodology_metrics.csv to tfidf_basic_methodology_metrics (4).csv
Saving tfidf_kfold_methodology_metrics.csv to tfidf_kfold_methodology_metrics (4).csv
</code></pre>
</div>
<div class="output display_data">

  <div id="df-36359552-2940-4a9d-a638-c12c4465736b" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>run</th>
      <th>val_acc</th>
      <th>macro_f1</th>
      <th>Recall_DS/SD</th>
      <th>Recall_MM</th>
      <th>Recall_Qual</th>
      <th>Recall_TC</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>scibert_base_methodology_1run_len512</td>
      <td>0.820054</td>
      <td>0.594046</td>
      <td>0.945985</td>
      <td>0.351064</td>
      <td>0.166667</td>
      <td>0.725000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>TFIDF_basic</td>
      <td>0.756491</td>
      <td>0.390160</td>
      <td>0.934813</td>
      <td>0.044444</td>
      <td>0.000000</td>
      <td>0.566102</td>
    </tr>
    <tr>
      <th>2</th>
      <td>TFIDF_kfold</td>
      <td>0.758689</td>
      <td>0.381373</td>
      <td>0.931408</td>
      <td>0.017778</td>
      <td>0.000000</td>
      <td>0.591063</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-36359552-2940-4a9d-a638-c12c4465736b')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-36359552-2940-4a9d-a638-c12c4465736b button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-36359552-2940-4a9d-a638-c12c4465736b');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    <div id="df-55d9b437-92d3-4bb7-9e22-1d69b53d04f0">
      <button class="colab-df-quickchart" onclick="quickchart('df-55d9b437-92d3-4bb7-9e22-1d69b53d04f0')"
                title="Suggest charts"
                style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
      </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

      <script>
        async function quickchart(key) {
          const quickchartButtonEl =
            document.querySelector('#' + key + ' button');
          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
          quickchartButtonEl.classList.add('colab-df-spinner');
          try {
            const charts = await google.colab.kernel.invokeFunction(
                'suggestCharts', [key], {});
          } catch (error) {
            console.error('Error during call to suggestCharts:', error);
          }
          quickchartButtonEl.classList.remove('colab-df-spinner');
          quickchartButtonEl.classList.add('colab-df-quickchart-complete');
        }
        (() => {
          let quickchartButtonEl =
            document.querySelector('#df-55d9b437-92d3-4bb7-9e22-1d69b53d04f0 button');
          quickchartButtonEl.style.display =
            google.colab.kernel.accessAllowed ? 'block' : 'none';
        })();
      </script>
    </div>

  <div id="id_31ff8628-5b6a-4c0f-b090-c4ad6c0fc68f">
    <style>
      .colab-df-generate {
        background-color: #E8F0FE;
        border: none;
        border-radius: 50%;
        cursor: pointer;
        display: none;
        fill: #1967D2;
        height: 32px;
        padding: 0 0 0 0;
        width: 32px;
      }

      .colab-df-generate:hover {
        background-color: #E2EBFA;
        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
        fill: #174EA6;
      }

      [theme=dark] .colab-df-generate {
        background-color: #3B4455;
        fill: #D2E3FC;
      }

      [theme=dark] .colab-df-generate:hover {
        background-color: #434B5C;
        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
        fill: #FFFFFF;
      }
    </style>
    <button class="colab-df-generate" onclick="generateWithVariable('combined')"
            title="Generate code using this dataframe."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z"/>
  </svg>
    </button>
    <script>
      (() => {
      const buttonEl =
        document.querySelector('#id_31ff8628-5b6a-4c0f-b090-c4ad6c0fc68f button.colab-df-generate');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      buttonEl.onclick = () => {
        google.colab.notebook.generateWithVariable('combined');
      }
      })();
    </script>
  </div>

    </div>
  </div>

</div>
<div class="output display_data">
<p><img
src="vertopal_e37543f3817e498792271d4afeefc0f0/43c4c52d2f6b75e3e42557bab34713dd52929a15.png" /></p>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:555}"
id="3imybvPPMNVQ" data-outputId="f65e03e8-4720-4607-f901-a161c6b6b76a">
<div class="sourceCode" id="cb121"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a><span class="co">#  Spider plot</span></span>
<span id="cb121-2"><a href="#cb121-2" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> [<span class="st">&quot;Recall_DS/SD&quot;</span>, <span class="st">&quot;Recall_MM&quot;</span>, <span class="st">&quot;Recall_Qual&quot;</span>, <span class="st">&quot;Recall_TC&quot;</span>]</span>
<span id="cb121-3"><a href="#cb121-3" aria-hidden="true" tabindex="-1"></a>angles <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">2</span><span class="op">*</span>np.pi, <span class="bu">len</span>(labels), endpoint<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb121-4"><a href="#cb121-4" aria-hidden="true" tabindex="-1"></a>angles <span class="op">=</span> np.append(angles, angles[<span class="dv">0</span>])</span>
<span id="cb121-5"><a href="#cb121-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-6"><a href="#cb121-6" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">6</span>), subplot_kw<span class="op">=</span><span class="bu">dict</span>(polar<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb121-7"><a href="#cb121-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-8"><a href="#cb121-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _, row <span class="kw">in</span> combined.iterrows():</span>
<span id="cb121-9"><a href="#cb121-9" aria-hidden="true" tabindex="-1"></a>    vals <span class="op">=</span> row[labels].astype(<span class="bu">float</span>).fillna(<span class="dv">0</span>).to_numpy()</span>
<span id="cb121-10"><a href="#cb121-10" aria-hidden="true" tabindex="-1"></a>    vals <span class="op">=</span> np.append(vals, vals[<span class="dv">0</span>])</span>
<span id="cb121-11"><a href="#cb121-11" aria-hidden="true" tabindex="-1"></a>    ax.plot(angles, vals, label<span class="op">=</span><span class="bu">str</span>(row[<span class="st">&quot;run&quot;</span>]))</span>
<span id="cb121-12"><a href="#cb121-12" aria-hidden="true" tabindex="-1"></a>    ax.fill(angles, vals, alpha<span class="op">=</span><span class="fl">0.10</span>)</span>
<span id="cb121-13"><a href="#cb121-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-14"><a href="#cb121-14" aria-hidden="true" tabindex="-1"></a>ax.set_thetagrids(np.degrees(angles[:<span class="op">-</span><span class="dv">1</span>]), labels)</span>
<span id="cb121-15"><a href="#cb121-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-16"><a href="#cb121-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Title position</span></span>
<span id="cb121-17"><a href="#cb121-17" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">&quot;Per-Class Recall Comparison&quot;</span>, x<span class="op">=</span><span class="fl">0.5</span>, y<span class="op">=</span><span class="fl">0.92</span>)</span>
<span id="cb121-18"><a href="#cb121-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-19"><a href="#cb121-19" aria-hidden="true" tabindex="-1"></a><span class="co"># legend</span></span>
<span id="cb121-20"><a href="#cb121-20" aria-hidden="true" tabindex="-1"></a>plt.legend(</span>
<span id="cb121-21"><a href="#cb121-21" aria-hidden="true" tabindex="-1"></a>    loc<span class="op">=</span><span class="st">&quot;upper center&quot;</span>,</span>
<span id="cb121-22"><a href="#cb121-22" aria-hidden="true" tabindex="-1"></a>    bbox_to_anchor<span class="op">=</span>(<span class="fl">0.7</span>, <span class="fl">0.9</span>),</span>
<span id="cb121-23"><a href="#cb121-23" aria-hidden="true" tabindex="-1"></a>    frameon<span class="op">=</span><span class="va">True</span>, fancybox<span class="op">=</span><span class="va">True</span>, framealpha<span class="op">=</span><span class="fl">0.9</span>,</span>
<span id="cb121-24"><a href="#cb121-24" aria-hidden="true" tabindex="-1"></a>    borderpad<span class="op">=</span><span class="fl">0.4</span>, labelspacing<span class="op">=</span><span class="fl">0.3</span>, handlelength<span class="op">=</span><span class="fl">1.8</span>, handletextpad<span class="op">=</span><span class="fl">0.6</span>,</span>
<span id="cb121-25"><a href="#cb121-25" aria-hidden="true" tabindex="-1"></a>    ncol<span class="op">=</span><span class="dv">1</span>, fontsize<span class="op">=</span><span class="dv">10</span></span>
<span id="cb121-26"><a href="#cb121-26" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb121-27"><a href="#cb121-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-28"><a href="#cb121-28" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb121-29"><a href="#cb121-29" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_e37543f3817e498792271d4afeefc0f0/85598900acd528133aea98aca08592cc8656bcff.png" /></p>
</div>
</div>
<section id="52-transformer-model-1s" class="cell markdown"
id="BZWW7b6IXoEh">
<h2>5.2 Transformer Model 1’s</h2>
<p>Here I held the training recipe constant same split (seed=42),
512-token window, AdamW 2e-5 for 3 epochs with gradient clipping and
swapped only the backbone. The three models bring different priors:
SciBERT is pretrained on scientific text and vocabulary; RoBERTa is a
robustly-trained general-domain encoder; DistilBERT is a distilled,
shallower student of BERT that trades capacity for speed.</p>
<ul>
<li><p>DistilBERT posts the highest validation accuracy (at about
0.829). That number is driven by strong performance on the frequent
labels Theoretical/Conceptual (at about 0.85 recall) and a solid Design
Science/System Design (at about 0.88) and the best Mixed Methods recall
(at about 0.56) of the three. But it never picks Qualitative (0.00
recall) on this split. Accuracy remains high because most instances are
not Qualitative; macro-F1 (which weights classes equally) drops to at
about 0.56 and exposes that blind spot. In other words, DistilBERT is
confident and efficient on the dominant signal, but its decision
boundary essentially excludes the smallest class.</p></li>
<li><p>RoBERTa lands slightly below in accuracy (at about 0.806) and at
about 0.53 macro-F1. It behaves like a stronger TF-IDF: DS/SD at about
0.90, TC at about 0.75, MM at about 0.48, yet Qualitative again goes to
0. The large, general-domain pretraining helps with broad academic
phrasing and terminology, but without explicit rebalancing it doesn’t
discover enough evidence to fire on the most diffuse class.</p></li>
<li><p>SciBERT accuracy (at about 0.820) is close to DistilBERT’s, but
macro-F1 is the best (at about 0.59) because it recovers non-zero
Qualitative (at about 0.17) while still delivering the highest DS/SD
recall (at about 0.946) and a solid TC (at about 0.73). The scientific
vocabulary and discourse pretraining seem to matter here: Qualitative
abstracts often describe method and epistemic stance indirectly rather
than via a tight keyword set. SciBERT picks up enough of that
“scientific rhetoric” to register the class occasionally, which macro-F1
rewards.</p></li>
</ul>
<p>In other words, the scientific-domain pretraining appears to encode
cues in academic prose that are not tied to simple keywords, and
macro-F1 rewards that broader coverage. For this project I prioritise
balanced coverage across labels, so macro-F1 is the deciding metric. On
that basis SciBERT is the strongest backbone to carry forward;
DistilBERT is attractive for efficiency but needs rebalancing to avoid
majority-class bias, and RoBERTa is a solid baseline that benefits from
the extended variants tested next.</p>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:642}"
id="GYDA2oPkXjdv" data-outputId="6eafcd5e-a1ad-4190-c80a-d43bfa9a74e2">
<div class="sourceCode" id="cb122"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> google.colab <span class="im">import</span> files</span>
<span id="cb122-2"><a href="#cb122-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Upload one or more files</span></span>
<span id="cb122-3"><a href="#cb122-3" aria-hidden="true" tabindex="-1"></a>up <span class="op">=</span> files.upload()</span>
<span id="cb122-4"><a href="#cb122-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-5"><a href="#cb122-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Read → keep only TF-IDF metric set → stack</span></span>
<span id="cb122-6"><a href="#cb122-6" aria-hidden="true" tabindex="-1"></a>dfs <span class="op">=</span> []</span>
<span id="cb122-7"><a href="#cb122-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, data <span class="kw">in</span> up.items():</span>
<span id="cb122-8"><a href="#cb122-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> name.lower().endswith((<span class="st">&quot;.xlsx&quot;</span>, <span class="st">&quot;.xls&quot;</span>)):</span>
<span id="cb122-9"><a href="#cb122-9" aria-hidden="true" tabindex="-1"></a>        df <span class="op">=</span> pd.read_excel(io.BytesIO(data))</span>
<span id="cb122-10"><a href="#cb122-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb122-11"><a href="#cb122-11" aria-hidden="true" tabindex="-1"></a>        df <span class="op">=</span> pd.read_csv(io.BytesIO(data))</span>
<span id="cb122-12"><a href="#cb122-12" aria-hidden="true" tabindex="-1"></a>    keep <span class="op">=</span> [c <span class="cf">for</span> c <span class="kw">in</span> df.columns</span>
<span id="cb122-13"><a href="#cb122-13" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> c <span class="op">==</span> <span class="st">&quot;run&quot;</span> <span class="kw">or</span> c <span class="kw">in</span> (<span class="st">&quot;val_acc&quot;</span>, <span class="st">&quot;macro_f1&quot;</span>) <span class="kw">or</span> c.lower().startswith(<span class="st">&quot;recall_&quot;</span>)]</span>
<span id="cb122-14"><a href="#cb122-14" aria-hidden="true" tabindex="-1"></a>    dfs.append(df[keep])</span>
<span id="cb122-15"><a href="#cb122-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-16"><a href="#cb122-16" aria-hidden="true" tabindex="-1"></a>combined <span class="op">=</span> pd.concat(dfs, ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb122-17"><a href="#cb122-17" aria-hidden="true" tabindex="-1"></a>combined <span class="op">=</span> combined[</span>
<span id="cb122-18"><a href="#cb122-18" aria-hidden="true" tabindex="-1"></a>    [<span class="st">&quot;run&quot;</span>]</span>
<span id="cb122-19"><a href="#cb122-19" aria-hidden="true" tabindex="-1"></a>    <span class="op">+</span> [c <span class="cf">for</span> c <span class="kw">in</span> (<span class="st">&quot;val_acc&quot;</span>, <span class="st">&quot;macro_f1&quot;</span>) <span class="cf">if</span> c <span class="kw">in</span> combined.columns]</span>
<span id="cb122-20"><a href="#cb122-20" aria-hidden="true" tabindex="-1"></a>    <span class="op">+</span> [c <span class="cf">for</span> c <span class="kw">in</span> combined.columns <span class="cf">if</span> c.lower().startswith(<span class="st">&quot;recall_&quot;</span>)]</span>
<span id="cb122-21"><a href="#cb122-21" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb122-22"><a href="#cb122-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-23"><a href="#cb122-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Rename recall columns for display</span></span>
<span id="cb122-24"><a href="#cb122-24" aria-hidden="true" tabindex="-1"></a>combined <span class="op">=</span> combined.rename(columns<span class="op">=</span>{</span>
<span id="cb122-25"><a href="#cb122-25" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;recall_Design_Science_/_System_Design&quot;</span>: <span class="st">&quot;Recall_DS/SD&quot;</span>,</span>
<span id="cb122-26"><a href="#cb122-26" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;recall_Mixed_Methods&quot;</span>: <span class="st">&quot;Recall_MM&quot;</span>,</span>
<span id="cb122-27"><a href="#cb122-27" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;recall_Qualitative&quot;</span>: <span class="st">&quot;Recall_Qual&quot;</span>,</span>
<span id="cb122-28"><a href="#cb122-28" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;recall_Theoretical_/_Conceptual&quot;</span>: <span class="st">&quot;Recall_TC&quot;</span>,</span>
<span id="cb122-29"><a href="#cb122-29" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb122-30"><a href="#cb122-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-31"><a href="#cb122-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Round + show</span></span>
<span id="cb122-32"><a href="#cb122-32" aria-hidden="true" tabindex="-1"></a>num_cols <span class="op">=</span> combined.select_dtypes(<span class="st">&quot;number&quot;</span>).columns</span>
<span id="cb122-33"><a href="#cb122-33" aria-hidden="true" tabindex="-1"></a>combined[num_cols] <span class="op">=</span> combined[num_cols].<span class="bu">round</span>(<span class="dv">6</span>)</span>
<span id="cb122-34"><a href="#cb122-34" aria-hidden="true" tabindex="-1"></a>display(combined)</span>
<span id="cb122-35"><a href="#cb122-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-36"><a href="#cb122-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb122-37"><a href="#cb122-37" aria-hidden="true" tabindex="-1"></a>metrics <span class="op">=</span> [c <span class="cf">for</span> c <span class="kw">in</span> [<span class="st">&quot;val_acc&quot;</span>,<span class="st">&quot;macro_f1&quot;</span>,<span class="st">&quot;Recall_DS/SD&quot;</span>,<span class="st">&quot;Recall_MM&quot;</span>,<span class="st">&quot;Recall_Qual&quot;</span>,<span class="st">&quot;Recall_TC&quot;</span>] <span class="cf">if</span> c <span class="kw">in</span> combined.columns]</span>
<span id="cb122-38"><a href="#cb122-38" aria-hidden="true" tabindex="-1"></a>combined.set_index(<span class="st">&quot;run&quot;</span>)[metrics].plot(kind<span class="op">=</span><span class="st">&quot;bar&quot;</span>, figsize<span class="op">=</span>(<span class="dv">12</span>,<span class="dv">6</span>), rot<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb122-39"><a href="#cb122-39" aria-hidden="true" tabindex="-1"></a>plt.ylim(<span class="dv">0</span>, <span class="fl">1.05</span>)<span class="op">;</span> plt.grid(axis<span class="op">=</span><span class="st">&quot;y&quot;</span>, linestyle<span class="op">=</span><span class="st">&quot;--&quot;</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)<span class="op">;</span> plt.tight_layout()<span class="op">;</span> plt.show()</span></code></pre></div>
<div class="output display_data">

     <input type="file" id="files-f8496383-4a79-48cf-b82d-c3dc6b9e1048" name="files[]" multiple disabled
        style="border:none" />
     <output id="result-f8496383-4a79-48cf-b82d-c3dc6b9e1048">
      Upload widget is only available when the cell has been executed in the
      current browser session. Please rerun this cell to enable.
      </output>
      <script>// Copyright 2017 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

/**
 * @fileoverview Helpers for google.colab Python module.
 */
(function(scope) {
function span(text, styleAttributes = {}) {
  const element = document.createElement('span');
  element.textContent = text;
  for (const key of Object.keys(styleAttributes)) {
    element.style[key] = styleAttributes[key];
  }
  return element;
}

// Max number of bytes which will be uploaded at a time.
const MAX_PAYLOAD_SIZE = 100 * 1024;

function _uploadFiles(inputId, outputId) {
  const steps = uploadFilesStep(inputId, outputId);
  const outputElement = document.getElementById(outputId);
  // Cache steps on the outputElement to make it available for the next call
  // to uploadFilesContinue from Python.
  outputElement.steps = steps;

  return _uploadFilesContinue(outputId);
}

// This is roughly an async generator (not supported in the browser yet),
// where there are multiple asynchronous steps and the Python side is going
// to poll for completion of each step.
// This uses a Promise to block the python side on completion of each step,
// then passes the result of the previous step as the input to the next step.
function _uploadFilesContinue(outputId) {
  const outputElement = document.getElementById(outputId);
  const steps = outputElement.steps;

  const next = steps.next(outputElement.lastPromiseValue);
  return Promise.resolve(next.value.promise).then((value) => {
    // Cache the last promise value to make it available to the next
    // step of the generator.
    outputElement.lastPromiseValue = value;
    return next.value.response;
  });
}

/**
 * Generator function which is called between each async step of the upload
 * process.
 * @param {string} inputId Element ID of the input file picker element.
 * @param {string} outputId Element ID of the output display.
 * @return {!Iterable<!Object>} Iterable of next steps.
 */
function* uploadFilesStep(inputId, outputId) {
  const inputElement = document.getElementById(inputId);
  inputElement.disabled = false;

  const outputElement = document.getElementById(outputId);
  outputElement.innerHTML = '';

  const pickedPromise = new Promise((resolve) => {
    inputElement.addEventListener('change', (e) => {
      resolve(e.target.files);
    });
  });

  const cancel = document.createElement('button');
  inputElement.parentElement.appendChild(cancel);
  cancel.textContent = 'Cancel upload';
  const cancelPromise = new Promise((resolve) => {
    cancel.onclick = () => {
      resolve(null);
    };
  });

  // Wait for the user to pick the files.
  const files = yield {
    promise: Promise.race([pickedPromise, cancelPromise]),
    response: {
      action: 'starting',
    }
  };

  cancel.remove();

  // Disable the input element since further picks are not allowed.
  inputElement.disabled = true;

  if (!files) {
    return {
      response: {
        action: 'complete',
      }
    };
  }

  for (const file of files) {
    const li = document.createElement('li');
    li.append(span(file.name, {fontWeight: 'bold'}));
    li.append(span(
        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +
        `last modified: ${
            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :
                                    'n/a'} - `));
    const percent = span('0% done');
    li.appendChild(percent);

    outputElement.appendChild(li);

    const fileDataPromise = new Promise((resolve) => {
      const reader = new FileReader();
      reader.onload = (e) => {
        resolve(e.target.result);
      };
      reader.readAsArrayBuffer(file);
    });
    // Wait for the data to be ready.
    let fileData = yield {
      promise: fileDataPromise,
      response: {
        action: 'continue',
      }
    };

    // Use a chunked sending to avoid message size limits. See b/62115660.
    let position = 0;
    do {
      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);
      const chunk = new Uint8Array(fileData, position, length);
      position += length;

      const base64 = btoa(String.fromCharCode.apply(null, chunk));
      yield {
        response: {
          action: 'append',
          file: file.name,
          data: base64,
        },
      };

      let percentDone = fileData.byteLength === 0 ?
          100 :
          Math.round((position / fileData.byteLength) * 100);
      percent.textContent = `${percentDone}% done`;

    } while (position < fileData.byteLength);
  }

  // All done.
  yield {
    response: {
      action: 'complete',
    }
  };
}

scope.google = scope.google || {};
scope.google.colab = scope.google.colab || {};
scope.google.colab._files = {
  _uploadFiles,
  _uploadFilesContinue,
};
})(self);
</script> 
</div>
<div class="output stream stdout">
<pre><code>Saving all_model1.xlsx to all_model1.xlsx
</code></pre>
</div>
<div class="output display_data">

  <div id="df-8de538ee-2584-4cf1-8dd9-057d819f48fd" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>run</th>
      <th>val_acc</th>
      <th>macro_f1</th>
      <th>Recall_DS/SD</th>
      <th>Recall_MM</th>
      <th>Recall_Qual</th>
      <th>Recall_TC</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>scibert_base_methodology_1run_len512</td>
      <td>0.820054</td>
      <td>0.594046</td>
      <td>0.945985</td>
      <td>0.351064</td>
      <td>0.166667</td>
      <td>0.725000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>roberta_base_methodology_1run_len512</td>
      <td>0.805730</td>
      <td>0.531523</td>
      <td>0.896350</td>
      <td>0.478723</td>
      <td>0.000000</td>
      <td>0.753125</td>
    </tr>
    <tr>
      <th>2</th>
      <td>distilbert_base_len512</td>
      <td>0.829006</td>
      <td>0.562073</td>
      <td>0.878832</td>
      <td>0.563830</td>
      <td>0.000000</td>
      <td>0.846875</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-8de538ee-2584-4cf1-8dd9-057d819f48fd')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-8de538ee-2584-4cf1-8dd9-057d819f48fd button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-8de538ee-2584-4cf1-8dd9-057d819f48fd');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    <div id="df-8d810e4f-0bf9-4ac0-ad2e-35b53851a081">
      <button class="colab-df-quickchart" onclick="quickchart('df-8d810e4f-0bf9-4ac0-ad2e-35b53851a081')"
                title="Suggest charts"
                style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
      </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

      <script>
        async function quickchart(key) {
          const quickchartButtonEl =
            document.querySelector('#' + key + ' button');
          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
          quickchartButtonEl.classList.add('colab-df-spinner');
          try {
            const charts = await google.colab.kernel.invokeFunction(
                'suggestCharts', [key], {});
          } catch (error) {
            console.error('Error during call to suggestCharts:', error);
          }
          quickchartButtonEl.classList.remove('colab-df-spinner');
          quickchartButtonEl.classList.add('colab-df-quickchart-complete');
        }
        (() => {
          let quickchartButtonEl =
            document.querySelector('#df-8d810e4f-0bf9-4ac0-ad2e-35b53851a081 button');
          quickchartButtonEl.style.display =
            google.colab.kernel.accessAllowed ? 'block' : 'none';
        })();
      </script>
    </div>

  <div id="id_56ea5ab0-36a6-4161-9ce2-70335c4851e8">
    <style>
      .colab-df-generate {
        background-color: #E8F0FE;
        border: none;
        border-radius: 50%;
        cursor: pointer;
        display: none;
        fill: #1967D2;
        height: 32px;
        padding: 0 0 0 0;
        width: 32px;
      }

      .colab-df-generate:hover {
        background-color: #E2EBFA;
        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
        fill: #174EA6;
      }

      [theme=dark] .colab-df-generate {
        background-color: #3B4455;
        fill: #D2E3FC;
      }

      [theme=dark] .colab-df-generate:hover {
        background-color: #434B5C;
        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
        fill: #FFFFFF;
      }
    </style>
    <button class="colab-df-generate" onclick="generateWithVariable('combined')"
            title="Generate code using this dataframe."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z"/>
  </svg>
    </button>
    <script>
      (() => {
      const buttonEl =
        document.querySelector('#id_56ea5ab0-36a6-4161-9ce2-70335c4851e8 button.colab-df-generate');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      buttonEl.onclick = () => {
        google.colab.notebook.generateWithVariable('combined');
      }
      })();
    </script>
  </div>

    </div>
  </div>

</div>
<div class="output display_data">
<p><img
src="vertopal_e37543f3817e498792271d4afeefc0f0/738009630df6ecaa53cfc60f4147ab079eecc54c.png" /></p>
</div>
</div>
<section id="53-all-models-macro-f1" class="cell markdown"
id="2nqgGInWAM-u">
<h2>5.3 All Models (Macro F1)</h2>
<p>The macro-F1 ranking across all baselines and extensions shows a
stable pattern: SciBERT Model 1 delivers the highest balanced
performance without relying on aggressive training heuristics. This is
not an artefact of one split or token length. The token-length study
established that 256 tokens cover almost all abstracts, and across both
512 and 256 contexts the ordering remains consistent. Where extensions
help (e.g., RoBERTa with loss weights), gains are incremental and
confined to specific families; they do not overturn the ranking.</p>
<p>The most plausible explanation is representational: SciBERT’s
pretraining on scientific corpora confers an inductive bias that aligns
with methodological language (e.g., study design, theoretical framing,
evidential stance) that is distributed across sentences rather than
concentrated in keywords. DistilBERT attains strong accuracy through
confident decisions on the frequent labels, but macro-F1 reveals a gap
on minority classes. RoBERTa is competitive yet typically requires
weighting or sampling to approach the same balance.</p>
<p>Conclusion. For a classifier where balanced coverage is the objective
metric, I select SciBERT Model 1 as the reference model. It achieves the
highest macro-F1, preserves high recall on the easy classes, and
critically does so without fragile, run-specific tuning. This makes it
the most defensible backbone to carry forward into downstream analyses
and the multi-label pipeline.</p>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:740}"
id="-bGwFrn2sF8m" data-outputId="3ecef52d-7da4-4c8c-8607-ace29c5920ad">
<div class="sourceCode" id="cb124"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> google.colab <span class="im">import</span> files</span>
<span id="cb124-2"><a href="#cb124-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Upload one or more files</span></span>
<span id="cb124-3"><a href="#cb124-3" aria-hidden="true" tabindex="-1"></a>up <span class="op">=</span> files.upload()</span>
<span id="cb124-4"><a href="#cb124-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-5"><a href="#cb124-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Read ALL columns and combine</span></span>
<span id="cb124-6"><a href="#cb124-6" aria-hidden="true" tabindex="-1"></a>dfs_full <span class="op">=</span> []</span>
<span id="cb124-7"><a href="#cb124-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, data <span class="kw">in</span> up.items():</span>
<span id="cb124-8"><a href="#cb124-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> name.lower().endswith((<span class="st">&quot;.xlsx&quot;</span>, <span class="st">&quot;.xls&quot;</span>)):</span>
<span id="cb124-9"><a href="#cb124-9" aria-hidden="true" tabindex="-1"></a>        df <span class="op">=</span> pd.read_excel(io.BytesIO(data))</span>
<span id="cb124-10"><a href="#cb124-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb124-11"><a href="#cb124-11" aria-hidden="true" tabindex="-1"></a>        df <span class="op">=</span> pd.read_csv(io.BytesIO(data))</span>
<span id="cb124-12"><a href="#cb124-12" aria-hidden="true" tabindex="-1"></a>    dfs_full.append(df)</span>
<span id="cb124-13"><a href="#cb124-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-14"><a href="#cb124-14" aria-hidden="true" tabindex="-1"></a>full_df <span class="op">=</span> pd.concat(dfs_full, ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb124-15"><a href="#cb124-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-16"><a href="#cb124-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Macro-F1 bar chart</span></span>
<span id="cb124-17"><a href="#cb124-17" aria-hidden="true" tabindex="-1"></a>plot_df <span class="op">=</span> full_df[[<span class="st">&quot;run&quot;</span>, <span class="st">&quot;macro_f1&quot;</span>]].dropna().copy()</span>
<span id="cb124-18"><a href="#cb124-18" aria-hidden="true" tabindex="-1"></a>plot_df[<span class="st">&quot;macro_f1&quot;</span>] <span class="op">=</span> plot_df[<span class="st">&quot;macro_f1&quot;</span>].astype(<span class="bu">float</span>).<span class="bu">round</span>(<span class="dv">6</span>)</span>
<span id="cb124-19"><a href="#cb124-19" aria-hidden="true" tabindex="-1"></a>plot_df <span class="op">=</span> plot_df.sort_values(<span class="st">&quot;macro_f1&quot;</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb124-20"><a href="#cb124-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-21"><a href="#cb124-21" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="bu">max</span>(<span class="dv">3</span>, <span class="fl">0.5</span> <span class="op">*</span> <span class="bu">len</span>(plot_df) <span class="op">+</span> <span class="dv">1</span>)))</span>
<span id="cb124-22"><a href="#cb124-22" aria-hidden="true" tabindex="-1"></a>ax.barh(plot_df[<span class="st">&quot;run&quot;</span>], plot_df[<span class="st">&quot;macro_f1&quot;</span>], color<span class="op">=</span><span class="st">&quot;tab:orange&quot;</span>)</span>
<span id="cb124-23"><a href="#cb124-23" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">&quot;Macro F1&quot;</span>)<span class="op">;</span> ax.set_ylabel(<span class="st">&quot;&quot;</span>)<span class="op">;</span> ax.set_xlim(<span class="dv">0</span>, <span class="fl">1.05</span>)</span>
<span id="cb124-24"><a href="#cb124-24" aria-hidden="true" tabindex="-1"></a>ax.grid(axis<span class="op">=</span><span class="st">&quot;x&quot;</span>, linestyle<span class="op">=</span><span class="st">&quot;--&quot;</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb124-25"><a href="#cb124-25" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, v <span class="kw">in</span> <span class="bu">enumerate</span>(plot_df[<span class="st">&quot;macro_f1&quot;</span>]):</span>
<span id="cb124-26"><a href="#cb124-26" aria-hidden="true" tabindex="-1"></a>    ax.text(v <span class="op">+</span> <span class="fl">0.01</span>, i, <span class="ss">f&quot;</span><span class="sc">{</span>v<span class="sc">:.3f}</span><span class="ss">&quot;</span>, va<span class="op">=</span><span class="st">&quot;center&quot;</span>)</span>
<span id="cb124-27"><a href="#cb124-27" aria-hidden="true" tabindex="-1"></a>ax.invert_yaxis()</span>
<span id="cb124-28"><a href="#cb124-28" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()<span class="op">;</span> plt.show()</span></code></pre></div>
<div class="output display_data">

     <input type="file" id="files-bfb2aae0-15ac-4d45-8445-453959764d9b" name="files[]" multiple disabled
        style="border:none" />
     <output id="result-bfb2aae0-15ac-4d45-8445-453959764d9b">
      Upload widget is only available when the cell has been executed in the
      current browser session. Please rerun this cell to enable.
      </output>
      <script>// Copyright 2017 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

/**
 * @fileoverview Helpers for google.colab Python module.
 */
(function(scope) {
function span(text, styleAttributes = {}) {
  const element = document.createElement('span');
  element.textContent = text;
  for (const key of Object.keys(styleAttributes)) {
    element.style[key] = styleAttributes[key];
  }
  return element;
}

// Max number of bytes which will be uploaded at a time.
const MAX_PAYLOAD_SIZE = 100 * 1024;

function _uploadFiles(inputId, outputId) {
  const steps = uploadFilesStep(inputId, outputId);
  const outputElement = document.getElementById(outputId);
  // Cache steps on the outputElement to make it available for the next call
  // to uploadFilesContinue from Python.
  outputElement.steps = steps;

  return _uploadFilesContinue(outputId);
}

// This is roughly an async generator (not supported in the browser yet),
// where there are multiple asynchronous steps and the Python side is going
// to poll for completion of each step.
// This uses a Promise to block the python side on completion of each step,
// then passes the result of the previous step as the input to the next step.
function _uploadFilesContinue(outputId) {
  const outputElement = document.getElementById(outputId);
  const steps = outputElement.steps;

  const next = steps.next(outputElement.lastPromiseValue);
  return Promise.resolve(next.value.promise).then((value) => {
    // Cache the last promise value to make it available to the next
    // step of the generator.
    outputElement.lastPromiseValue = value;
    return next.value.response;
  });
}

/**
 * Generator function which is called between each async step of the upload
 * process.
 * @param {string} inputId Element ID of the input file picker element.
 * @param {string} outputId Element ID of the output display.
 * @return {!Iterable<!Object>} Iterable of next steps.
 */
function* uploadFilesStep(inputId, outputId) {
  const inputElement = document.getElementById(inputId);
  inputElement.disabled = false;

  const outputElement = document.getElementById(outputId);
  outputElement.innerHTML = '';

  const pickedPromise = new Promise((resolve) => {
    inputElement.addEventListener('change', (e) => {
      resolve(e.target.files);
    });
  });

  const cancel = document.createElement('button');
  inputElement.parentElement.appendChild(cancel);
  cancel.textContent = 'Cancel upload';
  const cancelPromise = new Promise((resolve) => {
    cancel.onclick = () => {
      resolve(null);
    };
  });

  // Wait for the user to pick the files.
  const files = yield {
    promise: Promise.race([pickedPromise, cancelPromise]),
    response: {
      action: 'starting',
    }
  };

  cancel.remove();

  // Disable the input element since further picks are not allowed.
  inputElement.disabled = true;

  if (!files) {
    return {
      response: {
        action: 'complete',
      }
    };
  }

  for (const file of files) {
    const li = document.createElement('li');
    li.append(span(file.name, {fontWeight: 'bold'}));
    li.append(span(
        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +
        `last modified: ${
            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :
                                    'n/a'} - `));
    const percent = span('0% done');
    li.appendChild(percent);

    outputElement.appendChild(li);

    const fileDataPromise = new Promise((resolve) => {
      const reader = new FileReader();
      reader.onload = (e) => {
        resolve(e.target.result);
      };
      reader.readAsArrayBuffer(file);
    });
    // Wait for the data to be ready.
    let fileData = yield {
      promise: fileDataPromise,
      response: {
        action: 'continue',
      }
    };

    // Use a chunked sending to avoid message size limits. See b/62115660.
    let position = 0;
    do {
      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);
      const chunk = new Uint8Array(fileData, position, length);
      position += length;

      const base64 = btoa(String.fromCharCode.apply(null, chunk));
      yield {
        response: {
          action: 'append',
          file: file.name,
          data: base64,
        },
      };

      let percentDone = fileData.byteLength === 0 ?
          100 :
          Math.round((position / fileData.byteLength) * 100);
      percent.textContent = `${percentDone}% done`;

    } while (position < fileData.byteLength);
  }

  // All done.
  yield {
    response: {
      action: 'complete',
    }
  };
}

scope.google = scope.google || {};
scope.google.colab = scope.google.colab || {};
scope.google.colab._files = {
  _uploadFiles,
  _uploadFilesContinue,
};
})(self);
</script> 
</div>
<div class="output stream stdout">
<pre><code>Saving all_extended_models.xlsx to all_extended_models (2).xlsx
Saving all_model1.xlsx to all_model1 (3).xlsx
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_e37543f3817e498792271d4afeefc0f0/5ad7bfa251c0841796b2370bf5d0cbca12a06d1e.png" /></p>
</div>
</div>
<section id="54-all-models-per-class-recall" class="cell markdown"
id="EOprVS5CAR3s">
<h2>5.4 All Models (Per Class Recall)</h2>
<p>The per-class recall heatmap explains the macro-F1 ordering by
locating where each model derives (or loses) performance. Design
Science/System Design and Theoretical/Conceptual are consistently high
across families, indicating abundant, separable signal. The
differentiation appears in Mixed Methods and, most notably, Qualitative.
Reweighting improves Mixed Methods in models such as RoBERTa-D2, but
Qualitative remains difficult: most backbones fail to register it at
all, whereas SciBERT is the only family that reproducibly yields
non-zero recall on this split.</p>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:926}"
id="GCUWNBnXqyfR" data-outputId="a8073ff5-000b-4acf-e9a7-e9132307ddd1">
<div class="sourceCode" id="cb126"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a>rename_map <span class="op">=</span> {</span>
<span id="cb126-2"><a href="#cb126-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;recall_Design_Science_-_System_Design&quot;</span>: <span class="st">&quot;Recall_DS/SD&quot;</span>,</span>
<span id="cb126-3"><a href="#cb126-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;recall_Mixed_Methods&quot;</span>: <span class="st">&quot;Recall_MM&quot;</span>,</span>
<span id="cb126-4"><a href="#cb126-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;recall_Qualitative&quot;</span>: <span class="st">&quot;Recall_Qual&quot;</span>,</span>
<span id="cb126-5"><a href="#cb126-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;recall_Theoretical_-_Conceptual&quot;</span>: <span class="st">&quot;Recall_TC&quot;</span>,</span>
<span id="cb126-6"><a href="#cb126-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb126-7"><a href="#cb126-7" aria-hidden="true" tabindex="-1"></a>heat_df <span class="op">=</span> full_df.rename(columns<span class="op">=</span>rename_map)</span>
<span id="cb126-8"><a href="#cb126-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb126-9"><a href="#cb126-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Build matrix</span></span>
<span id="cb126-10"><a href="#cb126-10" aria-hidden="true" tabindex="-1"></a>recall_cols <span class="op">=</span> [<span class="st">&quot;Recall_DS/SD&quot;</span>, <span class="st">&quot;Recall_MM&quot;</span>, <span class="st">&quot;Recall_Qual&quot;</span>, <span class="st">&quot;Recall_TC&quot;</span>]</span>
<span id="cb126-11"><a href="#cb126-11" aria-hidden="true" tabindex="-1"></a>missing <span class="op">=</span> [c <span class="cf">for</span> c <span class="kw">in</span> recall_cols <span class="cf">if</span> c <span class="kw">not</span> <span class="kw">in</span> heat_df.columns]</span>
<span id="cb126-12"><a href="#cb126-12" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> missing:</span>
<span id="cb126-13"><a href="#cb126-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f&quot;Missing recall columns: </span><span class="sc">{</span>missing<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb126-14"><a href="#cb126-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb126-15"><a href="#cb126-15" aria-hidden="true" tabindex="-1"></a><span class="co"># align row order with Macro-F1 chart</span></span>
<span id="cb126-16"><a href="#cb126-16" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">&#39;plot_df&#39;</span> <span class="kw">in</span> <span class="bu">globals</span>():</span>
<span id="cb126-17"><a href="#cb126-17" aria-hidden="true" tabindex="-1"></a>    heat_df <span class="op">=</span> heat_df.set_index(<span class="st">&quot;run&quot;</span>).loc[plot_df[<span class="st">&quot;run&quot;</span>]].reset_index()</span>
<span id="cb126-18"><a href="#cb126-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb126-19"><a href="#cb126-19" aria-hidden="true" tabindex="-1"></a>mat <span class="op">=</span> heat_df[recall_cols].astype(<span class="bu">float</span>).to_numpy()</span>
<span id="cb126-20"><a href="#cb126-20" aria-hidden="true" tabindex="-1"></a>row_labels <span class="op">=</span> heat_df[<span class="st">&quot;run&quot;</span>].astype(<span class="bu">str</span>).tolist()</span>
<span id="cb126-21"><a href="#cb126-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb126-22"><a href="#cb126-22" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="fl">6.4</span>, <span class="fl">0.6</span> <span class="op">*</span> <span class="bu">len</span>(row_labels) <span class="op">+</span> <span class="dv">2</span>))</span>
<span id="cb126-23"><a href="#cb126-23" aria-hidden="true" tabindex="-1"></a>plt.imshow(mat, aspect<span class="op">=</span><span class="st">&quot;auto&quot;</span>, vmin<span class="op">=</span><span class="dv">0</span>, vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb126-24"><a href="#cb126-24" aria-hidden="true" tabindex="-1"></a>plt.xticks(<span class="bu">range</span>(<span class="bu">len</span>(recall_cols)), recall_cols, rotation<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb126-25"><a href="#cb126-25" aria-hidden="true" tabindex="-1"></a>plt.yticks(<span class="bu">range</span>(<span class="bu">len</span>(row_labels)), row_labels)</span>
<span id="cb126-26"><a href="#cb126-26" aria-hidden="true" tabindex="-1"></a>plt.colorbar(label<span class="op">=</span><span class="st">&quot;Recall&quot;</span>)</span>
<span id="cb126-27"><a href="#cb126-27" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Per-class Recall — All Models&quot;</span>)</span>
<span id="cb126-28"><a href="#cb126-28" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()<span class="op">;</span> plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_e37543f3817e498792271d4afeefc0f0/515aeee22a81cb74058eb27ea9d58df9f4e14dcc.png" /></p>
</div>
</div>
<section id="6-multi-label-classification-scibert" class="cell markdown"
id="TxQlK2QkBSPk">
<h1>6. Multi Label Classification (SciBERT)</h1>
<p>I extend the task from single-label (one target per sample) to
multi-label: each abstract can carry a discipline, a subfield, and a
methodology simultaneously. I keep the backbone and data recipe from
SciBERT Model 1 to isolate the effect of changing the prediction
objective: the model now emits one logit per label and decisions are
made independently per label (sigmoid + threshold).</p>
<p>Macro-F1 is the decision metric. On the validation split, macro-F1
lands in the low-to-mid-0.4s across families (methodology at about 0.43;
subfield lower; discipline similar), reflecting that minority labels
remain hard when each label is predicted independently. On the
validation split the element-wise accuracy is about 0.89. Slicing the
reports by family shows a familiar pattern: discipline and subfield are
learned reliably (several labels in the 0.6–0.8 recall range), while
methodology remains the hardest DS/SD high, TC moderate, MM low, and
Qualitative near zero on this split. That continuity with the
single-label experiments matters: moving to multi-label preserves
strengths but does not magically fix the weakest class, so any further
gains will need targeted rebalancing or data.</p>
</section>
<section id="configuration" class="cell markdown" id="bfdo3Du5arn7">
<h3>Configuration</h3>
</section>
<div class="cell code" id="mtx0iMLw43v7">
<div class="sourceCode" id="cb127"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a><span class="co">#  Config and Seed</span></span>
<span id="cb127-2"><a href="#cb127-2" aria-hidden="true" tabindex="-1"></a><span class="at">@dataclass</span></span>
<span id="cb127-3"><a href="#cb127-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> RunConfig:</span>
<span id="cb127-4"><a href="#cb127-4" aria-hidden="true" tabindex="-1"></a>    model_name: <span class="bu">str</span> <span class="op">=</span> <span class="st">&quot;allenai/scibert_scivocab_uncased&quot;</span></span>
<span id="cb127-5"><a href="#cb127-5" aria-hidden="true" tabindex="-1"></a>    max_len: <span class="bu">int</span> <span class="op">=</span> <span class="dv">512</span></span>
<span id="cb127-6"><a href="#cb127-6" aria-hidden="true" tabindex="-1"></a>    batch_size: <span class="bu">int</span> <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb127-7"><a href="#cb127-7" aria-hidden="true" tabindex="-1"></a>    lr: <span class="bu">float</span> <span class="op">=</span> <span class="fl">2e-5</span></span>
<span id="cb127-8"><a href="#cb127-8" aria-hidden="true" tabindex="-1"></a>    weight_decay: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb127-9"><a href="#cb127-9" aria-hidden="true" tabindex="-1"></a>    epochs: <span class="bu">int</span> <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb127-10"><a href="#cb127-10" aria-hidden="true" tabindex="-1"></a>    patience: <span class="bu">int</span> <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb127-11"><a href="#cb127-11" aria-hidden="true" tabindex="-1"></a>    device: <span class="bu">str</span> <span class="op">=</span> <span class="st">&quot;cuda&quot;</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">&quot;cpu&quot;</span></span>
<span id="cb127-12"><a href="#cb127-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb127-13"><a href="#cb127-13" aria-hidden="true" tabindex="-1"></a>cfg <span class="op">=</span> RunConfig()</span>
<span id="cb127-14"><a href="#cb127-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb127-15"><a href="#cb127-15" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> set_seed(seed<span class="op">=</span><span class="dv">42</span>):</span>
<span id="cb127-16"><a href="#cb127-16" aria-hidden="true" tabindex="-1"></a>    random.seed(seed)</span>
<span id="cb127-17"><a href="#cb127-17" aria-hidden="true" tabindex="-1"></a>    np.random.seed(seed)</span>
<span id="cb127-18"><a href="#cb127-18" aria-hidden="true" tabindex="-1"></a>    torch.manual_seed(seed)</span>
<span id="cb127-19"><a href="#cb127-19" aria-hidden="true" tabindex="-1"></a>    torch.cuda.manual_seed_all(seed)</span>
<span id="cb127-20"><a href="#cb127-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb127-21"><a href="#cb127-21" aria-hidden="true" tabindex="-1"></a>set_seed(<span class="dv">42</span>)</span></code></pre></div>
</div>
<section id="tokenisation" class="cell markdown" id="oUMYSO-RbEuA">
<h3>Tokenisation</h3>
<p>The task is made multi-label by building a multi-hot target over
{discipline, subfield, methodology} using MultiLabelBinarizer; I persist
the encoder to mlb.pkl and the class list to classes.npy for later
decoding. Texts come from processed_with_stopwords and are tokenized by
the SciBERT tokenizer at max_len=512. I use an 80/20 split with seed=42
and wrap encodings plus targets into a small Dataset, producing
train/val DataLoaders (training shuffled).</p>
</section>
<div class="cell code" id="Pzwdoxi27cGM">
<div class="sourceCode" id="cb128"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> label_list(row):</span>
<span id="cb128-2"><a href="#cb128-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [row[<span class="st">&#39;discipline&#39;</span>], row[<span class="st">&#39;subfield&#39;</span>], row[<span class="st">&#39;methodology&#39;</span>]]</span>
<span id="cb128-3"><a href="#cb128-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-4"><a href="#cb128-4" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&#39;labels&#39;</span>] <span class="op">=</span> df.<span class="bu">apply</span>(label_list, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb128-5"><a href="#cb128-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-6"><a href="#cb128-6" aria-hidden="true" tabindex="-1"></a>mlb <span class="op">=</span> MultiLabelBinarizer()</span>
<span id="cb128-7"><a href="#cb128-7" aria-hidden="true" tabindex="-1"></a>all_labels <span class="op">=</span> mlb.fit_transform(df[<span class="st">&#39;labels&#39;</span>])</span>
<span id="cb128-8"><a href="#cb128-8" aria-hidden="true" tabindex="-1"></a>classes <span class="op">=</span> np.array(mlb.classes_)</span>
<span id="cb128-9"><a href="#cb128-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-10"><a href="#cb128-10" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">&quot;mlb.pkl&quot;</span>, <span class="st">&quot;wb&quot;</span>) <span class="im">as</span> f:</span>
<span id="cb128-11"><a href="#cb128-11" aria-hidden="true" tabindex="-1"></a>    pickle.dump(mlb, f)</span>
<span id="cb128-12"><a href="#cb128-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-13"><a href="#cb128-13" aria-hidden="true" tabindex="-1"></a>np.save(<span class="st">&quot;classes.npy&quot;</span>, classes)</span>
<span id="cb128-14"><a href="#cb128-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-15"><a href="#cb128-15" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(cfg.model_name)</span>
<span id="cb128-16"><a href="#cb128-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-17"><a href="#cb128-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tokenize_function(texts):</span>
<span id="cb128-18"><a href="#cb128-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tokenizer(texts, padding<span class="op">=</span><span class="st">&quot;max_length&quot;</span>, truncation<span class="op">=</span><span class="va">True</span>, max_length<span class="op">=</span>cfg.max_len)</span>
<span id="cb128-19"><a href="#cb128-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-20"><a href="#cb128-20" aria-hidden="true" tabindex="-1"></a>tokens <span class="op">=</span> tokenize_function(df[<span class="st">&#39;processed_with_stopwords&#39;</span>].tolist())</span>
<span id="cb128-21"><a href="#cb128-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-22"><a href="#cb128-22" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MultiLabelDataset(torch.utils.data.Dataset):</span>
<span id="cb128-23"><a href="#cb128-23" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, encodings, labels):</span>
<span id="cb128-24"><a href="#cb128-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.encodings <span class="op">=</span> encodings</span>
<span id="cb128-25"><a href="#cb128-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.labels <span class="op">=</span> labels</span>
<span id="cb128-26"><a href="#cb128-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-27"><a href="#cb128-27" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx):</span>
<span id="cb128-28"><a href="#cb128-28" aria-hidden="true" tabindex="-1"></a>        item <span class="op">=</span> {key: torch.tensor(val[idx]) <span class="cf">for</span> key, val <span class="kw">in</span> <span class="va">self</span>.encodings.items()}</span>
<span id="cb128-29"><a href="#cb128-29" aria-hidden="true" tabindex="-1"></a>        item[<span class="st">&#39;labels&#39;</span>] <span class="op">=</span> torch.tensor(<span class="va">self</span>.labels[idx]).<span class="bu">float</span>()</span>
<span id="cb128-30"><a href="#cb128-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> item</span>
<span id="cb128-31"><a href="#cb128-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-32"><a href="#cb128-32" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb128-33"><a href="#cb128-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.labels)</span>
<span id="cb128-34"><a href="#cb128-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-35"><a href="#cb128-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Train/val split</span></span>
<span id="cb128-36"><a href="#cb128-36" aria-hidden="true" tabindex="-1"></a>train_texts, val_texts, train_labels, val_labels <span class="op">=</span> train_test_split(</span>
<span id="cb128-37"><a href="#cb128-37" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">&#39;processed_with_stopwords&#39;</span>].tolist(),</span>
<span id="cb128-38"><a href="#cb128-38" aria-hidden="true" tabindex="-1"></a>    all_labels, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb128-39"><a href="#cb128-39" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb128-40"><a href="#cb128-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-41"><a href="#cb128-41" aria-hidden="true" tabindex="-1"></a>train_encodings <span class="op">=</span> tokenize_function(train_texts)</span>
<span id="cb128-42"><a href="#cb128-42" aria-hidden="true" tabindex="-1"></a>val_encodings <span class="op">=</span> tokenize_function(val_texts)</span>
<span id="cb128-43"><a href="#cb128-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-44"><a href="#cb128-44" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> MultiLabelDataset(train_encodings, train_labels)</span>
<span id="cb128-45"><a href="#cb128-45" aria-hidden="true" tabindex="-1"></a>val_dataset <span class="op">=</span> MultiLabelDataset(val_encodings, val_labels)</span>
<span id="cb128-46"><a href="#cb128-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-47"><a href="#cb128-47" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(train_dataset, batch_size<span class="op">=</span>cfg.batch_size, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb128-48"><a href="#cb128-48" aria-hidden="true" tabindex="-1"></a>val_loader <span class="op">=</span> DataLoader(val_dataset, batch_size<span class="op">=</span>cfg.batch_size, shuffle<span class="op">=</span><span class="va">False</span>)</span></code></pre></div>
</div>
<section id="runner" class="cell markdown" id="WM4MWPWQbFT4">
<h3>Runner</h3>
<p>MultiLabelSciBERT feeds the sequence through SciBERT, takes the CLS
vector, applies dropout, and projects to one logit per label.
Optimisation uses BCEWithLogitsLoss (independent binary decisions),
AdamW(2e-5), a short LinearLR warm-up (of about 10% of steps), and
gradient clipping at 1.0; early stopping monitors validation loss. At
inference I apply a 0.5 sigmoid threshold per label. I report
element-wise accuracy across the label matrix and classification_reports
grouped by family (Discipline, Subfield, Methodology).</p>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="MR_FDBWK7dSI" data-outputId="4fbaf249-2edb-4ad2-fa88-70cfbb1ade1c">
<div class="sourceCode" id="cb129"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MultiLabelSciBERT(nn.Module):</span>
<span id="cb129-2"><a href="#cb129-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_labels):</span>
<span id="cb129-3"><a href="#cb129-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb129-4"><a href="#cb129-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bert <span class="op">=</span> AutoModel.from_pretrained(cfg.model_name)</span>
<span id="cb129-5"><a href="#cb129-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout <span class="op">=</span> nn.Dropout(<span class="fl">0.3</span>)</span>
<span id="cb129-6"><a href="#cb129-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.classifier <span class="op">=</span> nn.Linear(<span class="va">self</span>.bert.config.hidden_size, num_labels)</span>
<span id="cb129-7"><a href="#cb129-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-8"><a href="#cb129-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, input_ids, attention_mask):</span>
<span id="cb129-9"><a href="#cb129-9" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> <span class="va">self</span>.bert(input_ids<span class="op">=</span>input_ids, attention_mask<span class="op">=</span>attention_mask)</span>
<span id="cb129-10"><a href="#cb129-10" aria-hidden="true" tabindex="-1"></a>        pooled_output <span class="op">=</span> outputs.last_hidden_state[:, <span class="dv">0</span>]  <span class="co"># CLS token</span></span>
<span id="cb129-11"><a href="#cb129-11" aria-hidden="true" tabindex="-1"></a>        pooled_output <span class="op">=</span> <span class="va">self</span>.dropout(pooled_output)</span>
<span id="cb129-12"><a href="#cb129-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.classifier(pooled_output)</span>
<span id="cb129-13"><a href="#cb129-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-14"><a href="#cb129-14" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> MultiLabelSciBERT(num_labels<span class="op">=</span>all_labels.shape[<span class="dv">1</span>]).to(cfg.device)</span>
<span id="cb129-15"><a href="#cb129-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-16"><a href="#cb129-16" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.AdamW(model.parameters(), lr<span class="op">=</span>cfg.lr, weight_decay<span class="op">=</span>cfg.weight_decay)</span>
<span id="cb129-17"><a href="#cb129-17" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> nn.BCEWithLogitsLoss()</span>
<span id="cb129-18"><a href="#cb129-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-19"><a href="#cb129-19" aria-hidden="true" tabindex="-1"></a>total_steps <span class="op">=</span> <span class="bu">len</span>(train_loader) <span class="op">*</span> cfg.epochs</span>
<span id="cb129-20"><a href="#cb129-20" aria-hidden="true" tabindex="-1"></a>scheduler <span class="op">=</span> torch.optim.lr_scheduler.LinearLR(optimizer, start_factor<span class="op">=</span><span class="fl">0.1</span>, total_iters<span class="op">=</span><span class="bu">int</span>(<span class="fl">0.1</span> <span class="op">*</span> total_steps))  <span class="co"># warmup 10%</span></span>
<span id="cb129-21"><a href="#cb129-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-22"><a href="#cb129-22" aria-hidden="true" tabindex="-1"></a>best_val_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">&quot;inf&quot;</span>)</span>
<span id="cb129-23"><a href="#cb129-23" aria-hidden="true" tabindex="-1"></a>patience_counter <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb129-24"><a href="#cb129-24" aria-hidden="true" tabindex="-1"></a>best_state_dict <span class="op">=</span> <span class="va">None</span></span>
<span id="cb129-25"><a href="#cb129-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-26"><a href="#cb129-26" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, cfg.epochs <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb129-27"><a href="#cb129-27" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb129-28"><a href="#cb129-28" aria-hidden="true" tabindex="-1"></a>    total_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb129-29"><a href="#cb129-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-30"><a href="#cb129-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch <span class="kw">in</span> train_loader:</span>
<span id="cb129-31"><a href="#cb129-31" aria-hidden="true" tabindex="-1"></a>        input_ids <span class="op">=</span> batch[<span class="st">&#39;input_ids&#39;</span>].to(cfg.device)</span>
<span id="cb129-32"><a href="#cb129-32" aria-hidden="true" tabindex="-1"></a>        attention_mask <span class="op">=</span> batch[<span class="st">&#39;attention_mask&#39;</span>].to(cfg.device)</span>
<span id="cb129-33"><a href="#cb129-33" aria-hidden="true" tabindex="-1"></a>        labels <span class="op">=</span> batch[<span class="st">&#39;labels&#39;</span>].to(cfg.device)</span>
<span id="cb129-34"><a href="#cb129-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-35"><a href="#cb129-35" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> model(input_ids, attention_mask)</span>
<span id="cb129-36"><a href="#cb129-36" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> criterion(outputs, labels)</span>
<span id="cb129-37"><a href="#cb129-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-38"><a href="#cb129-38" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb129-39"><a href="#cb129-39" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb129-40"><a href="#cb129-40" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb129-41"><a href="#cb129-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> scheduler: scheduler.step()</span>
<span id="cb129-42"><a href="#cb129-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-43"><a href="#cb129-43" aria-hidden="true" tabindex="-1"></a>        total_loss <span class="op">+=</span> loss.item()</span>
<span id="cb129-44"><a href="#cb129-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-45"><a href="#cb129-45" aria-hidden="true" tabindex="-1"></a>    avg_train_loss <span class="op">=</span> total_loss <span class="op">/</span> <span class="bu">len</span>(train_loader)</span>
<span id="cb129-46"><a href="#cb129-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-47"><a href="#cb129-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Validation</span></span>
<span id="cb129-48"><a href="#cb129-48" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb129-49"><a href="#cb129-49" aria-hidden="true" tabindex="-1"></a>    val_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb129-50"><a href="#cb129-50" aria-hidden="true" tabindex="-1"></a>    all_preds, all_targets <span class="op">=</span> [], []</span>
<span id="cb129-51"><a href="#cb129-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-52"><a href="#cb129-52" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb129-53"><a href="#cb129-53" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> batch <span class="kw">in</span> val_loader:</span>
<span id="cb129-54"><a href="#cb129-54" aria-hidden="true" tabindex="-1"></a>            input_ids <span class="op">=</span> batch[<span class="st">&#39;input_ids&#39;</span>].to(cfg.device)</span>
<span id="cb129-55"><a href="#cb129-55" aria-hidden="true" tabindex="-1"></a>            attention_mask <span class="op">=</span> batch[<span class="st">&#39;attention_mask&#39;</span>].to(cfg.device)</span>
<span id="cb129-56"><a href="#cb129-56" aria-hidden="true" tabindex="-1"></a>            labels <span class="op">=</span> batch[<span class="st">&#39;labels&#39;</span>].to(cfg.device)</span>
<span id="cb129-57"><a href="#cb129-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-58"><a href="#cb129-58" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> model(input_ids, attention_mask)</span>
<span id="cb129-59"><a href="#cb129-59" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> criterion(outputs, labels)</span>
<span id="cb129-60"><a href="#cb129-60" aria-hidden="true" tabindex="-1"></a>            val_loss <span class="op">+=</span> loss.item()</span>
<span id="cb129-61"><a href="#cb129-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-62"><a href="#cb129-62" aria-hidden="true" tabindex="-1"></a>            preds <span class="op">=</span> torch.sigmoid(outputs).cpu().numpy() <span class="op">&gt;</span> <span class="fl">0.5</span></span>
<span id="cb129-63"><a href="#cb129-63" aria-hidden="true" tabindex="-1"></a>            targets <span class="op">=</span> labels.cpu().numpy()</span>
<span id="cb129-64"><a href="#cb129-64" aria-hidden="true" tabindex="-1"></a>            all_preds.append(preds)</span>
<span id="cb129-65"><a href="#cb129-65" aria-hidden="true" tabindex="-1"></a>            all_targets.append(targets)</span>
<span id="cb129-66"><a href="#cb129-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-67"><a href="#cb129-67" aria-hidden="true" tabindex="-1"></a>    avg_val_loss <span class="op">=</span> val_loss <span class="op">/</span> <span class="bu">len</span>(val_loader)</span>
<span id="cb129-68"><a href="#cb129-68" aria-hidden="true" tabindex="-1"></a>    all_preds <span class="op">=</span> np.vstack(all_preds)</span>
<span id="cb129-69"><a href="#cb129-69" aria-hidden="true" tabindex="-1"></a>    all_targets <span class="op">=</span> np.vstack(all_targets)</span>
<span id="cb129-70"><a href="#cb129-70" aria-hidden="true" tabindex="-1"></a>    val_acc <span class="op">=</span> (all_preds <span class="op">==</span> all_targets).mean()</span>
<span id="cb129-71"><a href="#cb129-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-72"><a href="#cb129-72" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Epoch </span><span class="sc">{</span>epoch<span class="sc">:02d}</span><span class="ss"> | train_loss: </span><span class="sc">{</span>avg_train_loss<span class="sc">:.4f}</span><span class="ss"> | val_loss: </span><span class="sc">{</span>avg_val_loss<span class="sc">:.4f}</span><span class="ss"> | val_acc: </span><span class="sc">{</span>val_acc<span class="sc">:.4f}</span><span class="ss"> | patience </span><span class="sc">{</span>patience_counter<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>cfg<span class="sc">.</span>patience<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb129-73"><a href="#cb129-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-74"><a href="#cb129-74" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> avg_val_loss <span class="op">&lt;</span> best_val_loss:</span>
<span id="cb129-75"><a href="#cb129-75" aria-hidden="true" tabindex="-1"></a>        best_val_loss <span class="op">=</span> avg_val_loss</span>
<span id="cb129-76"><a href="#cb129-76" aria-hidden="true" tabindex="-1"></a>        best_state_dict <span class="op">=</span> model.state_dict()</span>
<span id="cb129-77"><a href="#cb129-77" aria-hidden="true" tabindex="-1"></a>        patience_counter <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb129-78"><a href="#cb129-78" aria-hidden="true" tabindex="-1"></a>        torch.save(best_state_dict, <span class="st">&quot;multi_label_scibert.pt&quot;</span>)</span>
<span id="cb129-79"><a href="#cb129-79" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb129-80"><a href="#cb129-80" aria-hidden="true" tabindex="-1"></a>        patience_counter <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb129-81"><a href="#cb129-81" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> patience_counter <span class="op">&gt;=</span> cfg.patience:</span>
<span id="cb129-82"><a href="#cb129-82" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">&quot;Early stopping triggered.&quot;</span>)</span>
<span id="cb129-83"><a href="#cb129-83" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb129-84"><a href="#cb129-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-85"><a href="#cb129-85" aria-hidden="true" tabindex="-1"></a>model.load_state_dict(best_state_dict)</span>
<span id="cb129-86"><a href="#cb129-86" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb129-87"><a href="#cb129-87" aria-hidden="true" tabindex="-1"></a>final_preds, final_targets <span class="op">=</span> [], []</span>
<span id="cb129-88"><a href="#cb129-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-89"><a href="#cb129-89" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb129-90"><a href="#cb129-90" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch <span class="kw">in</span> val_loader:</span>
<span id="cb129-91"><a href="#cb129-91" aria-hidden="true" tabindex="-1"></a>        input_ids <span class="op">=</span> batch[<span class="st">&#39;input_ids&#39;</span>].to(cfg.device)</span>
<span id="cb129-92"><a href="#cb129-92" aria-hidden="true" tabindex="-1"></a>        attention_mask <span class="op">=</span> batch[<span class="st">&#39;attention_mask&#39;</span>].to(cfg.device)</span>
<span id="cb129-93"><a href="#cb129-93" aria-hidden="true" tabindex="-1"></a>        labels <span class="op">=</span> batch[<span class="st">&#39;labels&#39;</span>].to(cfg.device)</span>
<span id="cb129-94"><a href="#cb129-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-95"><a href="#cb129-95" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> model(input_ids, attention_mask)</span>
<span id="cb129-96"><a href="#cb129-96" aria-hidden="true" tabindex="-1"></a>        preds <span class="op">=</span> torch.sigmoid(outputs).cpu().numpy() <span class="op">&gt;</span> <span class="fl">0.5</span></span>
<span id="cb129-97"><a href="#cb129-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-98"><a href="#cb129-98" aria-hidden="true" tabindex="-1"></a>        final_preds.append(preds)</span>
<span id="cb129-99"><a href="#cb129-99" aria-hidden="true" tabindex="-1"></a>        final_targets.append(labels.cpu().numpy())</span>
<span id="cb129-100"><a href="#cb129-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-101"><a href="#cb129-101" aria-hidden="true" tabindex="-1"></a>final_preds <span class="op">=</span> np.vstack(final_preds)</span>
<span id="cb129-102"><a href="#cb129-102" aria-hidden="true" tabindex="-1"></a>final_targets <span class="op">=</span> np.vstack(final_targets)</span>
<span id="cb129-103"><a href="#cb129-103" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Validation accuracy:&quot;</span>, (final_preds <span class="op">==</span> final_targets).mean())</span>
<span id="cb129-104"><a href="#cb129-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-105"><a href="#cb129-105" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> group_report(label, group_list):</span>
<span id="cb129-106"><a href="#cb129-106" aria-hidden="true" tabindex="-1"></a>    indices <span class="op">=</span> [i <span class="cf">for</span> i, c <span class="kw">in</span> <span class="bu">enumerate</span>(classes) <span class="cf">if</span> c <span class="kw">in</span> group_list]</span>
<span id="cb129-107"><a href="#cb129-107" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> indices:</span>
<span id="cb129-108"><a href="#cb129-108" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;</span><span class="ch">\n</span><span class="ss">Classification Report — </span><span class="sc">{</span>label<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb129-109"><a href="#cb129-109" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(classification_report(</span>
<span id="cb129-110"><a href="#cb129-110" aria-hidden="true" tabindex="-1"></a>            final_targets[:, indices], final_preds[:, indices], target_names<span class="op">=</span>classes[indices], zero_division<span class="op">=</span><span class="dv">0</span></span>
<span id="cb129-111"><a href="#cb129-111" aria-hidden="true" tabindex="-1"></a>        ))</span>
<span id="cb129-112"><a href="#cb129-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-113"><a href="#cb129-113" aria-hidden="true" tabindex="-1"></a>group_report(<span class="st">&quot;Discipline&quot;</span>, df[<span class="st">&#39;discipline&#39;</span>].unique().tolist())</span>
<span id="cb129-114"><a href="#cb129-114" aria-hidden="true" tabindex="-1"></a>group_report(<span class="st">&quot;Subfield&quot;</span>, df[<span class="st">&#39;subfield&#39;</span>].unique().tolist())</span>
<span id="cb129-115"><a href="#cb129-115" aria-hidden="true" tabindex="-1"></a>group_report(<span class="st">&quot;Methodology&quot;</span>, df[<span class="st">&#39;methodology&#39;</span>].unique().tolist())</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch 01 | train_loss: 0.3189 | val_loss: 0.2670 | val_acc: 0.8905 | patience 0/2
Epoch 02 | train_loss: 0.2610 | val_loss: 0.2511 | val_acc: 0.8933 | patience 0/2
Epoch 03 | train_loss: 0.2332 | val_loss: 0.2481 | val_acc: 0.8965 | patience 0/2
Epoch 04 | train_loss: 0.2054 | val_loss: 0.2599 | val_acc: 0.8940 | patience 0/2
Epoch 05 | train_loss: 0.1720 | val_loss: 0.2778 | val_acc: 0.8927 | patience 1/2
Early stopping triggered.

Validation accuracy: 0.8927036705461057

Classification Report — Discipline
                                            precision    recall  f1-score   support

                              Astrophysics       0.71      0.80      0.76        46
                          Computer Science       0.50      0.22      0.30       268
                                 Economics       0.64      0.90      0.75       245
Electrical Engineering and Systems Science       0.33      0.07      0.11        29
                               Mathematics       0.49      0.34      0.40       202
                                   Physics       0.30      0.06      0.10       122
                      Quantitative Biology       0.58      0.39      0.46        93
                                Statistics       0.39      0.40      0.39       112

                                 micro avg       0.55      0.42      0.48      1117
                                 macro avg       0.49      0.40      0.41      1117
                              weighted avg       0.51      0.42      0.43      1117
                               samples avg       0.42      0.42      0.42      1117


Classification Report — Subfield
                                  precision    recall  f1-score   support

              Algebraic Geometry       0.57      0.60      0.58       206
Computer Science and Game Theory       0.00      0.00      0.00        57
             Galaxy Astrophysics       0.73      0.77      0.75        43
               General Economics       0.66      0.80      0.73       322
      Image and Video Processing       0.33      0.05      0.09        19
                Machine Learning       0.52      0.42      0.46       289
   Neural and Cognitive Modeling       0.40      0.22      0.28        93
                 Quantum Physics       0.20      0.01      0.02        88

                       micro avg       0.59      0.50      0.54      1117
                       macro avg       0.43      0.36      0.36      1117
                    weighted avg       0.51      0.50      0.49      1117
                     samples avg       0.50      0.50      0.50      1117


Classification Report — Methodology
                                precision    recall  f1-score   support

Design Science / System Design       0.84      0.93      0.88       717
                 Mixed Methods       1.00      0.06      0.11        83
                   Qualitative       0.00      0.00      0.00         8
      Theoretical / Conceptual       0.76      0.68      0.72       309

                     micro avg       0.82      0.79      0.81      1117
                     macro avg       0.65      0.42      0.43      1117
                  weighted avg       0.82      0.79      0.78      1117
                   samples avg       0.79      0.79      0.79      1117

</code></pre>
</div>
</div>
<section id="7-complete-working-classification-pipeline"
class="cell markdown" id="9OyVLY_VqA9v">
<h1>7. Complete Working Classification Pipeline</h1>
</section>
<section id="loading-assets" class="cell markdown" id="et5RB4-Hot31">
<h3>Loading Assets</h3>
<p>This cell ingests the three artifacts produced during training,
mlb.pkl (the fitted MultiLabelBinarizer), classes.npy (the frozen label
order), and multi_label_scibert.pt (the fine-tuned weights). Writing the
raw bytes to disk and normalising names guarantees the inference code
sees exactly the filenames it expects. Keeping the class order identical
to training is critical: it ensures each logit maps to the same semantic
label at inference as it did during training, so per-family selection
and confidence reporting remain correct.</p>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:178}"
id="931rUVqBvGvj" data-outputId="1b56db37-055e-412b-d8e9-cc3b96df3dcb">
<div class="sourceCode" id="cb131"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Upload and standardise filenames</span></span>
<span id="cb131-2"><a href="#cb131-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> google.colab <span class="im">import</span> files</span>
<span id="cb131-3"><a href="#cb131-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-4"><a href="#cb131-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-5"><a href="#cb131-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Upload files</span></span>
<span id="cb131-6"><a href="#cb131-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Please select: mlb.pkl, classes.npy, multi_label_scibert.pt&quot;</span>)</span>
<span id="cb131-7"><a href="#cb131-7" aria-hidden="true" tabindex="-1"></a>up <span class="op">=</span> files.upload()</span>
<span id="cb131-8"><a href="#cb131-8" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> up:</span>
<span id="cb131-9"><a href="#cb131-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">RuntimeError</span>(<span class="st">&quot;No files uploaded.&quot;</span>)</span>
<span id="cb131-10"><a href="#cb131-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-11"><a href="#cb131-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Save uploaded bytes</span></span>
<span id="cb131-12"><a href="#cb131-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, data <span class="kw">in</span> up.items():</span>
<span id="cb131-13"><a href="#cb131-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> <span class="bu">open</span>(name, <span class="st">&quot;wb&quot;</span>) <span class="im">as</span> f:</span>
<span id="cb131-14"><a href="#cb131-14" aria-hidden="true" tabindex="-1"></a>        f.write(data)</span>
<span id="cb131-15"><a href="#cb131-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-16"><a href="#cb131-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ensure_file(target_name, exts):</span>
<span id="cb131-17"><a href="#cb131-17" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;If target_name not present, rename first uploaded file matching extensions.&quot;&quot;&quot;</span></span>
<span id="cb131-18"><a href="#cb131-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> os.path.exists(target_name):</span>
<span id="cb131-19"><a href="#cb131-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> target_name</span>
<span id="cb131-20"><a href="#cb131-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> fname <span class="kw">in</span> up.keys():</span>
<span id="cb131-21"><a href="#cb131-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">any</span>(fname.lower().endswith(ext) <span class="cf">for</span> ext <span class="kw">in</span> exts):</span>
<span id="cb131-22"><a href="#cb131-22" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> fname <span class="op">!=</span> target_name:</span>
<span id="cb131-23"><a href="#cb131-23" aria-hidden="true" tabindex="-1"></a>                os.rename(fname, target_name)</span>
<span id="cb131-24"><a href="#cb131-24" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> target_name</span>
<span id="cb131-25"><a href="#cb131-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">FileNotFoundError</span>(<span class="ss">f&quot;Missing </span><span class="sc">{</span>target_name<span class="sc">}</span><span class="ss">. Upload a file with extension(s) </span><span class="sc">{</span>exts<span class="sc">}</span><span class="ss">.&quot;</span>)</span>
<span id="cb131-26"><a href="#cb131-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-27"><a href="#cb131-27" aria-hidden="true" tabindex="-1"></a>ensure_file(<span class="st">&quot;mlb.pkl&quot;</span>, [<span class="st">&quot;.pkl&quot;</span>])</span>
<span id="cb131-28"><a href="#cb131-28" aria-hidden="true" tabindex="-1"></a>ensure_file(<span class="st">&quot;classes.npy&quot;</span>, [<span class="st">&quot;.npy&quot;</span>])</span>
<span id="cb131-29"><a href="#cb131-29" aria-hidden="true" tabindex="-1"></a>ensure_file(<span class="st">&quot;multi_label_scibert.pt&quot;</span>, [<span class="st">&quot;.pt&quot;</span>])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Please select: mlb.pkl, classes.npy, multi_label_scibert.pt
</code></pre>
</div>
<div class="output display_data">

     <input type="file" id="files-774cf633-9796-407c-9803-110e694a4247" name="files[]" multiple disabled
        style="border:none" />
     <output id="result-774cf633-9796-407c-9803-110e694a4247">
      Upload widget is only available when the cell has been executed in the
      current browser session. Please rerun this cell to enable.
      </output>
      <script>// Copyright 2017 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

/**
 * @fileoverview Helpers for google.colab Python module.
 */
(function(scope) {
function span(text, styleAttributes = {}) {
  const element = document.createElement('span');
  element.textContent = text;
  for (const key of Object.keys(styleAttributes)) {
    element.style[key] = styleAttributes[key];
  }
  return element;
}

// Max number of bytes which will be uploaded at a time.
const MAX_PAYLOAD_SIZE = 100 * 1024;

function _uploadFiles(inputId, outputId) {
  const steps = uploadFilesStep(inputId, outputId);
  const outputElement = document.getElementById(outputId);
  // Cache steps on the outputElement to make it available for the next call
  // to uploadFilesContinue from Python.
  outputElement.steps = steps;

  return _uploadFilesContinue(outputId);
}

// This is roughly an async generator (not supported in the browser yet),
// where there are multiple asynchronous steps and the Python side is going
// to poll for completion of each step.
// This uses a Promise to block the python side on completion of each step,
// then passes the result of the previous step as the input to the next step.
function _uploadFilesContinue(outputId) {
  const outputElement = document.getElementById(outputId);
  const steps = outputElement.steps;

  const next = steps.next(outputElement.lastPromiseValue);
  return Promise.resolve(next.value.promise).then((value) => {
    // Cache the last promise value to make it available to the next
    // step of the generator.
    outputElement.lastPromiseValue = value;
    return next.value.response;
  });
}

/**
 * Generator function which is called between each async step of the upload
 * process.
 * @param {string} inputId Element ID of the input file picker element.
 * @param {string} outputId Element ID of the output display.
 * @return {!Iterable<!Object>} Iterable of next steps.
 */
function* uploadFilesStep(inputId, outputId) {
  const inputElement = document.getElementById(inputId);
  inputElement.disabled = false;

  const outputElement = document.getElementById(outputId);
  outputElement.innerHTML = '';

  const pickedPromise = new Promise((resolve) => {
    inputElement.addEventListener('change', (e) => {
      resolve(e.target.files);
    });
  });

  const cancel = document.createElement('button');
  inputElement.parentElement.appendChild(cancel);
  cancel.textContent = 'Cancel upload';
  const cancelPromise = new Promise((resolve) => {
    cancel.onclick = () => {
      resolve(null);
    };
  });

  // Wait for the user to pick the files.
  const files = yield {
    promise: Promise.race([pickedPromise, cancelPromise]),
    response: {
      action: 'starting',
    }
  };

  cancel.remove();

  // Disable the input element since further picks are not allowed.
  inputElement.disabled = true;

  if (!files) {
    return {
      response: {
        action: 'complete',
      }
    };
  }

  for (const file of files) {
    const li = document.createElement('li');
    li.append(span(file.name, {fontWeight: 'bold'}));
    li.append(span(
        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +
        `last modified: ${
            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :
                                    'n/a'} - `));
    const percent = span('0% done');
    li.appendChild(percent);

    outputElement.appendChild(li);

    const fileDataPromise = new Promise((resolve) => {
      const reader = new FileReader();
      reader.onload = (e) => {
        resolve(e.target.result);
      };
      reader.readAsArrayBuffer(file);
    });
    // Wait for the data to be ready.
    let fileData = yield {
      promise: fileDataPromise,
      response: {
        action: 'continue',
      }
    };

    // Use a chunked sending to avoid message size limits. See b/62115660.
    let position = 0;
    do {
      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);
      const chunk = new Uint8Array(fileData, position, length);
      position += length;

      const base64 = btoa(String.fromCharCode.apply(null, chunk));
      yield {
        response: {
          action: 'append',
          file: file.name,
          data: base64,
        },
      };

      let percentDone = fileData.byteLength === 0 ?
          100 :
          Math.round((position / fileData.byteLength) * 100);
      percent.textContent = `${percentDone}% done`;

    } while (position < fileData.byteLength);
  }

  // All done.
  yield {
    response: {
      action: 'complete',
    }
  };
}

scope.google = scope.google || {};
scope.google.colab = scope.google.colab || {};
scope.google.colab._files = {
  _uploadFiles,
  _uploadFilesContinue,
};
})(self);
</script> 
</div>
<div class="output stream stdout">
<pre><code>Saving classes.npy to classes.npy
Saving mlb.pkl to mlb.pkl
Saving multi_label_scibert.pt to multi_label_scibert.pt
</code></pre>
</div>
<div class="output execute_result" data-execution_count="2">
<div class="sourceCode" id="cb134"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;type&quot;</span><span class="fu">:</span><span class="st">&quot;string&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
</div>
<section id="define-model" class="cell markdown" id="E7JeCE9Ao97O">
<h3>Define Model</h3>
<p>The model wraps allenai/scibert_scivocab_uncased with a light
classification head and pools the [CLS] token. The forward pass accepts
token_type_ids for compatibility, though SciBERT won’t use them; leaving
the signature flexible avoids tokenizer/model mismatch errors. After
loading the saved state dict and moving to eval() on CPU/GPU, the cell
defines a pragmatic PDF abstract extractor: scan the first pages, look
for an “Abstract” header, and fall back to the first ~1.5k characters.
This keeps latency low and aligns the inference text with what the model
saw during training (abstract-length inputs).</p>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:356,&quot;referenced_widgets&quot;:[&quot;b57eef0b5998446a87f6c294721a1801&quot;,&quot;3ac6dec95c134f23883d9ef919c2e111&quot;,&quot;5ec55fffae9b4985b0097b16472b1f08&quot;,&quot;80e0878e39d644d1acd849fabb4ab12a&quot;,&quot;7c24a67513984cd990c71568191149c1&quot;,&quot;36ee89bb5aa04063be41acdf645b3581&quot;,&quot;05036b16c20641c9b102459e46fb65b6&quot;,&quot;348e823bb7b64c8b8cae351fcfd78393&quot;,&quot;3d6f128913cb4804bc2c8aae39302ffd&quot;,&quot;d474c09cc17740f4b28ab87718a43e08&quot;,&quot;55f6396e3f0045febcb201d8d961539a&quot;,&quot;a5d8c27481a54005afdf90953f884dae&quot;,&quot;1e7560e12a1e4657a7921025dc1493fb&quot;,&quot;612d4b184a5842c7923797f6991a9e6a&quot;,&quot;cc9352df4a054f2e9672d141582d022a&quot;,&quot;4e26c01347ae43f3bc358e33ab63ab7e&quot;,&quot;5abb794708714f768a15915682f3f4fa&quot;,&quot;b65db23d3a0a40a1afca65516ba9652d&quot;,&quot;a7239d7dad45436c81ecebd24a1daaa3&quot;,&quot;b067cfad0cad4026b60d1d7ed862edb2&quot;,&quot;e8e7656f979c48d49923a47220da8282&quot;,&quot;a944a0ebb880465c81468a370250e74c&quot;,&quot;229822a45aa9413299afdef4a07c810b&quot;,&quot;74bb469e0ca140469da302557021c451&quot;,&quot;55b96d43ff3c41a6b6176a02efd9fe11&quot;,&quot;f36702974fce41649d43844105cfef4f&quot;,&quot;8037e1efab6042ed8c4eeac1602912a5&quot;,&quot;0b7af2e98efb4902abbf6af8baef1a22&quot;,&quot;e995224fd8b442819b833f3722158a79&quot;,&quot;82ba3e7cb20c42eb8c4057c633125063&quot;,&quot;4ffca645bf18450ba471315d36980497&quot;,&quot;66e00f1a274048c6957a639aa926fb94&quot;,&quot;9be1077b540f446681afbba6cd53daec&quot;,&quot;f05bff2ba51f483e9599d9c91bc6a4fe&quot;,&quot;0a2226ca1ab84d39991d6124344084b3&quot;,&quot;59ebdc32b2e44403927916a2b1d8b09a&quot;,&quot;a8f9bb1ad91143188874b01991391771&quot;,&quot;5e6904618a14464a8cca78756af9ea18&quot;,&quot;f99d88337600412a8347ab6baeb38528&quot;,&quot;c92d2328f3f241958d25694f5e576dfd&quot;,&quot;3b2e35ec060849ea87ae038d601712e7&quot;,&quot;87c4b7f530774b359ce5e0db88112ae5&quot;,&quot;735056ad11154d968004f54ff67aa44f&quot;,&quot;a7cc8f4ca1c14453a6a88b09da5aeee9&quot;]}"
id="DfrmXBPKx5st" data-outputId="ccb4c511-38ea-4d5e-ef7e-b72a00072998">
<div class="sourceCode" id="cb135"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> google.colab <span class="im">import</span> files</span>
<span id="cb135-2"><a href="#cb135-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-3"><a href="#cb135-3" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">&quot;cuda&quot;</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">&quot;cpu&quot;</span>)</span>
<span id="cb135-4"><a href="#cb135-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-5"><a href="#cb135-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Model definition &amp; load</span></span>
<span id="cb135-6"><a href="#cb135-6" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MultiLabelSciBERT(torch.nn.Module):</span>
<span id="cb135-7"><a href="#cb135-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_labels):</span>
<span id="cb135-8"><a href="#cb135-8" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb135-9"><a href="#cb135-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bert <span class="op">=</span> AutoModel.from_pretrained(<span class="st">&quot;allenai/scibert_scivocab_uncased&quot;</span>)</span>
<span id="cb135-10"><a href="#cb135-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout <span class="op">=</span> torch.nn.Dropout(<span class="fl">0.3</span>)</span>
<span id="cb135-11"><a href="#cb135-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.classifier <span class="op">=</span> torch.nn.Linear(<span class="va">self</span>.bert.config.hidden_size, num_labels)</span>
<span id="cb135-12"><a href="#cb135-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-13"><a href="#cb135-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, input_ids, attention_mask, token_type_ids<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb135-14"><a href="#cb135-14" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> <span class="va">self</span>.bert(input_ids<span class="op">=</span>input_ids, attention_mask<span class="op">=</span>attention_mask,</span>
<span id="cb135-15"><a href="#cb135-15" aria-hidden="true" tabindex="-1"></a>        token_type_ids<span class="op">=</span>token_type_ids)</span>
<span id="cb135-16"><a href="#cb135-16" aria-hidden="true" tabindex="-1"></a>        pooled <span class="op">=</span> outputs.last_hidden_state[:, <span class="dv">0</span>]              <span class="co"># [CLS]-like token</span></span>
<span id="cb135-17"><a href="#cb135-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.classifier(<span class="va">self</span>.dropout(pooled))</span>
<span id="cb135-18"><a href="#cb135-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-19"><a href="#cb135-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Load encoder, class names, tokeniser, and model weights</span></span>
<span id="cb135-20"><a href="#cb135-20" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">&quot;mlb.pkl&quot;</span>, <span class="st">&quot;rb&quot;</span>) <span class="im">as</span> f:</span>
<span id="cb135-21"><a href="#cb135-21" aria-hidden="true" tabindex="-1"></a>    mlb <span class="op">=</span> pickle.load(f)</span>
<span id="cb135-22"><a href="#cb135-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-23"><a href="#cb135-23" aria-hidden="true" tabindex="-1"></a>classes <span class="op">=</span> np.load(<span class="st">&quot;classes.npy&quot;</span>, allow_pickle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb135-24"><a href="#cb135-24" aria-hidden="true" tabindex="-1"></a>classes <span class="op">=</span> <span class="bu">list</span>(classes)  <span class="co"># ensure python list</span></span>
<span id="cb135-25"><a href="#cb135-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-26"><a href="#cb135-26" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(<span class="st">&quot;allenai/scibert_scivocab_uncased&quot;</span>)</span>
<span id="cb135-27"><a href="#cb135-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-28"><a href="#cb135-28" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> MultiLabelSciBERT(num_labels<span class="op">=</span><span class="bu">len</span>(classes))</span>
<span id="cb135-29"><a href="#cb135-29" aria-hidden="true" tabindex="-1"></a>model.load_state_dict(torch.load(<span class="st">&quot;multi_label_scibert.pt&quot;</span>, map_location<span class="op">=</span><span class="st">&quot;cpu&quot;</span>))</span>
<span id="cb135-30"><a href="#cb135-30" aria-hidden="true" tabindex="-1"></a>model.to(device).<span class="bu">eval</span>()</span>
<span id="cb135-31"><a href="#cb135-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-32"><a href="#cb135-32" aria-hidden="true" tabindex="-1"></a><span class="co"># PDF Extraction</span></span>
<span id="cb135-33"><a href="#cb135-33" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> extract_abstract_from_pdf(pdf_path, pages_to_scan<span class="op">=</span><span class="dv">2</span>, fallback_chars<span class="op">=</span><span class="dv">1500</span>):</span>
<span id="cb135-34"><a href="#cb135-34" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;Find text after an &#39;Abstract&#39; header; fall back to first N chars of first pages.&quot;&quot;&quot;</span></span>
<span id="cb135-35"><a href="#cb135-35" aria-hidden="true" tabindex="-1"></a>    text_blocks <span class="op">=</span> []</span>
<span id="cb135-36"><a href="#cb135-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> pdfplumber.<span class="bu">open</span>(pdf_path) <span class="im">as</span> pdf:</span>
<span id="cb135-37"><a href="#cb135-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> page <span class="kw">in</span> pdf.pages[:pages_to_scan]:</span>
<span id="cb135-38"><a href="#cb135-38" aria-hidden="true" tabindex="-1"></a>            t <span class="op">=</span> page.extract_text() <span class="kw">or</span> <span class="st">&quot;&quot;</span></span>
<span id="cb135-39"><a href="#cb135-39" aria-hidden="true" tabindex="-1"></a>            text_blocks.append(t)</span>
<span id="cb135-40"><a href="#cb135-40" aria-hidden="true" tabindex="-1"></a>    full_text <span class="op">=</span> <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>.join(text_blocks)</span>
<span id="cb135-41"><a href="#cb135-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-42"><a href="#cb135-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Normalise hyphenation &amp; spaces a bit</span></span>
<span id="cb135-43"><a href="#cb135-43" aria-hidden="true" tabindex="-1"></a>    full_text <span class="op">=</span> re.sub(<span class="vs">r&quot;-\n&quot;</span>, <span class="st">&quot;&quot;</span>, full_text)</span>
<span id="cb135-44"><a href="#cb135-44" aria-hidden="true" tabindex="-1"></a>    full_text <span class="op">=</span> re.sub(<span class="vs">r&quot;\s+\n&quot;</span>, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>, full_text)</span>
<span id="cb135-45"><a href="#cb135-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-46"><a href="#cb135-46" aria-hidden="true" tabindex="-1"></a>    lines <span class="op">=</span> full_text.splitlines()</span>
<span id="cb135-47"><a href="#cb135-47" aria-hidden="true" tabindex="-1"></a>    abstract <span class="op">=</span> <span class="st">&quot;&quot;</span></span>
<span id="cb135-48"><a href="#cb135-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, line <span class="kw">in</span> <span class="bu">enumerate</span>(lines):</span>
<span id="cb135-49"><a href="#cb135-49" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> re.search(<span class="vs">r&quot;\babstract\b&quot;</span>, line, flags<span class="op">=</span>re.IGNORECASE):</span>
<span id="cb135-50"><a href="#cb135-50" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Take the next few lines as the abstract body</span></span>
<span id="cb135-51"><a href="#cb135-51" aria-hidden="true" tabindex="-1"></a>            abstract <span class="op">=</span> <span class="st">&quot; &quot;</span>.join(lines[i<span class="op">+</span><span class="dv">1</span>:i<span class="op">+</span><span class="dv">12</span>])</span>
<span id="cb135-52"><a href="#cb135-52" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb135-53"><a href="#cb135-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-54"><a href="#cb135-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> abstract:</span>
<span id="cb135-55"><a href="#cb135-55" aria-hidden="true" tabindex="-1"></a>        abstract <span class="op">=</span> full_text[:fallback_chars]</span>
<span id="cb135-56"><a href="#cb135-56" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> abstract.strip()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.8/42.8 kB 1.1 MB/s eta 0:00:00
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.5/48.5 kB 2.4 MB/s eta 0:00:00
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.0/60.0 kB 3.5 MB/s eta 0:00:00
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.6/5.6 MB 26.8 MB/s eta 0:00:00
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.8/2.8 MB 58.4 MB/s eta 0:00:00
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: 
The secret `HF_TOKEN` does not exist in your Colab secrets.
To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.
You will be able to reuse this secret in all of your notebooks.
Please note that authentication is recommended but still optional to access public models or datasets.
  warnings.warn(
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb138"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb138-1"><a href="#cb138-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;b57eef0b5998446a87f6c294721a1801&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb139"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;a5d8c27481a54005afdf90953f884dae&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb140"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;229822a45aa9413299afdef4a07c810b&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb141"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb141-1"><a href="#cb141-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;f05bff2ba51f483e9599d9c91bc6a4fe&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
</div>
<section id="runner" class="cell markdown" id="Wx_4wUlHpOH9">
<h3>Runner</h3>
<p>predict_labels tokenises a string, applies the model, and turns
logits into probabilities via sigmoid, thresholded at 0.5. The helper
get_label_groups() declares the three families (discipline, subfield,
methodology) using the saved classes. group_predictions converts
multi-label outputs into a single, human-readable tag per family by
taking the highest-probability label within each group (while still
returning the full on/off vector). Finally, print_grouped_confidences
lists each family sorted by probability and marks which labels crossed
the threshold useful for quick sanity checks and for spotting borderline
cases without opening extra plots.</p>
</section>
<div class="cell code" id="T1V4hr_Gx699">
<div class="sourceCode" id="cb142"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb142-1"><a href="#cb142-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Inference</span></span>
<span id="cb142-2"><a href="#cb142-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> predict_labels(text, max_len<span class="op">=</span><span class="dv">256</span>, threshold<span class="op">=</span><span class="fl">0.5</span>):</span>
<span id="cb142-3"><a href="#cb142-3" aria-hidden="true" tabindex="-1"></a>    enc <span class="op">=</span> tokenizer(</span>
<span id="cb142-4"><a href="#cb142-4" aria-hidden="true" tabindex="-1"></a>        text,</span>
<span id="cb142-5"><a href="#cb142-5" aria-hidden="true" tabindex="-1"></a>        return_tensors<span class="op">=</span><span class="st">&quot;pt&quot;</span>,</span>
<span id="cb142-6"><a href="#cb142-6" aria-hidden="true" tabindex="-1"></a>        padding<span class="op">=</span><span class="st">&quot;max_length&quot;</span>,</span>
<span id="cb142-7"><a href="#cb142-7" aria-hidden="true" tabindex="-1"></a>        truncation<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb142-8"><a href="#cb142-8" aria-hidden="true" tabindex="-1"></a>        max_length<span class="op">=</span>max_len,</span>
<span id="cb142-9"><a href="#cb142-9" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb142-10"><a href="#cb142-10" aria-hidden="true" tabindex="-1"></a>    enc <span class="op">=</span> {k: v.to(device) <span class="cf">for</span> k, v <span class="kw">in</span> enc.items()}</span>
<span id="cb142-11"><a href="#cb142-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb142-12"><a href="#cb142-12" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> model(<span class="op">**</span>enc)</span>
<span id="cb142-13"><a href="#cb142-13" aria-hidden="true" tabindex="-1"></a>        probs <span class="op">=</span> torch.sigmoid(logits).squeeze().detach().cpu().numpy()</span>
<span id="cb142-14"><a href="#cb142-14" aria-hidden="true" tabindex="-1"></a>    preds <span class="op">=</span> (probs <span class="op">&gt;</span> threshold).astype(<span class="bu">int</span>)</span>
<span id="cb142-15"><a href="#cb142-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> preds, probs</span>
<span id="cb142-16"><a href="#cb142-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb142-17"><a href="#cb142-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Label group helpers</span></span>
<span id="cb142-18"><a href="#cb142-18" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_label_groups():</span>
<span id="cb142-19"><a href="#cb142-19" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;Return lists of labels for Discipline, Methodology, and Subfield.&quot;&quot;&quot;</span></span>
<span id="cb142-20"><a href="#cb142-20" aria-hidden="true" tabindex="-1"></a>    disc_list <span class="op">=</span> [</span>
<span id="cb142-21"><a href="#cb142-21" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;Computer Science&#39;</span>, <span class="st">&#39;Mathematics&#39;</span>, <span class="st">&#39;Physics&#39;</span>, <span class="st">&#39;Economics&#39;</span>,</span>
<span id="cb142-22"><a href="#cb142-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;Quantitative Biology&#39;</span>, <span class="st">&#39;Statistics&#39;</span>,</span>
<span id="cb142-23"><a href="#cb142-23" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;Electrical Engineering and Systems Science&#39;</span>, <span class="st">&#39;Astrophysics&#39;</span></span>
<span id="cb142-24"><a href="#cb142-24" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb142-25"><a href="#cb142-25" aria-hidden="true" tabindex="-1"></a>    meth_list <span class="op">=</span> [</span>
<span id="cb142-26"><a href="#cb142-26" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;Qualitative&#39;</span>, <span class="st">&#39;Mixed Methods&#39;</span>,</span>
<span id="cb142-27"><a href="#cb142-27" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;Theoretical / Conceptual&#39;</span>, <span class="st">&#39;Design Science / System Design&#39;</span></span>
<span id="cb142-28"><a href="#cb142-28" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb142-29"><a href="#cb142-29" aria-hidden="true" tabindex="-1"></a>    sub_list <span class="op">=</span> [lbl <span class="cf">for</span> lbl <span class="kw">in</span> classes <span class="cf">if</span> lbl <span class="kw">not</span> <span class="kw">in</span> disc_list <span class="op">+</span> meth_list]</span>
<span id="cb142-30"><a href="#cb142-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> disc_list, meth_list, sub_list</span>
<span id="cb142-31"><a href="#cb142-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb142-32"><a href="#cb142-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Grouped prediction selector</span></span>
<span id="cb142-33"><a href="#cb142-33" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> group_predictions(preds, probs):</span>
<span id="cb142-34"><a href="#cb142-34" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb142-35"><a href="#cb142-35" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb142-36"><a href="#cb142-36" aria-hidden="true" tabindex="-1"></a><span class="co">      discipline (str|None), subfield (str|None), methodology (str|None),</span></span>
<span id="cb142-37"><a href="#cb142-37" aria-hidden="true" tabindex="-1"></a><span class="co">      pred_labels (list[str]), probs (np.ndarray)</span></span>
<span id="cb142-38"><a href="#cb142-38" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb142-39"><a href="#cb142-39" aria-hidden="true" tabindex="-1"></a>    disc_list, meth_list, sub_list <span class="op">=</span> get_label_groups()</span>
<span id="cb142-40"><a href="#cb142-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb142-41"><a href="#cb142-41" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> best_of(group):</span>
<span id="cb142-42"><a href="#cb142-42" aria-hidden="true" tabindex="-1"></a>        idxs <span class="op">=</span> [i <span class="cf">for</span> i, c <span class="kw">in</span> <span class="bu">enumerate</span>(classes) <span class="cf">if</span> c <span class="kw">in</span> group]</span>
<span id="cb142-43"><a href="#cb142-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> idxs:</span>
<span id="cb142-44"><a href="#cb142-44" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb142-45"><a href="#cb142-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> classes[<span class="bu">max</span>(idxs, key<span class="op">=</span><span class="kw">lambda</span> i: probs[i])]</span>
<span id="cb142-46"><a href="#cb142-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb142-47"><a href="#cb142-47" aria-hidden="true" tabindex="-1"></a>    discipline  <span class="op">=</span> best_of(disc_list)</span>
<span id="cb142-48"><a href="#cb142-48" aria-hidden="true" tabindex="-1"></a>    subfield    <span class="op">=</span> best_of(sub_list)</span>
<span id="cb142-49"><a href="#cb142-49" aria-hidden="true" tabindex="-1"></a>    methodology <span class="op">=</span> best_of(meth_list)</span>
<span id="cb142-50"><a href="#cb142-50" aria-hidden="true" tabindex="-1"></a>    pred_labels <span class="op">=</span> [classes[i] <span class="cf">for</span> i, v <span class="kw">in</span> <span class="bu">enumerate</span>(preds) <span class="cf">if</span> v <span class="op">==</span> <span class="dv">1</span>]</span>
<span id="cb142-51"><a href="#cb142-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb142-52"><a href="#cb142-52" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> discipline, subfield, methodology, pred_labels, probs</span>
<span id="cb142-53"><a href="#cb142-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb142-54"><a href="#cb142-54" aria-hidden="true" tabindex="-1"></a><span class="co"># Pretty-print grouped confidences</span></span>
<span id="cb142-55"><a href="#cb142-55" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> print_grouped_confidences(probs, preds):</span>
<span id="cb142-56"><a href="#cb142-56" aria-hidden="true" tabindex="-1"></a>    disc_list, meth_list, sub_list <span class="op">=</span> get_label_groups()</span>
<span id="cb142-57"><a href="#cb142-57" aria-hidden="true" tabindex="-1"></a>    width <span class="op">=</span> <span class="bu">max</span>(<span class="bu">len</span>(lbl) <span class="cf">for</span> lbl <span class="kw">in</span> classes) <span class="op">+</span> <span class="dv">2</span></span>
<span id="cb142-58"><a href="#cb142-58" aria-hidden="true" tabindex="-1"></a>    prob_map <span class="op">=</span> {lbl: <span class="bu">float</span>(probs[i]) <span class="cf">for</span> i, lbl <span class="kw">in</span> <span class="bu">enumerate</span>(classes)}</span>
<span id="cb142-59"><a href="#cb142-59" aria-hidden="true" tabindex="-1"></a>    on_labels <span class="op">=</span> {classes[i] <span class="cf">for</span> i, v <span class="kw">in</span> <span class="bu">enumerate</span>(preds) <span class="cf">if</span> v <span class="op">==</span> <span class="dv">1</span>}</span>
<span id="cb142-60"><a href="#cb142-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb142-61"><a href="#cb142-61" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> dump(title, labels):</span>
<span id="cb142-62"><a href="#cb142-62" aria-hidden="true" tabindex="-1"></a>        rows <span class="op">=</span> [(lbl, prob_map.get(lbl, <span class="fl">0.0</span>)) <span class="cf">for</span> lbl <span class="kw">in</span> labels]</span>
<span id="cb142-63"><a href="#cb142-63" aria-hidden="true" tabindex="-1"></a>        rows.sort(key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="dv">1</span>], reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb142-64"><a href="#cb142-64" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;</span><span class="sc">{</span>title<span class="sc">}</span><span class="ss">:&quot;</span>)</span>
<span id="cb142-65"><a href="#cb142-65" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> lbl, p <span class="kw">in</span> rows:</span>
<span id="cb142-66"><a href="#cb142-66" aria-hidden="true" tabindex="-1"></a>            star <span class="op">=</span> <span class="st">&quot; *&quot;</span> <span class="cf">if</span> lbl <span class="kw">in</span> on_labels <span class="cf">else</span> <span class="st">&quot;&quot;</span></span>
<span id="cb142-67"><a href="#cb142-67" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot;  </span><span class="sc">{</span>lbl<span class="sc">:</span>{width}<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>p<span class="sc">:.2f}{</span>star<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb142-68"><a href="#cb142-68" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>()</span>
<span id="cb142-69"><a href="#cb142-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb142-70"><a href="#cb142-70" aria-hidden="true" tabindex="-1"></a>    dump(<span class="st">&quot;Discipline&quot;</span>,  disc_list)</span>
<span id="cb142-71"><a href="#cb142-71" aria-hidden="true" tabindex="-1"></a>    dump(<span class="st">&quot;Subfield&quot;</span>,    sub_list)</span>
<span id="cb142-72"><a href="#cb142-72" aria-hidden="true" tabindex="-1"></a>    dump(<span class="st">&quot;Methodology&quot;</span>, meth_list)</span></code></pre></div>
</div>
<section id="batch-inference-product" class="cell markdown"
id="bftIZLvkpiyS">
<h3>Batch Inference Product</h3>
<p>This cell provides the end-to-end loop: upload one or more PDFs,
extract an abstract-length snippet, run the model, and display (i) the
top discipline, subfield, and methodology and (ii) the ordered
confidence tables for each family. Exceptions are caught per file so a
bad scan or malformed PDF won’t interrupt the whole batch. The result is
a self-contained demo: drop in papers, get structured tags plus
transparent scores.</p>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="tiwPspAeJ0hp" data-outputId="c2a33431-c170-4034-cfa7-5116baa8fd15">
<div class="sourceCode" id="cb143"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb143-1"><a href="#cb143-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Upload &amp; Predict Multiple PDFs</span></span>
<span id="cb143-2"><a href="#cb143-2" aria-hidden="true" tabindex="-1"></a>uploaded <span class="op">=</span> files.upload()</span>
<span id="cb143-3"><a href="#cb143-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb143-4"><a href="#cb143-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> filename <span class="kw">in</span> uploaded:</span>
<span id="cb143-5"><a href="#cb143-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;</span><span class="ch">\n</span><span class="ss">File: </span><span class="sc">{</span>filename<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb143-6"><a href="#cb143-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb143-7"><a href="#cb143-7" aria-hidden="true" tabindex="-1"></a>        text <span class="op">=</span> extract_abstract_from_pdf(filename)</span>
<span id="cb143-8"><a href="#cb143-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> text.strip():</span>
<span id="cb143-9"><a href="#cb143-9" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">&quot;No extractable text found in the first pages; skipping.</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb143-10"><a href="#cb143-10" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb143-11"><a href="#cb143-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb143-12"><a href="#cb143-12" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;</span><span class="ch">\n</span><span class="ss">Extracted Abstract (preview):</span><span class="ch">\n</span><span class="sc">{</span>text[:<span class="dv">500</span>]<span class="sc">}</span><span class="ss">...</span><span class="ch">\n</span><span class="ss">&quot;</span>)</span>
<span id="cb143-13"><a href="#cb143-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb143-14"><a href="#cb143-14" aria-hidden="true" tabindex="-1"></a>        preds, probs <span class="op">=</span> predict_labels(text)</span>
<span id="cb143-15"><a href="#cb143-15" aria-hidden="true" tabindex="-1"></a>        discipline, subfield, methodology, pred_labels, probs <span class="op">=</span> group_predictions(preds, probs)</span>
<span id="cb143-16"><a href="#cb143-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb143-17"><a href="#cb143-17" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;Predicted Categories:&quot;</span>)</span>
<span id="cb143-18"><a href="#cb143-18" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;  Discipline : </span><span class="sc">{</span>discipline<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb143-19"><a href="#cb143-19" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;  Subfield   : </span><span class="sc">{</span>subfield<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb143-20"><a href="#cb143-20" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;  Methodology: </span><span class="sc">{</span>methodology<span class="sc">}</span><span class="ch">\n</span><span class="ss">&quot;</span>)</span>
<span id="cb143-21"><a href="#cb143-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb143-22"><a href="#cb143-22" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;Confidence per label (grouped):&quot;</span>)</span>
<span id="cb143-23"><a href="#cb143-23" aria-hidden="true" tabindex="-1"></a>        print_grouped_confidences(probs, preds)</span>
<span id="cb143-24"><a href="#cb143-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb143-25"><a href="#cb143-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb143-26"><a href="#cb143-26" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;Error processing </span><span class="sc">{</span>filename<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output display_data">

     <input type="file" id="files-0ef6175e-ea57-49cc-a283-07a2ed6be4f1" name="files[]" multiple disabled
        style="border:none" />
     <output id="result-0ef6175e-ea57-49cc-a283-07a2ed6be4f1">
      Upload widget is only available when the cell has been executed in the
      current browser session. Please rerun this cell to enable.
      </output>
      <script>// Copyright 2017 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

/**
 * @fileoverview Helpers for google.colab Python module.
 */
(function(scope) {
function span(text, styleAttributes = {}) {
  const element = document.createElement('span');
  element.textContent = text;
  for (const key of Object.keys(styleAttributes)) {
    element.style[key] = styleAttributes[key];
  }
  return element;
}

// Max number of bytes which will be uploaded at a time.
const MAX_PAYLOAD_SIZE = 100 * 1024;

function _uploadFiles(inputId, outputId) {
  const steps = uploadFilesStep(inputId, outputId);
  const outputElement = document.getElementById(outputId);
  // Cache steps on the outputElement to make it available for the next call
  // to uploadFilesContinue from Python.
  outputElement.steps = steps;

  return _uploadFilesContinue(outputId);
}

// This is roughly an async generator (not supported in the browser yet),
// where there are multiple asynchronous steps and the Python side is going
// to poll for completion of each step.
// This uses a Promise to block the python side on completion of each step,
// then passes the result of the previous step as the input to the next step.
function _uploadFilesContinue(outputId) {
  const outputElement = document.getElementById(outputId);
  const steps = outputElement.steps;

  const next = steps.next(outputElement.lastPromiseValue);
  return Promise.resolve(next.value.promise).then((value) => {
    // Cache the last promise value to make it available to the next
    // step of the generator.
    outputElement.lastPromiseValue = value;
    return next.value.response;
  });
}

/**
 * Generator function which is called between each async step of the upload
 * process.
 * @param {string} inputId Element ID of the input file picker element.
 * @param {string} outputId Element ID of the output display.
 * @return {!Iterable<!Object>} Iterable of next steps.
 */
function* uploadFilesStep(inputId, outputId) {
  const inputElement = document.getElementById(inputId);
  inputElement.disabled = false;

  const outputElement = document.getElementById(outputId);
  outputElement.innerHTML = '';

  const pickedPromise = new Promise((resolve) => {
    inputElement.addEventListener('change', (e) => {
      resolve(e.target.files);
    });
  });

  const cancel = document.createElement('button');
  inputElement.parentElement.appendChild(cancel);
  cancel.textContent = 'Cancel upload';
  const cancelPromise = new Promise((resolve) => {
    cancel.onclick = () => {
      resolve(null);
    };
  });

  // Wait for the user to pick the files.
  const files = yield {
    promise: Promise.race([pickedPromise, cancelPromise]),
    response: {
      action: 'starting',
    }
  };

  cancel.remove();

  // Disable the input element since further picks are not allowed.
  inputElement.disabled = true;

  if (!files) {
    return {
      response: {
        action: 'complete',
      }
    };
  }

  for (const file of files) {
    const li = document.createElement('li');
    li.append(span(file.name, {fontWeight: 'bold'}));
    li.append(span(
        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +
        `last modified: ${
            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :
                                    'n/a'} - `));
    const percent = span('0% done');
    li.appendChild(percent);

    outputElement.appendChild(li);

    const fileDataPromise = new Promise((resolve) => {
      const reader = new FileReader();
      reader.onload = (e) => {
        resolve(e.target.result);
      };
      reader.readAsArrayBuffer(file);
    });
    // Wait for the data to be ready.
    let fileData = yield {
      promise: fileDataPromise,
      response: {
        action: 'continue',
      }
    };

    // Use a chunked sending to avoid message size limits. See b/62115660.
    let position = 0;
    do {
      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);
      const chunk = new Uint8Array(fileData, position, length);
      position += length;

      const base64 = btoa(String.fromCharCode.apply(null, chunk));
      yield {
        response: {
          action: 'append',
          file: file.name,
          data: base64,
        },
      };

      let percentDone = fileData.byteLength === 0 ?
          100 :
          Math.round((position / fileData.byteLength) * 100);
      percent.textContent = `${percentDone}% done`;

    } while (position < fileData.byteLength);
  }

  // All done.
  yield {
    response: {
      action: 'complete',
    }
  };
}

scope.google = scope.google || {};
scope.google.colab = scope.google.colab || {};
scope.google.colab._files = {
  _uploadFiles,
  _uploadFilesContinue,
};
})(self);
</script> 
</div>
<div class="output stream stdout">
<pre><code>Saving 2506.09330v1.pdf to 2506.09330v1.pdf
Saving 2506.14102v1.pdf to 2506.14102v1.pdf
Saving 2508.02508v1.pdf to 2508.02508v1.pdf
Saving 2508.02548v1.pdf to 2508.02548v1.pdf
Saving 0503311v1.pdf to 0503311v1.pdf

File: 2506.09330v1.pdf

Extracted Abstract (preview):
We design a portfolio construction framework and implement an active investment strategy utilizing momentum and trend-following signals across multiple asset classes and asset class risk factors. We quantify the performance of this strategy to demonstrate its ability to create excess returns above industry standard benchmarks, as well as manage volatility and drawdown risks over a 22+ year period. 1. Introduction Conscious Capital Advisors is an investment advisory firm that combines rigorous re...

Predicted Categories:
  Discipline : Economics
  Subfield   : General Economics
  Methodology: Design Science / System Design

Confidence per label (grouped):
Discipline:
  Economics                                   : 0.77 *
  Computer Science                            : 0.08
  Mathematics                                 : 0.05
  Statistics                                  : 0.03
  Physics                                     : 0.02
  Electrical Engineering and Systems Science  : 0.01
  Quantitative Biology                        : 0.01
  Astrophysics                                : 0.00

Subfield:
  General Economics                           : 0.79 *
  Machine Learning                            : 0.11
  Computer Science and Game Theory            : 0.04
  Algebraic Geometry                          : 0.01
  Neural and Cognitive Modeling               : 0.01
  Quantum Physics                             : 0.01
  Image and Video Processing                  : 0.01
  Galaxy Astrophysics                         : 0.00

Methodology:
  Design Science / System Design              : 0.96 *
  Mixed Methods                               : 0.03
  Theoretical / Conceptual                    : 0.02
  Qualitative                                 : 0.01


File: 2506.14102v1.pdf

Extracted Abstract (preview):
There is increasing acknowledgement – including from the UK government - of the benefit of employing deliberative processes (deliberative fora, citizens’ juries, etc.). Evidence suggests that the qualitative reporting of deliberative fora are often unclear or imprecise. If this is the case, their value to policymakers could be diminished. In this study we develop numerical methods of deliberative processes to document people’s preferences, as a complement to qualitative analysis. Data are taken ...

Predicted Categories:
  Discipline : Economics
  Subfield   : General Economics
  Methodology: Design Science / System Design

Confidence per label (grouped):
Discipline:
  Economics                                   : 0.69 *
  Computer Science                            : 0.17
  Mathematics                                 : 0.08
  Statistics                                  : 0.05
  Physics                                     : 0.02
  Quantitative Biology                        : 0.01
  Electrical Engineering and Systems Science  : 0.01
  Astrophysics                                : 0.00

Subfield:
  General Economics                           : 0.63 *
  Machine Learning                            : 0.17
  Computer Science and Game Theory            : 0.03
  Neural and Cognitive Modeling               : 0.02
  Algebraic Geometry                          : 0.01
  Image and Video Processing                  : 0.01
  Quantum Physics                             : 0.01
  Galaxy Astrophysics                         : 0.00

Methodology:
  Design Science / System Design              : 0.91 *
  Theoretical / Conceptual                    : 0.04
  Mixed Methods                               : 0.04
  Qualitative                                 : 0.01


File: 2508.02508v1.pdf

Extracted Abstract (preview):
Moderndataanalyticworkloadsincreasinglyrequirehandlingmul- executionacrossthem.Unfortunately,however,thecoordinator tipledatamodelssimultaneously.Twoprimaryapproachesmeet andtheunderlyingdatabasesystemsarephysicallydisaggregated. thisneed:polyglotpersistenceandmulti-modeldatabasesystems. Consequently,asubstantialamountofcommunicationoverhead Polyglotpersistenceemploysacoordinatorprogramtomanage isincurredinevitablytotransferintermediateandfinalresultdata severalindependentdatabasesystemsbutsuffe...

Predicted Categories:
  Discipline : Computer Science
  Subfield   : Machine Learning
  Methodology: Design Science / System Design

Confidence per label (grouped):
Discipline:
  Computer Science                            : 0.53 *
  Electrical Engineering and Systems Science  : 0.13
  Mathematics                                 : 0.05
  Physics                                     : 0.03
  Quantitative Biology                        : 0.02
  Statistics                                  : 0.02
  Economics                                   : 0.02
  Astrophysics                                : 0.01

Subfield:
  Machine Learning                            : 0.47
  Computer Science and Game Theory            : 0.10
  Image and Video Processing                  : 0.07
  General Economics                           : 0.03
  Algebraic Geometry                          : 0.03
  Neural and Cognitive Modeling               : 0.02
  Quantum Physics                             : 0.02
  Galaxy Astrophysics                         : 0.01

Methodology:
  Design Science / System Design              : 0.95 *
  Theoretical / Conceptual                    : 0.03
  Mixed Methods                               : 0.02
  Qualitative                                 : 0.01


File: 2508.02548v1.pdf

Extracted Abstract (preview):
WeproposeKG-ER,aconceptualschemalanguageforknowledgegraphsthatdescribesthe structureofknowledgegraphsindependentlyoftheirrepresentation(relationaldatabases,property graphs,RDF)whilehelpingtocapturethesemanticsoftheinformationstoredinaknowledge graph. 1 Introduction Knowledgegraphs(KGs)havebecomecentraltomanyAIapplications[22],benefitingmanyAI-based tasks, including NLP and reasoning [17], data integration [15, 7], and semantic search [23]. KGs organizeinformationasgraphs,withnodesasentityinstanc...

Predicted Categories:
  Discipline : Computer Science
  Subfield   : Machine Learning
  Methodology: Design Science / System Design

Confidence per label (grouped):
Discipline:
  Computer Science                            : 0.51 *
  Mathematics                                 : 0.10
  Physics                                     : 0.05
  Electrical Engineering and Systems Science  : 0.04
  Quantitative Biology                        : 0.04
  Statistics                                  : 0.03
  Economics                                   : 0.01
  Astrophysics                                : 0.01

Subfield:
  Machine Learning                            : 0.44
  Computer Science and Game Theory            : 0.08
  Algebraic Geometry                          : 0.05
  General Economics                           : 0.05
  Neural and Cognitive Modeling               : 0.03
  Quantum Physics                             : 0.02
  Image and Video Processing                  : 0.02
  Galaxy Astrophysics                         : 0.00

Methodology:
  Design Science / System Design              : 0.74 *
  Theoretical / Conceptual                    : 0.19
  Mixed Methods                               : 0.04
  Qualitative                                 : 0.00


File: 0503311v1.pdf

Extracted Abstract (preview):
5002
raM
51
1v1133050/hp-ortsa:viXra
‘22nd Texas Symposium on Relativistic Astrophysics’, Palo Alto (USA), December 13-17, 2004 1
Evidence for Supernova light in all Gamma-Ray Burst afterglows
A.Zeh,S.Klose
Thu¨ringerLandessternwarteTautenburg,07778Tautenburg,Germany
D.H.Hartmann
DepartmentofPhysicsandAstronomy,ClemsonUniversity,Clemson,SC29634-0978
WepresentanupdateofoursystematicanalysisofallGamma-RayBurst(GRB)afterglowdata,nowpublished
throughtheendof2004,inanattempttodetectthepredictedsupern...

Predicted Categories:
  Discipline : Astrophysics
  Subfield   : Galaxy Astrophysics
  Methodology: Design Science / System Design

Confidence per label (grouped):
Discipline:
  Astrophysics                                : 0.82 *
  Physics                                     : 0.13
  Mathematics                                 : 0.04
  Electrical Engineering and Systems Science  : 0.03
  Computer Science                            : 0.02
  Quantitative Biology                        : 0.02
  Economics                                   : 0.01
  Statistics                                  : 0.01

Subfield:
  Galaxy Astrophysics                         : 0.78 *
  Quantum Physics                             : 0.08
  Neural and Cognitive Modeling               : 0.04
  Algebraic Geometry                          : 0.04
  General Economics                           : 0.03
  Machine Learning                            : 0.03
  Computer Science and Game Theory            : 0.02
  Image and Video Processing                  : 0.01

Methodology:
  Design Science / System Design              : 0.37
  Theoretical / Conceptual                    : 0.25
  Mixed Methods                               : 0.14
  Qualitative                                 : 0.10

</code></pre>
</div>
</div>
<section id="8-conclusion-and-discussion" class="cell markdown"
id="luVxYFQsLYTZ">
<h1>8. Conclusion and Discussion</h1>
<p>So all in all, this project documents an end-to-end build of a
research-paper classifier: data prep, TF-IDF baselines, three
transformer families, targeted extensions, a multi-label SciBERT, and a
runnable PDF-to-labels pipeline. The decision rule for “best model” was
grounded in macro-F1 (equal weight per class) with per-class recall as a
secondary lens for methodology—where minority coverage matters. Under
that criterion, SciBERT Model 1 emerged as the most balanced backbone;
its multi-label variant preserved that balance across discipline,
subfield, and methodology.</p>
<p>The engineering has showed that:</p>
<ul>
<li><p>Pretraining priors matter. SciBERT’s scientific domain
pretraining helped recover non-keyword cues (e.g., discourse markers)
and gave the best macro-F1 on methodology. RoBERTa was broadly strong
but needed rebalancing to lift the smallest class. DistilBERT was
efficient and accurate on dominant labels but under-fitted the smallest
class without targeted biasing.</p></li>
<li><p>A token-length study justified 256 as a safe operating point for
most abstracts (used in extended runs), while 512 was kept for the
headline Model-1 baselines to avoid truncation confounds in the first
comparison.</p></li>
<li><p>Multi-label training required BCEWithLogitsLoss, per-label
thresholding, and custom early-stopping logic; implementing these
directly was more stable in Colab and simpler to debug than bending a
generic Trainer around them.</p></li>
<li><p>Hyperparameter tuning was model-specific by design and necessity.
RoBERTa benefited from warm-up/label smoothing/loss weights; DistilBERT
was more sensitive to warm-up; SciBERT was already stable with minimal
tweaks. Colab GPU/memory limits also constrained exhaustive sweeps. Read
the cross-model gaps as reasonable, model-appropriate tuning, not fully
saturated optima. Key controls (split, tokenisation, selection rule)
were held fixed to anchor fairness.</p></li>
</ul>
<p>Constraints encountered (and how they shaped my choices):</p>
<ul>
<li><p>GPU/time limits influenced batch sizes, epoch counts, and the
choice to prefer early stopping over long schedules or large HPO
grids.</p></li>
<li><p>Label growth during data collection created a moving target:
adding papers surfaced new subfields/methods. A practical “scope freeze”
was applied to keep the label space stable for training and evaluation,
with ontology clean-ups deferred to future work.</p></li>
<li><p>Explainability at scale (LIME) was memory-fragile in Colab; it
was run locally to extract qualitative insights and to design a simple
rule-based fallback for very low-confidence cases.</p></li>
</ul>
</section>
</body>
</html>
