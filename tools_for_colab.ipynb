{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e1f8c34-d491-485f-975f-f643c5047524",
   "metadata": {},
   "source": [
    "# 1. Data Loading & Preprocessing\n",
    "\n",
    "In this section, I describe how I prepared the dataset before modeling. The aim was to ensure the text data is clean, consistent, and suitable for use with various NLP models. I first filtered out incomplete records and then applied text normalisation using spaCy and NLTK. Lastly, I encoded the target variable (methodology) into a format compatible with machine learning models. These preprocessing steps are essential to ensure reliable model performance and valid evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa320d05-3978-4909-9c90-1ef304a60da3",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47c189a6-7d5e-4dea-be7b-3246656d188d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Alvin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\Alvin\\.conda\\envs\\FYP\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Core Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import gc\n",
    "import csv\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# NLP Libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import download\n",
    "import spacy\n",
    "download('stopwords')  \n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Transformers & Torch\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification\n",
    ")\n",
    "\n",
    "# Hugging Face Datasets\n",
    "from datasets import Dataset, DatasetDict, ClassLabel\n",
    "\n",
    "# LIME for Model Explainability\n",
    "!pip install -q lime\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "# Web Tools for ArXiv Harvesting\n",
    "import requests\n",
    "import feedparser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47789ca-08f1-46cc-b844-1dc6d7eaba5a",
   "metadata": {},
   "source": [
    "## 1.1 Dataset Loading and Filtering\n",
    "\n",
    "To begin, I loaded the dataset Ver5dataset_three_final.csv using Pandas. Since not all records have complete data, I filtered the DataFrame to retain only rows where the text_excerpt column is not null. This ensures that downstream tasks like tokenisation and classification are not disrupted by missing or malformed text entries. I also created a copy of the DataFrame to avoid unintended side effects during subsequent transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14fae7f2-f242-482d-9f47-addfe7230130",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Ver5dataset_three_final.csv\")\n",
    "df = df[df['text_excerpt'].notnull()].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed30f79-b36f-41a0-902b-dc96634982e1",
   "metadata": {},
   "source": [
    "## 1.2 Text Preprocessing\n",
    "\n",
    "Here, I implemented a preprocessing function using both spaCy and NLTK. First, I downloaded the NLTK stopword list and loaded the en_core_web_sm spaCy model. Then, I created a function that performs the following operations: lowercasing the text, removing punctuation, tokenising the input using spaCy, lemmatising each token, and optionally removing stopwords. The function helps standardise the text, reduce vocabulary noise, and focus the model on meaningful word stems. I applied this function twice to generate two different processed versions of the text: one with stopwords removed (processed_no_stopwords) and one that retains stopwords (processed_with_stopwords). This allows flexibility during model experimentation later on, as different models may perform better with or without stopwords included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8d6e429-b4e2-4eae-96ee-48ffcfb841e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download stopwords and spaCy model\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text, remove_stopwords=True):\n",
    "    text = text.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "    doc = nlp(text)\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_alpha:\n",
    "            if remove_stopwords and token.text in stop_words:\n",
    "                continue\n",
    "            tokens.append(token.lemma_)\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Apply preprocessing \n",
    "df['processed_no_stopwords'] = df['text_excerpt'].apply(lambda x: preprocess_text(str(x), remove_stopwords=True))\n",
    "df['processed_with_stopwords'] = df['text_excerpt'].apply(lambda x: preprocess_text(str(x), remove_stopwords=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b02a64c-8044-4691-9ed9-b48b6ad1d17b",
   "metadata": {},
   "source": [
    "## 1.3 Label Encoding for Methodology Classification\n",
    "\n",
    "This block prepares the dataset for supervised classification by focusing on the methodology column, which is my target label. I removed rows with missing methodology values to ensure valid training examples, then reset the DataFrame index. I preserved the original indices using a new column called orig_idx, which helps trace predictions back to the original raw examples later (e.g., during error analysis or explainability). Finally, I used scikit-learnâ€™s LabelEncoder to convert each unique methodology class into a numerical label. This transformation is required for the model to compute loss and evaluate predictions during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55c61f39-5bad-4dca-9c50-839ec457d041",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = df[df['methodology'].notnull()].copy().reset_index()\n",
    "df_m.rename(columns={'index': 'orig_idx'}, inplace=True)\n",
    "\n",
    "le_m = LabelEncoder()\n",
    "df_m['label'] = le_m.fit_transform(df_m['methodology'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ec058c-6632-4a9e-ba0b-462b1e0916e5",
   "metadata": {},
   "source": [
    "# 2. Token Length Distribution and Model Loading for LIME Explainability\n",
    "\n",
    "As part of my investigation into model behavior and explainability, I conducted an analysis using the SciBERT model trained on the methodology label. The goal was to inspect token length distributions, ensure compatibility with model input requirements, and apply LIME (Local Interpretable Model-agnostic Explanations) for interpretability insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed60124-f6a9-461b-a008-bc4646ea765c",
   "metadata": {},
   "source": [
    "## 2.1 Model Loading for LIME\n",
    "\n",
    "To apply LIME explanations, I reloaded the trained SciBERT model using PyTorch. I used the same tokeniser (allenai/scibert_scivocab_uncased) and reloaded the saved model weights (scibert_methodology_best_state.pt). I ensured the model was set to evaluation mode to prevent dropout or training-time behaviors, which could otherwise interfere with consistent prediction outputs required by LIME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d280e5a9-3eca-4bbd-80c8-42a320032351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alvin\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(31090, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load label encoder and tokeniser \n",
    "model_name = \"allenai/scibert_scivocab_uncased\"\n",
    "model_m = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(le_m.classes_)\n",
    ")\n",
    "\n",
    "# Load saved weights\n",
    "model_m.load_state_dict(torch.load(\"scibert_methodology_best_state.pt\"))\n",
    "model_m.eval()  # model is in eval mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157d247d-4269-477b-abb3-e8a99759c433",
   "metadata": {},
   "source": [
    "## 2.2 Token Length Distribution Analysis\n",
    "\n",
    "Before fine-tuning or interpreting model predictions, it was important to analyse the tokenized sequence lengths generated by the SciBERT tokeniser. Using the preprocessed column processed_with_stopwords (which retains full context), I calculated the distribution of token lengths across the dataset without truncation.\n",
    "\n",
    "The histogram and statistical summary (see image) show that the majority of samples fall well below the 256-token threshold, with only 9.48% exceeding 256 tokens and 0.02% exceeding the 512-token maximum allowed by BERT-based models. Based on this, I decided that a maximum sequence length of 256 tokens would be a suitable and efficient truncation threshold for downstream model training and LIME explanations. This decision was used consistently across all extended configurations (C1â€“C3, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c85e853-1e75-43d2-9654-d5de2cda9470",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alvin\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 5582\n",
      "count    5582.000000\n",
      "mean      166.563776\n",
      "std        64.506522\n",
      "min        11.000000\n",
      "50%       166.000000\n",
      "75%       213.000000\n",
      "90%       254.900000\n",
      "95%       275.000000\n",
      "99%       303.000000\n",
      "max       596.000000\n",
      "dtype: float64\n",
      "\n",
      "% > 256 tokens: 9.48%\n",
      "% > 512 tokens: 0.02%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"allenai/scibert_scivocab_uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "texts = df['processed_with_stopwords'].astype(str).tolist()\n",
    "\n",
    "def lengths_in_batches(texts, batch_size=128):\n",
    "    lens = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        enc = tokenizer(batch, add_special_tokens=True, truncation=False)\n",
    "        # len of each input_ids sequence\n",
    "        lens.extend([len(ids) for ids in enc[\"input_ids\"]])\n",
    "    return np.array(lens, dtype=np.int32)\n",
    "\n",
    "lens = lengths_in_batches(texts, batch_size=128)\n",
    "\n",
    "print(\"Count:\", len(lens))\n",
    "print(pd.Series(lens).describe(percentiles=[0.5, 0.75, 0.9, 0.95, 0.99]))\n",
    "pct_over_256 = (lens > 256).mean() * 100\n",
    "pct_over_512 = (lens > 512).mean() * 100\n",
    "print(f\"\\n% > 256 tokens: {pct_over_256:.2f}%\")\n",
    "print(f\"% > 512 tokens: {pct_over_512:.2f}%\")\n",
    "\n",
    "# Histogram \n",
    "plt.figure()\n",
    "plt.hist(lens, bins=50)\n",
    "plt.title(\"Token length distribution (SciBERT tokenizer, no truncation)\")\n",
    "plt.xlabel(\"tokens\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28846441-2bc7-4482-bd58-0d2418beaaa8",
   "metadata": {},
   "source": [
    "## 2.3 Tokenisation\n",
    "\n",
    "I constructed a Hugging Face Dataset using only the samples with valid methodology labels. This dataset was then tokenised using the SciBERT tokeniser with truncation. I performed a stratified train-test split (80/20) using train_test_split to maintain class distribution, ensuring representative samples were selected for LIME interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "247ee9c7-0a7d-4948-a16c-0a07d6d8aa3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Casting the dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5582/5582 [00:00<00:00, 107282.11 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_m = Dataset.from_pandas(df_m[['processed_with_stopwords', 'label', 'orig_idx']])\n",
    "dataset_m = dataset_m.cast_column(\"label\", ClassLabel(num_classes=len(le_m.classes_), names=list(le_m.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dec8b9e9-5553-4bb9-96a7-f4ed5dad6ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alvin\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Map:   0%|                                                                             | 0/5582 [00:00<?, ? examples/s]Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5582/5582 [00:00<00:00, 7718.60 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"processed_with_stopwords\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_m = dataset_m.map(tokenize_function, batched=True)\n",
    "\n",
    "split_m = tokenized_m.train_test_split(test_size=0.2, stratify_by_column=\"label\", seed=42)\n",
    "train_m = split_m[\"train\"]\n",
    "test_m = split_m[\"test\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d0018a-777b-40f3-b63a-d773ff64c5f8",
   "metadata": {},
   "source": [
    "## 2.4 Applying LIME for Interpretability\n",
    "\n",
    "I employed LIME Text Explainer, which treats the model as a black box and perturbs the input text to learn the most influential tokens for prediction. I randomly selected three samples from the test set for analysis. For each sample, I:\n",
    "\n",
    "- Retrieved the original text and true label.\n",
    "- Ran LIME to identify the top 10 features (words) influencing the model's prediction.\n",
    "- Printed the predicted and actual labels for comparison.\n",
    "- Saved the HTML visualisation from LIME, which shows highlighted words and their contribution toward the predicted class.\n",
    "\n",
    "This helped me understand what textual patterns the model relies on, especially within each of the four methodology classes. This interpretability check was critical in validating the model's decision logic and guided further steps like rule-based classification using LIME-derived keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df70a40c-8ae5-4261-aeb9-7e4ef7367bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sample 302 ===\n",
      "True Label     : Theoretical / Conceptual\n",
      "Predicted Label: Theoretical / Conceptual\n",
      "[Saved] lime_methodology_sample_302.html\n"
     ]
    }
   ],
   "source": [
    "# Class names for LIME\n",
    "class_names = le_m.classes_.tolist()\n",
    "\n",
    "# Prediction wrapper\n",
    "def predict_proba(texts):\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(model_m.device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        logits = model_m(**inputs).logits\n",
    "        probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# LIME explainer\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "# Pick random test samples\n",
    "sample_indices = random.sample(range(len(test_m)), 3)\n",
    "\n",
    "for idx in sample_indices:\n",
    "    # Get original index from test set\n",
    "    orig_idx = test_m[idx]['orig_idx']\n",
    "    sample_text = df_m.loc[orig_idx]['text_excerpt']\n",
    "    true_label = df_m.loc[orig_idx]['methodology']\n",
    "\n",
    "    # Run LIME\n",
    "    exp = explainer.explain_instance(sample_text, predict_proba, num_features=10, top_labels=1, num_samples=1000)\n",
    "    pred_label_idx = exp.top_labels[0]\n",
    "    pred_label = class_names[pred_label_idx]\n",
    "\n",
    "    # Display\n",
    "    print(f\"\\n=== Sample {idx} ===\")\n",
    "    print(f\"True Label     : {true_label}\")\n",
    "    print(f\"Predicted Label: {pred_label}\")\n",
    "    exp.save_to_file(f\"lime_methodology_sample_{idx}.html\")\n",
    "    print(f\"[Saved] lime_methodology_sample_{idx}.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3305eb7-e795-420d-b179-658549716814",
   "metadata": {},
   "source": [
    "# 3. LIME Keyword Discovery, Paper Harvesting, and Rule-Based Classification\n",
    "\n",
    "At this stage of the project, I extended my analysis beyond model evaluation by building interpretable explanations, collecting real-world data, and applying a rule-based classification system. These were implemented in three parts: analyzing feature importance using LIME, harvesting academic papers from arXiv, and building a simple rule-based classifier using methodology-specific keywords."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcc4897-d8a2-4b6b-82fc-6ad418cd05ff",
   "metadata": {},
   "source": [
    "## 3.1 Extracting Important Keywords Using LIME\n",
    "\n",
    "I performed a local interpretability analysis of my fine-tuned methodology classification model using the LIME (Local Interpretable Model-Agnostic Explanations) framework. This allowed me to uncover which keywords my model was relying on for its predictions.\n",
    "\n",
    "First, I defined a fixed number of correctly predicted test samples (N=50) from the validation set. These samples were selected by passing individual inputs through the fine-tuned SciBERT model (model_m) and matching the predicted label with the true label.\n",
    "\n",
    "Then, I applied LIME to each of these samples using the predict_proba function that wraps the model. LIME perturbs each input and fits a simple surrogate model locally to highlight important features (in this case, words) that influenced the model's decision. I extracted the top 10 most important keywords (NUM_FEATURES) from each sample and tracked both:\n",
    "- How often each keyword appeared across samples per methodology label.\n",
    "- The cumulative importance weight (magnitude of influence) for each keyword.\n",
    "\n",
    "The output summarises the top influential keywords for each methodology class. This process provided an interpretable layer on top of my model, helping me identify model-reliant linguistic features like \"prototype\", \"interview\", or \"conceptual\" that align with each research methodology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0dd6802-0ebe-44d9-8273-e28921c3139f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LIME on 200 correctly predicted samples...\n",
      "[1/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[2/200] Processed sample for 'Design Science / System Design'\n",
      "[3/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[4/200] Processed sample for 'Design Science / System Design'\n",
      "[5/200] Processed sample for 'Design Science / System Design'\n",
      "[6/200] Processed sample for 'Design Science / System Design'\n",
      "[7/200] Processed sample for 'Design Science / System Design'\n",
      "[8/200] Processed sample for 'Design Science / System Design'\n",
      "[9/200] Processed sample for 'Design Science / System Design'\n",
      "[10/200] Processed sample for 'Design Science / System Design'\n",
      "[11/200] Processed sample for 'Design Science / System Design'\n",
      "[12/200] Processed sample for 'Design Science / System Design'\n",
      "[13/200] Processed sample for 'Design Science / System Design'\n",
      "[14/200] Processed sample for 'Design Science / System Design'\n",
      "[15/200] Processed sample for 'Design Science / System Design'\n",
      "[16/200] Processed sample for 'Design Science / System Design'\n",
      "[17/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[18/200] Processed sample for 'Design Science / System Design'\n",
      "[19/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[20/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[21/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[22/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[23/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[24/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[25/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[26/200] Processed sample for 'Design Science / System Design'\n",
      "[27/200] Processed sample for 'Design Science / System Design'\n",
      "[28/200] Processed sample for 'Mixed Methods'\n",
      "[29/200] Processed sample for 'Mixed Methods'\n",
      "[30/200] Processed sample for 'Design Science / System Design'\n",
      "[31/200] Processed sample for 'Design Science / System Design'\n",
      "[32/200] Processed sample for 'Design Science / System Design'\n",
      "[33/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[34/200] Processed sample for 'Design Science / System Design'\n",
      "[35/200] Processed sample for 'Design Science / System Design'\n",
      "[36/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[37/200] Processed sample for 'Design Science / System Design'\n",
      "[38/200] Processed sample for 'Design Science / System Design'\n",
      "[39/200] Processed sample for 'Design Science / System Design'\n",
      "[40/200] Processed sample for 'Design Science / System Design'\n",
      "[41/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[42/200] Processed sample for 'Design Science / System Design'\n",
      "[43/200] Processed sample for 'Design Science / System Design'\n",
      "[44/200] Processed sample for 'Design Science / System Design'\n",
      "[45/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[46/200] Processed sample for 'Design Science / System Design'\n",
      "[47/200] Processed sample for 'Design Science / System Design'\n",
      "[48/200] Processed sample for 'Design Science / System Design'\n",
      "[49/200] Processed sample for 'Design Science / System Design'\n",
      "[50/200] Processed sample for 'Design Science / System Design'\n",
      "[51/200] Processed sample for 'Design Science / System Design'\n",
      "[52/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[53/200] Processed sample for 'Design Science / System Design'\n",
      "[54/200] Processed sample for 'Design Science / System Design'\n",
      "[55/200] Processed sample for 'Design Science / System Design'\n",
      "[56/200] Processed sample for 'Design Science / System Design'\n",
      "[57/200] Processed sample for 'Design Science / System Design'\n",
      "[58/200] Processed sample for 'Design Science / System Design'\n",
      "[59/200] Processed sample for 'Design Science / System Design'\n",
      "[60/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[61/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[62/200] Processed sample for 'Design Science / System Design'\n",
      "[63/200] Processed sample for 'Design Science / System Design'\n",
      "[64/200] Processed sample for 'Design Science / System Design'\n",
      "[65/200] Processed sample for 'Design Science / System Design'\n",
      "[66/200] Processed sample for 'Design Science / System Design'\n",
      "[67/200] Processed sample for 'Design Science / System Design'\n",
      "[68/200] Processed sample for 'Design Science / System Design'\n",
      "[69/200] Processed sample for 'Design Science / System Design'\n",
      "[70/200] Processed sample for 'Design Science / System Design'\n",
      "[71/200] Processed sample for 'Design Science / System Design'\n",
      "[72/200] Processed sample for 'Mixed Methods'\n",
      "[73/200] Processed sample for 'Design Science / System Design'\n",
      "[74/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[75/200] Processed sample for 'Design Science / System Design'\n",
      "[76/200] Processed sample for 'Design Science / System Design'\n",
      "[77/200] Processed sample for 'Design Science / System Design'\n",
      "[78/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[79/200] Processed sample for 'Design Science / System Design'\n",
      "[80/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[81/200] Processed sample for 'Design Science / System Design'\n",
      "[82/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[83/200] Processed sample for 'Design Science / System Design'\n",
      "[84/200] Processed sample for 'Design Science / System Design'\n",
      "[85/200] Processed sample for 'Design Science / System Design'\n",
      "[86/200] Processed sample for 'Design Science / System Design'\n",
      "[87/200] Processed sample for 'Design Science / System Design'\n",
      "[88/200] Processed sample for 'Design Science / System Design'\n",
      "[89/200] Processed sample for 'Design Science / System Design'\n",
      "[90/200] Processed sample for 'Design Science / System Design'\n",
      "[91/200] Processed sample for 'Design Science / System Design'\n",
      "[92/200] Processed sample for 'Design Science / System Design'\n",
      "[93/200] Processed sample for 'Design Science / System Design'\n",
      "[94/200] Processed sample for 'Design Science / System Design'\n",
      "[95/200] Processed sample for 'Design Science / System Design'\n",
      "[96/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[97/200] Processed sample for 'Design Science / System Design'\n",
      "[98/200] Processed sample for 'Design Science / System Design'\n",
      "[99/200] Processed sample for 'Design Science / System Design'\n",
      "[100/200] Processed sample for 'Design Science / System Design'\n",
      "[101/200] Processed sample for 'Design Science / System Design'\n",
      "[102/200] Processed sample for 'Design Science / System Design'\n",
      "[103/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[104/200] Processed sample for 'Design Science / System Design'\n",
      "[105/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[106/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[107/200] Processed sample for 'Design Science / System Design'\n",
      "[108/200] Processed sample for 'Design Science / System Design'\n",
      "[109/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[110/200] Processed sample for 'Design Science / System Design'\n",
      "[111/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[112/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[113/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[114/200] Processed sample for 'Design Science / System Design'\n",
      "[115/200] Processed sample for 'Design Science / System Design'\n",
      "[116/200] Processed sample for 'Design Science / System Design'\n",
      "[117/200] Processed sample for 'Design Science / System Design'\n",
      "[118/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[119/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[120/200] Processed sample for 'Design Science / System Design'\n",
      "[121/200] Processed sample for 'Design Science / System Design'\n",
      "[122/200] Processed sample for 'Design Science / System Design'\n",
      "[123/200] Processed sample for 'Design Science / System Design'\n",
      "[124/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[125/200] Processed sample for 'Design Science / System Design'\n",
      "[126/200] Processed sample for 'Mixed Methods'\n",
      "[127/200] Processed sample for 'Design Science / System Design'\n",
      "[128/200] Processed sample for 'Mixed Methods'\n",
      "[129/200] Processed sample for 'Design Science / System Design'\n",
      "[130/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[131/200] Processed sample for 'Mixed Methods'\n",
      "[132/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[133/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[134/200] Processed sample for 'Design Science / System Design'\n",
      "[135/200] Processed sample for 'Design Science / System Design'\n",
      "[136/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[137/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[138/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[139/200] Processed sample for 'Design Science / System Design'\n",
      "[140/200] Processed sample for 'Design Science / System Design'\n",
      "[141/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[142/200] Processed sample for 'Design Science / System Design'\n",
      "[143/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[144/200] Processed sample for 'Design Science / System Design'\n",
      "[145/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[146/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[147/200] Processed sample for 'Design Science / System Design'\n",
      "[148/200] Processed sample for 'Design Science / System Design'\n",
      "[149/200] Processed sample for 'Design Science / System Design'\n",
      "[150/200] Processed sample for 'Mixed Methods'\n",
      "[151/200] Processed sample for 'Design Science / System Design'\n",
      "[152/200] Processed sample for 'Design Science / System Design'\n",
      "[153/200] Processed sample for 'Design Science / System Design'\n",
      "[154/200] Processed sample for 'Mixed Methods'\n",
      "[155/200] Processed sample for 'Design Science / System Design'\n",
      "[156/200] Processed sample for 'Design Science / System Design'\n",
      "[157/200] Processed sample for 'Design Science / System Design'\n",
      "[158/200] Processed sample for 'Design Science / System Design'\n",
      "[159/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[160/200] Processed sample for 'Design Science / System Design'\n",
      "[161/200] Processed sample for 'Design Science / System Design'\n",
      "[162/200] Processed sample for 'Design Science / System Design'\n",
      "[163/200] Processed sample for 'Design Science / System Design'\n",
      "[164/200] Processed sample for 'Design Science / System Design'\n",
      "[165/200] Processed sample for 'Design Science / System Design'\n",
      "[166/200] Processed sample for 'Design Science / System Design'\n",
      "[167/200] Processed sample for 'Design Science / System Design'\n",
      "[168/200] Processed sample for 'Design Science / System Design'\n",
      "[169/200] Processed sample for 'Design Science / System Design'\n",
      "[170/200] Processed sample for 'Design Science / System Design'\n",
      "[171/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[172/200] Processed sample for 'Design Science / System Design'\n",
      "[173/200] Processed sample for 'Design Science / System Design'\n",
      "[174/200] Processed sample for 'Design Science / System Design'\n",
      "[175/200] Processed sample for 'Design Science / System Design'\n",
      "[176/200] Processed sample for 'Design Science / System Design'\n",
      "[177/200] Processed sample for 'Design Science / System Design'\n",
      "[178/200] Processed sample for 'Design Science / System Design'\n",
      "[179/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[180/200] Processed sample for 'Design Science / System Design'\n",
      "[181/200] Processed sample for 'Design Science / System Design'\n",
      "[182/200] Processed sample for 'Mixed Methods'\n",
      "[183/200] Processed sample for 'Design Science / System Design'\n",
      "[184/200] Processed sample for 'Design Science / System Design'\n",
      "[185/200] Processed sample for 'Design Science / System Design'\n",
      "[186/200] Processed sample for 'Design Science / System Design'\n",
      "[187/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[188/200] Processed sample for 'Design Science / System Design'\n",
      "[189/200] Processed sample for 'Design Science / System Design'\n",
      "[190/200] Processed sample for 'Design Science / System Design'\n",
      "[191/200] Processed sample for 'Design Science / System Design'\n",
      "[192/200] Processed sample for 'Design Science / System Design'\n",
      "[193/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[194/200] Processed sample for 'Design Science / System Design'\n",
      "[195/200] Processed sample for 'Design Science / System Design'\n",
      "[196/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[197/200] Processed sample for 'Design Science / System Design'\n",
      "[198/200] Processed sample for 'Design Science / System Design'\n",
      "[199/200] Processed sample for 'Theoretical / Conceptual'\n",
      "[200/200] Processed sample for 'Theoretical / Conceptual'\n",
      "\n",
      "=== Top Keywords Per Methodology ===\n",
      "\n",
      "Design Science / System Design:\n",
      "  model                (samples: 33, weight: 7.3752)\n",
      "  framework            (samples: 31, weight: 5.3606)\n",
      "  propose              (samples: 29, weight: 6.3479)\n",
      "  performance          (samples: 26, weight: 4.3202)\n",
      "  proposed             (samples: 17, weight: 2.4930)\n",
      "  algorithm            (samples: 13, weight: 2.0385)\n",
      "  training             (samples: 12, weight: 1.1271)\n",
      "  system               (samples: 11, weight: 1.1908)\n",
      "  method               (samples: 11, weight: 2.1063)\n",
      "  experiments          (samples: 11, weight: 0.9749)\n",
      "\n",
      "Mixed Methods:\n",
      "  framework            (samples:  3, weight: 2.0980)\n",
      "  statistical          (samples:  3, weight: 0.6815)\n",
      "  models               (samples:  2, weight: 0.4358)\n",
      "  empirical            (samples:  2, weight: 1.1354)\n",
      "  findings             (samples:  2, weight: 0.6194)\n",
      "  require              (samples:  1, weight: 0.1119)\n",
      "  sizes                (samples:  1, weight: 0.0735)\n",
      "  leverages            (samples:  1, weight: 0.0538)\n",
      "  link                 (samples:  1, weight: 0.0382)\n",
      "  meaningful           (samples:  1, weight: 0.0122)\n",
      "\n",
      "Qualitative:\n",
      "\n",
      "Theoretical / Conceptual:\n",
      "  theory               (samples:  9, weight: 4.2601)\n",
      "  prove                (samples:  7, weight: 0.1977)\n",
      "  framework            (samples:  7, weight: 1.7021)\n",
      "  derive               (samples:  6, weight: 2.2051)\n",
      "  concept              (samples:  4, weight: 1.4898)\n",
      "  theoretical          (samples:  4, weight: 2.3135)\n",
      "  results              (samples:  4, weight: 0.1574)\n",
      "  construct            (samples:  4, weight: 0.6814)\n",
      "  show                 (samples:  4, weight: 0.0983)\n",
      "  theories             (samples:  3, weight: 0.9170)\n"
     ]
    }
   ],
   "source": [
    "# CONFIGURATION \n",
    "N = 200  # Number of correctly predicted samples to analyze\n",
    "NUM_FEATURES = 10\n",
    "NUM_PERTURBATIONS = 300\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "punct_table = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "# Data Structures \n",
    "keyword_weight_counter = defaultdict(Counter)  # total importance weight\n",
    "keyword_sample_counter = defaultdict(Counter)  # count of how many samples keyword appeared in\n",
    "correct_samples = []\n",
    "\n",
    "# Identify Correct Predictions\n",
    "for i in range(len(test_m)):\n",
    "    orig_idx = test_m[i]['orig_idx']\n",
    "    sample_text = df_m.loc[orig_idx]['text_excerpt']\n",
    "    true_label = df_m.loc[orig_idx]['methodology']\n",
    "    \n",
    "    # Predict label\n",
    "    inputs = tokenizer(sample_text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    inputs = {k: v.to(model_m.device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        logits = model_m(**inputs).logits\n",
    "        pred_label_idx = torch.argmax(logits, dim=1).item()\n",
    "    pred_label = class_names[pred_label_idx]\n",
    "\n",
    "    if pred_label == true_label:\n",
    "        correct_samples.append((sample_text, true_label))\n",
    "    if len(correct_samples) >= N:\n",
    "        break\n",
    "\n",
    "print(f\"Running LIME on {len(correct_samples)} correctly predicted samples...\")\n",
    "\n",
    "# Run LIME and extract keywords\n",
    "for idx, (sample_text, label) in enumerate(correct_samples):\n",
    "    try:\n",
    "        exp = explainer.explain_instance(\n",
    "            sample_text,\n",
    "            predict_proba,\n",
    "            num_features=NUM_FEATURES,\n",
    "            top_labels=1,\n",
    "            num_samples=NUM_PERTURBATIONS\n",
    "        )\n",
    "        label_idx = class_names.index(label)\n",
    "        keywords = exp.as_list(label=label_idx)\n",
    "\n",
    "        seen_words = set()\n",
    "        for word, weight in keywords:\n",
    "            # Pre-clean word\n",
    "            clean_word = word.lower().translate(punct_table).strip()\n",
    "            if not clean_word or clean_word in stop_words or not clean_word.isalpha():\n",
    "                continue\n",
    "            keyword_weight_counter[label][clean_word] += abs(weight)\n",
    "            if clean_word not in seen_words:\n",
    "                keyword_sample_counter[label][clean_word] += 1\n",
    "                seen_words.add(clean_word)\n",
    "\n",
    "        print(f\"[{idx+1}/{N}] Processed sample for '{label}'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing sample {idx}: {e}\")\n",
    "\n",
    "    # Free memory\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "# Display Top Keywords\n",
    "print(\"\\n=== Top Keywords Per Methodology ===\")\n",
    "for label in class_names:\n",
    "    print(f\"\\n{label}:\")\n",
    "    words = keyword_sample_counter[label].most_common()\n",
    "    for word, sample_count in words[:10]:\n",
    "        total_weight = keyword_weight_counter[label][word]\n",
    "        print(f\"  {word:20s} (samples: {sample_count:2d}, weight: {total_weight:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5a2642-6256-4426-bdc4-a33e585dd12d",
   "metadata": {},
   "source": [
    "## 3.2 Collection of papers (ARXIV)\n",
    "\n",
    "This is a custom-built paper collection tool that harvested a large number of research papers from the arXiv\n",
    " API, with a focus on relevant categories (e.g., cs, stat, math, econ, etc.).\n",
    "\n",
    "I used the official arXiv API to query papers in batches (BATCH_SIZE = 100), across eight disciplines, with up to 5,000 results per category.\n",
    "\n",
    "This script resulted in a dataset of academic abstracts that were categorised by field and subfield. The final dataset was saved as arxiv_bulk_download.csv. This dataset serves as an unlabeled input for further experimentation and testing of external generalisability of the classifiers I trained on manually labeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe58f2e4-6961-4823-a7d1-af3b798c5cd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting category: cs\n",
      "  Fetching cs results 0 to 100...\n",
      "  Batch done. New entries: 100, Total: 100\n",
      "  Fetching cs results 100 to 200...\n",
      "  No results returned.\n",
      "\n",
      "Starting category: math\n",
      "  Fetching math results 0 to 100...\n",
      "  Batch done. New entries: 94, Total: 194\n",
      "  Fetching math results 100 to 200...\n",
      "  No results returned.\n",
      "\n",
      "Starting category: stat\n",
      "  Fetching stat results 0 to 100...\n",
      "  Batch done. New entries: 89, Total: 283\n",
      "  Fetching stat results 100 to 200...\n",
      "  Batch done. New entries: 100, Total: 383\n",
      "  Fetching stat results 200 to 300...\n",
      "  Batch done. New entries: 100, Total: 483\n",
      "  Fetching stat results 300 to 400...\n",
      "  Batch done. New entries: 100, Total: 583\n",
      "  Fetching stat results 400 to 500...\n",
      "  Batch done. New entries: 100, Total: 683\n",
      "  Fetching stat results 500 to 600...\n",
      "  Batch done. New entries: 100, Total: 783\n",
      "  Fetching stat results 600 to 700...\n",
      "  Batch done. New entries: 100, Total: 883\n",
      "  Fetching stat results 700 to 800...\n",
      "  Batch done. New entries: 100, Total: 983\n",
      "  Fetching stat results 800 to 900...\n",
      "  Batch done. New entries: 100, Total: 1083\n",
      "  Fetching stat results 900 to 1000...\n",
      "  Batch done. New entries: 100, Total: 1183\n",
      "  Fetching stat results 1000 to 1100...\n",
      "  No results returned.\n",
      "\n",
      "Starting category: econ\n",
      "  Fetching econ results 0 to 100...\n",
      "  Batch done. New entries: 78, Total: 1261\n",
      "  Fetching econ results 100 to 200...\n",
      "  Batch done. New entries: 85, Total: 1346\n",
      "  Fetching econ results 200 to 300...\n",
      "  Batch done. New entries: 96, Total: 1442\n",
      "  Fetching econ results 300 to 400...\n",
      "  Batch done. New entries: 100, Total: 1542\n",
      "  Fetching econ results 400 to 500...\n",
      "  Batch done. New entries: 100, Total: 1642\n",
      "  Fetching econ results 500 to 600...\n",
      "  Batch done. New entries: 100, Total: 1742\n",
      "  Fetching econ results 600 to 700...\n",
      "  Batch done. New entries: 100, Total: 1842\n",
      "  Fetching econ results 700 to 800...\n",
      "  Batch done. New entries: 100, Total: 1942\n",
      "  Fetching econ results 800 to 900...\n",
      "  No results returned.\n",
      "\n",
      "Starting category: q-bio\n",
      "  Fetching q-bio results 0 to 100...\n",
      "  Batch done. New entries: 88, Total: 2030\n",
      "  Fetching q-bio results 100 to 200...\n",
      "  Batch done. New entries: 90, Total: 2120\n",
      "  Fetching q-bio results 200 to 300...\n",
      "  Batch done. New entries: 90, Total: 2210\n",
      "  Fetching q-bio results 300 to 400...\n",
      "  Batch done. New entries: 93, Total: 2303\n",
      "  Fetching q-bio results 400 to 500...\n",
      "  Batch done. New entries: 99, Total: 2402\n",
      "  Fetching q-bio results 500 to 600...\n",
      "  Batch done. New entries: 100, Total: 2502\n",
      "  Fetching q-bio results 600 to 700...\n",
      "  Batch done. New entries: 100, Total: 2602\n",
      "  Fetching q-bio results 700 to 800...\n",
      "  Batch done. New entries: 100, Total: 2702\n",
      "  Fetching q-bio results 800 to 900...\n",
      "  No results returned.\n",
      "\n",
      "Starting category: physics\n",
      "  Fetching physics results 0 to 100...\n",
      "  Batch done. New entries: 92, Total: 2794\n",
      "  Fetching physics results 100 to 200...\n",
      "  Batch done. New entries: 95, Total: 2889\n",
      "  Fetching physics results 200 to 300...\n",
      "  No results returned.\n",
      "\n",
      "Starting category: eess\n",
      "  Fetching eess results 0 to 100...\n",
      "  Batch done. New entries: 85, Total: 2974\n",
      "  Fetching eess results 100 to 200...\n",
      "  Batch done. New entries: 94, Total: 3068\n",
      "  Fetching eess results 200 to 300...\n",
      "  Batch done. New entries: 94, Total: 3162\n",
      "  Fetching eess results 300 to 400...\n",
      "  Batch done. New entries: 95, Total: 3257\n",
      "  Fetching eess results 400 to 500...\n",
      "  Batch done. New entries: 97, Total: 3354\n",
      "  Fetching eess results 500 to 600...\n",
      "  Batch done. New entries: 92, Total: 3446\n",
      "  Fetching eess results 600 to 700...\n",
      "  Batch done. New entries: 99, Total: 3545\n",
      "  Fetching eess results 700 to 800...\n",
      "  Batch done. New entries: 97, Total: 3642\n",
      "  Fetching eess results 800 to 900...\n",
      "  Batch done. New entries: 96, Total: 3738\n",
      "  Fetching eess results 900 to 1000...\n",
      "  Batch done. New entries: 95, Total: 3833\n",
      "  Fetching eess results 1000 to 1100...\n",
      "  Batch done. New entries: 95, Total: 3928\n",
      "  Fetching eess results 1100 to 1200...\n",
      "  Batch done. New entries: 97, Total: 4025\n",
      "  Fetching eess results 1200 to 1300...\n",
      "  Batch done. New entries: 94, Total: 4119\n",
      "  Fetching eess results 1300 to 1400...\n",
      "  Batch done. New entries: 94, Total: 4213\n",
      "  Fetching eess results 1400 to 1500...\n",
      "  Batch done. New entries: 97, Total: 4310\n",
      "  Fetching eess results 1500 to 1600...\n",
      "  Batch done. New entries: 98, Total: 4408\n",
      "  Fetching eess results 1600 to 1700...\n",
      "  No results returned.\n",
      "\n",
      "Starting category: astro-ph\n",
      "  Fetching astro-ph results 0 to 100...\n",
      "  Batch done. New entries: 97, Total: 4505\n",
      "  Fetching astro-ph results 100 to 200...\n",
      "  Batch done. New entries: 94, Total: 4599\n",
      "  Fetching astro-ph results 200 to 300...\n",
      "  No results returned.\n",
      "\n",
      "Done. 4599 unique papers saved to: arxiv_bulk_download.csv\n"
     ]
    }
   ],
   "source": [
    "# CONFIG\n",
    "OUTPUT_FILE = \"arxiv_bulk_download.csv\"\n",
    "CATEGORY_PREFIXES = [\n",
    "    \"cs\", \"math\", \"stat\", \"econ\", \"q-bio\", \"physics\", \"eess\", \"astro-ph\"\n",
    "]\n",
    "BATCH_SIZE = 100\n",
    "MAX_RESULTS_PER_CATEGORY = 5000\n",
    "SLEEP_TIME = 3  # seconds between API calls\n",
    "\n",
    "# Label Maps\n",
    "priority_subfield_map = {\n",
    "    \"cs.CL\": \"Natural Language Processing\",\n",
    "    \"cs.LG\": \"Machine Learning\",\n",
    "    \"cs.HC\": \"Human Computer Interaction\",\n",
    "    \"cs.SE\": \"Software Engineering\",\n",
    "    \"cs.CY\": \"Information Systems\",\n",
    "    \"cs.DL\": \"Computing Education\",\n",
    "    \"cs.ET\": \"Education Systems\",\n",
    "    \"math.ST\": \"Statistics\",\n",
    "    \"econ.EM\": \"Econometrics\",\n",
    "    \"stat.ML\": \"Statistical Machine Learning\",\n",
    "    \"q-bio.NC\": \"Neural and Cognitive Modeling\",\n",
    "}\n",
    "\n",
    "discipline_map = {\n",
    "    \"cs\": \"Computer Science\",\n",
    "    \"math\": \"Mathematics\",\n",
    "    \"stat\": \"Statistics\",\n",
    "    \"q-bio\": \"Quantitative Biology\",\n",
    "    \"econ\": \"Economics\",\n",
    "    \"eess\": \"Electrical Engineering and Systems Science\",\n",
    "    \"physics\": \"Physics\",\n",
    "    \"astro-ph\": \"Astrophysics\",\n",
    "}\n",
    "\n",
    "def get_discipline(cat):\n",
    "    return discipline_map.get(cat.split(\".\")[0], \"Other\")\n",
    "\n",
    "def get_subfield(categories):\n",
    "    for code in priority_subfield_map:\n",
    "        if code in categories:\n",
    "            return priority_subfield_map[code]\n",
    "    return \"Other\"\n",
    "\n",
    "#  HARVEST \n",
    "all_ids = set()\n",
    "total_saved = 0\n",
    "all_rows = []\n",
    "\n",
    "for prefix in CATEGORY_PREFIXES:\n",
    "    print(f\"\\nStarting category: {prefix}\")\n",
    "    for start in range(0, MAX_RESULTS_PER_CATEGORY, BATCH_SIZE):\n",
    "        print(f\"  Fetching {prefix} results {start} to {start + BATCH_SIZE}...\")\n",
    "\n",
    "        url = (\n",
    "            f\"https://export.arxiv.org/api/query?\"\n",
    "            f\"search_query=cat:{prefix}*&\"\n",
    "            f\"start={start}&max_results={BATCH_SIZE}&\"\n",
    "            f\"sortBy=submittedDate&sortOrder=descending\"\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            feed = feedparser.parse(response.content)\n",
    "        except Exception as e:\n",
    "            print(f\"  Request failed: {e}\")\n",
    "            break\n",
    "\n",
    "        if not feed.entries:\n",
    "            print(f\"  No results returned.\")\n",
    "            break\n",
    "\n",
    "        new_entries = 0\n",
    "        for entry in feed.entries:\n",
    "            paper_id = entry.id\n",
    "            if paper_id in all_ids:\n",
    "                continue\n",
    "\n",
    "            all_ids.add(paper_id)\n",
    "            title = entry.title.strip().replace(\"\\n\", \" \")\n",
    "            abstract = entry.summary.strip().replace(\"\\n\", \" \")\n",
    "            pdf_url = next((l.href for l in entry.links if l.type == \"application/pdf\"), \"\")\n",
    "            primary_cat = entry.arxiv_primary_category['term']\n",
    "            all_cats = [t['term'] for t in entry.tags]\n",
    "            subfield = get_subfield(all_cats)\n",
    "            discipline = get_discipline(primary_cat)\n",
    "\n",
    "            all_rows.append([\n",
    "                title, abstract, \",\".join(all_cats), primary_cat, pdf_url, subfield, discipline\n",
    "            ])\n",
    "            new_entries += 1\n",
    "\n",
    "        total_saved += new_entries\n",
    "        print(f\"  Batch done. New entries: {new_entries}, Total: {total_saved}\")\n",
    "        time.sleep(SLEEP_TIME)\n",
    "\n",
    "# Save to CSV\n",
    "columns = [\"title\", \"abstract\", \"categories\", \"primary_category\", \"pdf_url\", \"subfield\", \"discipline\"]\n",
    "df = pd.DataFrame(all_rows, columns=columns)\n",
    "df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"\\nDone. {total_saved} unique papers saved to: {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71915dc0-8f61-4139-baf1-f34704f6579b",
   "metadata": {},
   "source": [
    "## 3.3 Rule-Based Classifier on Raw Data without Methodology\n",
    "\n",
    "Using the data harvested from arXiv, I built a lightweight rule-based classifier to predict the methodology of papers based solely on keyword presence in the abstract text. This part of the pipeline is completely independent of the neural network models.\n",
    "\n",
    "I manually curated four lists of methodology-specific keywords for:\n",
    "- Design Science / System Design\n",
    "- Mixed Methods\n",
    "- Qualitative\n",
    "- Theoretical / Conceptual\n",
    "\n",
    "Each paper's abstract was lowercased and searched for the presence of these keywords using regular expressions. A score was computed for each methodology by counting keyword matches. The methodology with the highest score was assigned as the prediction, unless all scores were zero, in which case the label was \"Uncertain\".\n",
    "\n",
    "This rule-based method served two purposes:\n",
    "- Interpretability : I could clearly inspect which keywords triggered certain classifications.\n",
    "- Bootstrapping :  It offered a way to automatically label large unlabeled corpora (like arXiv papers) for future experiments.\n",
    "- The final results were saved to a new CSV (arxiv_bulk_download_wMethodology.csv) with a predicted methodology column added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4a8b14b-fed6-4299-b23a-37dfb1c4d134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            abstract  \\\n",
      "0  Generative models typically sample outputs ind...   \n",
      "1  Visual diffusion models achieve remarkable pro...   \n",
      "2  Recent advances in diffusion models have broug...   \n",
      "3  3D content generation has recently attracted s...   \n",
      "4  Parametric body models offer expressive 3D rep...   \n",
      "\n",
      "            predicted_methodology  \n",
      "0                   Mixed Methods  \n",
      "1  Design Science / System Design  \n",
      "2        Theoretical / Conceptual  \n",
      "3  Design Science / System Design  \n",
      "4  Design Science / System Design  \n"
     ]
    }
   ],
   "source": [
    "# Load CSV \n",
    "df = pd.read_csv(\"arxiv_bulk_download.csv\") \n",
    "\n",
    "# Keyword rules per methodology \n",
    "rules = {\n",
    "    \"Design Science / System Design\": [\n",
    "        \"dataset\", \"evaluate\", \"propose\", \"training\", \"benchmark\", \"proposed\",\n",
    "        \"outperforms\", \"implementation\", \"system\", \"architecture\", \n",
    "        \"prototype\", \"algorithm\", \"model\", \"design\", \"development\", \n",
    "        \"testing\", \"validation\", \"performance\", \"experiment\", \"optimization\"\n",
    "    ],\n",
    "    \"Mixed Methods\": [\n",
    "        \"survey\", \"interview\", \"quantitative\", \"mixed methods\",\n",
    "        \"participants\", \"framework\", \"empirical\", \"multi-method\", \"case study\",\n",
    "        \"triangulation\", \"data integration\", \"sequential\", \"concurrent\", \n",
    "        \"questionnaire\", \"statistical\", \"thematic analysis\", \"mixed-method\"\n",
    "    ],\n",
    "    \"Qualitative\": [\n",
    "        \"interviews\", \"semi-structured\", \"qualitative\", \"grounded theory\", \n",
    "        \"thematic\", \"open-ended\", \"narrative\", \"focus group\", \"field notes\", \n",
    "        \"transcripts\", \"ethnography\", \"phenomenology\", \"observation\", \n",
    "        \"coding\", \"discourse\", \"interpretive\", \"participant observation\"\n",
    "    ],\n",
    "    \"Theoretical / Conceptual\": [\n",
    "        \"theoretical\", \"framework\", \"conceptual\", \"model\", \"hypothesis\",\n",
    "        \"proposition\", \"derive\", \"formalize\", \"assumption\", \"philosophical\",\n",
    "        \"literature review\", \"synthesis\", \"theory\", \"concept\", \"paradigm\", \n",
    "        \"ontology\", \"epistemology\", \"abstraction\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Scoring function\n",
    "def classify_methodology(text):\n",
    "    text = str(text).lower()\n",
    "    scores = {}\n",
    "\n",
    "    for label, keywords in rules.items():\n",
    "        count = sum(bool(re.search(r'\\b' + re.escape(word) + r'\\b', text)) for word in keywords)\n",
    "        scores[label] = count\n",
    "\n",
    "    best_label = max(scores, key=scores.get)\n",
    "    return best_label if scores[best_label] > 0 else \"Uncertain\"\n",
    "\n",
    "# Apply classifier\n",
    "df['predicted_methodology'] = df['abstract'].apply(classify_methodology)\n",
    "\n",
    "# Save/preview\n",
    "print(df[['abstract', 'predicted_methodology']].head())\n",
    "df.to_csv(\"arxiv_bulk_download_wMethodology.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-FYP]",
   "language": "python",
   "name": "conda-env-.conda-FYP-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
